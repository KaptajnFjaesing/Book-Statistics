\chapter{Introduction to Probability Theory}
\label{chp:probaiblity_theory}
Probability theory is a foundational branch of mathematics that provides the formal framework for reasoning about uncertainty. At its core, it studies random experiments and the likelihood of their outcomes. This chapter reviews the essential principles and axioms of probability, laying the groundwork for statistical inference and decision-making under uncertainty.

\begin{definition}[Sample Space]
	\label{def:sample_space}
	The sample space\index{Sample space}, denoted by $\Omega$, is the set of all possible outcomes of a random experiment. It encompasses every conceivable result that could occur, serving as the foundation for analyzing probabilities associated with different outcomes.
\end{definition}

\begin{definition}[Event]
	An event\index{Event}, $E$, is a subset of the sample space\index{Sample space}, denoted by $E \subseteq \Omega$, that corresponds to a specific collection of possible outcomes in a random experiment. Events may consist of single or multiple outcomes and are defined by the occurrence or non-occurrence of particular conditions.
\end{definition}

\begin{example}
	\label{ex:die1}
	Consider the roll of a fair six-sided die\index{Die example}. The sample space\index{Sample space} for this experiment is given by $\Omega = \{ \epsdice{1}, \epsdice{2}, \epsdice{3}, \epsdice{4}, \epsdice{5}, \epsdice{6} \}$. $E = \{\epsdice{2}, \epsdice{4}, \epsdice{6}\}$, is the event of rolling an even number. 
\end{example}

\begin{definition}[$\sigma$-algebra]
	\label{def:sigma_algebra}
	A $\sigma$-algebra\index{$\sigma$-algebra} over a sample space\index{Sample space} $\Omega$ is a collection of subsets $\mathcal{G}$ of $\Omega$ that contains both $\emptyset$ and $\Omega$, is closed under complementation (that is, if $E \in \mathcal{G}$ then $E^c \in \mathcal{G}$), and is closed under countable unions (and therefore also under countable intersections).
\end{definition}

\begin{example}
	\label{ex:die1a}
	For the roll with the fair die considered in \exref{ex:die1}\index{Die example}, the sample space\index{Sample space} is $\Omega = \{ \epsdice{1}, \epsdice{2}, \epsdice{3}, \epsdice{4}, \epsdice{5}, \epsdice{6} \}$ and the trivial $\sigma$-algebra on $\Omega$ is given by
	\begin{equation}
		\mathcal{G}_{\text{trivial}} = \{\emptyset, \Omega\}.
	\end{equation}
	In this case, the only events that can be described are the impossible event $\emptyset$ and the certain event $\Omega$. For instance, the event of rolling an even number $E = \{\epsdice{2}, \epsdice{4}, \epsdice{6}\}$ is not in $\mathcal{G}_{\text{trivial}}$.
\end{example}

\begin{definition}[Borel $\sigma$-algebra]
	\label{def:borel_sigma_algebra}
	The Borel $\sigma$-algebra\index{Borel $\sigma$-algebra}, denoted $\mathcal{B}(\mathbb{R})$, is the smallest $\sigma$-algebra on $\mathbb{R}$ that contains all open subsets of $\mathbb{R}$.  Equivalently, $\mathcal{B}(\mathbb{R})$ is generated by the collection of open intervals $(a,b) \subset \mathbb{R}$. Thus, $\mathcal{B}(\mathbb{R})$ contains all sets that can be formed from open intervals through countable unions, intersections, and complements.  
\end{definition}

\begin{definition}[Event Space]
	\label{def:event_space}
	The set containing all valid possible events for a random experiment is referred to as the event space\index{Event space}, $\mathcal{F}$. The notion of "all valid possible events for a random experiment" is formally defined by requiring $\mathcal{F}$ to be a $\sigma$-algebra \index{$\sigma$-algebra}.
\end{definition}

\begin{remark}[Typical Event Spaces]
	For a discrete sample space\index{Sample space} $\Omega$, $\mathcal{F}$ is typically the power set of $\Omega$. For a continuous sample space, $\mathcal{F}$ is typically the Borel $\sigma$-algebra, generated by open sets in $\mathbb{R}$ ($\mathcal{B}(\mathbb{R})$).
\end{remark}

\begin{example}
	\label{ex:die2}
	For the roll with the fair die considered in \exref{ex:die1}\index{Die example}, the sample space\index{Sample space} is $\Omega = \{ \epsdice{1}, \epsdice{2}, \epsdice{3}, \epsdice{4}, \epsdice{5}, \epsdice{6} \}$ and the event space is given by
	\begin{equation}
		\begin{split}
			\mathcal{F}&=\{\emptyset, \{\epsdice{1}\},\{\epsdice{1},\epsdice{3}\},\{\epsdice{3}\},\{\epsdice{1},\epsdice{2},\epsdice{3},\epsdice{4}\},\{\epsdice{5}\},\dots,\Omega\}\\
			& = 2^\Omega.
		\end{split}
	\end{equation}
\end{example}

\begin{definition}[Measurable Space]
	\label{def:measurable_space}
	A measurable space is a pair $(\Omega, \mathcal{F})$, where $\Omega$ is the sample space\index{Sample space} of a random experiment and $\mathcal{F}$ is the event space.
\end{definition}

\begin{definition}[Measure]
	\label{def:measure}
	\index{Measure}
	Let $(\Omega, \mathcal{F})$ be a measurable space, where $\Omega$ is the sample space\index{Sample space} and $\mathcal{F}$ is the event space. A measure $\mu$ is a set function
	\begin{equation}
		\mu\colon \mathcal{F} \to [0,\infty]
	\end{equation}
	that satisfies \axref{ax:non_neg} (non-negativity) and \axref{ax:add} (additivity).
\end{definition}

\begin{axiom}[Non-negativity]
	\label{ax:non_neg}
	For any event $E\in \mathcal{F}$, the measure $\mu(E)$ is non-negative, satisfying
	\begin{equation}
		\mu(E) \geq 0 \quad \forall E \in  \mathcal{F}.
	\end{equation}
\end{axiom}

\begin{axiom}[Additivity]
	\label{ax:add}
	For any countable sequence of mutually exclusive events $E_1, E_2, \ldots\in \mathcal{F}$, the measure of their union is the sum of their individual measures, such that
	\begin{equation}
		\mu\left(\bigcup_{i=1}^{\infty} \mathit{E}_i\right) = \sum_{i=1}^{\infty} \mu(\mathit{E}_i) \quad \forall \mathit{E}_i \in \mathcal{F} \text{ where } \bigcap_{i=1}^{\infty} \mathit{E}_i = \emptyset.
	\end{equation}
\end{axiom}

\begin{definition}[$\sigma$-finite Measure]
	\label{def:sigma_finite_measure}
	\index{$\sigma$-finite measure}
	Let $(\Omega, \mathcal{F})$ be a measurable space, where $\Omega$ is the sample space\index{Sample space} and $\mathcal{F}$ is the event space. A measure $\mu$ on $(\Omega, \mathcal{F})$ is called $\sigma$-finite if there exists a countable collection of sets $\{A_i\}_{i\in\mathbb{N}} \subseteq \mathcal{F}$ such that 
	\begin{equation}
		\Omega = \bigcup_{i=1}^\infty A_i
		\quad\text{and}\quad 
		\mu(A_i) < \infty \;\; \forall i\in\mathbb{N}.
	\end{equation}
\end{definition}

\begin{definition}[Measurable Function]
	\label{def:measurable_function}
	\index{Measurable function}
	Let $(\Omega,\mathcal{F})$ and $(\Omega_X,\mathcal{F}_X)$ be measurable spaces. A function
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	is said to be measurable if
	\begin{equation}
		X^{-1}(B) \in \mathcal{F} \quad \forall B \in \mathcal{F}_X,
	\end{equation}
	where
	\begin{equation}
		X^{-1}(B) = \{\omega \in \Omega \mid X(\omega) \in B\}.
	\end{equation}
	In words, the preimage of every measurable set in $\mathcal{F}_X$ is a measurable set in $\mathcal{F}$.
\end{definition}

\begin{definition}[Lebesgue Measure]
	\label{def:lebesgue_measure}
	\index{Lebesgue measure}
	The Lebesgue measure $\lambda$ is a measure, in the sense of \dfref{def:measure}, defined on the Borel $\sigma$-algebra $\mathcal{B}(\mathbb{R})$ such that for every interval $(a,b] \subseteq \mathbb{R}$,
	\begin{equation}
		\lambda((a,b]) = b-a.
	\end{equation}
	In higher dimensions, $\lambda$ generalizes to $\mathbb{R}^n$, where it coincides with the usual notions of length, area, and volume.
\end{definition}

\begin{definition}[Counting Measure]
	\label{def:counting_measure}
	\index{Counting measure}
	Let $(\Omega, \mathcal{F})$ be a discrete measurable space, where $\Omega$ is the sample space\index{Sample space} and $\mathcal{F}$ is the event space. The counting measure $\nu$ is a measure, in the sense of \dfref{def:measure}, defined on $\mathcal{F}$ such that for every event $E \in \mathcal{F}$,
	\begin{equation}
		\nu(E) = |E|,
	\end{equation}
	where $|E|$ denotes the cardinality of $E$ (finite or countably infinite). In particular, for finite sets $E$, $\nu(E)$ equals the number of elements in $E$, and for countably infinite sets, $\nu(E) = \infty$.
\end{definition}


\begin{definition}[Probability Measure]
	\label{def:probability}
	\index{Probability Measure}
	Loosely speaking, probability can be regarded~\cite{chan2021introduction} as a measure of the size of an event relative to the sample space\index{Sample space}. Formally, a probability measure\index{Probability Measure} $\mathbb{P}$ is a measure, in accordance with \dfref{def:measure} (measure), defined on a measurable space $(\Omega, \mathcal{F})$ that, in addition to satisfying \axref{ax:non_neg} (non-negativity) and \axref{ax:add} (additivity), obeys the normalization property
	\begin{equation}
		\mathbb{P}(\Omega) = 1.
	\end{equation}
\end{definition}




\begin{definition}[Objective Probability Measure]
	\label{def:objective_probability}
	Let $\mathbb{P}$ denote a generic probability measure\index{Probability measure} defined on the generic probability space\index{Probability space} $(\Omega,\mathcal{F},\mathbb{P})$. 
	The \emph{objective probability measure}\index{Objective probability measure}-interpretation defines $\mathbb{P}$ as the long-run or limiting frequency of an event $E$. 
	That is, if $m$ is the number of occurrences of $E$ and $n$ the number of experiments, then~\cite{Leamer1978}
	\begin{equation}
		\mathbb{P}(E) \equiv \lim_{{n \to \infty}} \bigg(\frac{m}{n}\bigg)
	\end{equation}
	defines the probability measure as the limit of a relative frequency.
\end{definition}

\begin{definition}[Sugeno Measure]
	\label{def:sugeno_measure}
	Let $(\Omega, \mathcal{F})$ be a measurable space\index{Sugeno measure}\index{Measurable space}. 
	A set function\index{Belief function}
	\begin{equation}
		\operatorname{Bel}\colon \mathcal{F} \to [0,1]
	\end{equation}
	is called a \emph{Sugeno measure}~\cite{shafer1987} if it satisfies the following properties:
	\begin{enumerate}
		\item \axref{ax:non_neg} (non-negativity),
		\item $\operatorname{Bel}(\Omega) = 1$ (normalization),
		\item $\operatorname{Bel}(A) \le \operatorname{Bel}(B)$ for all $A, B \in \mathcal{F}$ with $A \subseteq B$ (monotonicity).
	\end{enumerate}
\end{definition}

\begin{definition}[Subjective Probability Measure]
	\label{def:subjective_probability}
	A \emph{subjective probability measure}\index{Subjective probability measure} is a numerical representation of rational beliefs\index{Rational beliefs}. 
	Formally, it is a probability measure\index{Probability measure} $\mathbb{P}$, according to \dfref{def:probability}, on a measurable space\index{Measurable space} $(\Omega, \mathcal{F})$ that fulfills \dfref{def:sugeno_measure} ~\cite{shafer1987,hoff2009first}.
\end{definition}

\begin{theorem}[Probability vs.\ Sugeno Measures]
	Any probability measure $\mathbb{P}$ on $(\Omega, \mathcal{F})$ is a Sugeno measure.
\end{theorem}
\begin{proof}
	Let $\mathbb{P}$ be a probability measure on $(\Omega, \mathcal{F})$. By definition, $\mathbb{P}$ satisfies:
	\begin{enumerate}
		\item $\mathbb{P}(\emptyset) = 0$ and $\mathbb{P}(\Omega) = 1$ (Boundary Conditions).
		\item If $A, B \in \mathcal{F}$ and $A \subseteq B$, then $\mathbb{P}(A) \leq \mathbb{P}(B)$ (Monotonicity).
	\end{enumerate}
	Thus, $\mathbb{P}$ is a Sugeno measure.
\end{proof}

\begin{remark}
	Since a probability measure $\mathbb{P}$ satisfies the axioms of a Sugeno measure\index{Sugeno measure}, it can be interpreted as a belief function\index{Belief function}.
\end{remark}





\begin{definition}[Probability Space]
	\label{def:probability_space}
	A probability space\index{Probability space} is a triple $(\Omega, \mathcal{F}, \mathbb{P})$, where $\Omega$ is the sample space\index{Sample space},	$\mathcal{F}$ is the event space and $\mathbb{P}$ is a probability measure on the measurable space $(\Omega, \mathcal{F})$.
\end{definition}

\begin{remark}[Events for Continuous Sample Spaces]
	In continuous sample spaces\index{Sample space}, individual outcomes (single real numbers) have probability zero. Therefore, events are nontrivial subsets of the sample space, typically intervals or more general Borel sets\index{Borel set}. For example, the event 
	\begin{equation}
		E = (0.2, 0.5)
	\end{equation} 
	represents the outcome that the randomly chosen number lies between $0.2$ and $0.5$.
\end{remark}

\begin{remark}[Reason for Borel $\sigma$-algebra]
	The restriction to Borel sets\index{Borel set} in case of a continuous sample space\index{Sample space} (rather than all subsets of $\mathbb{R}$) is not arbitrary: it avoids paradoxical constructions such as non-measurable sets (e.g. the Vitali set), which cannot be consistently assigned a probability. This ensures that the probability measure is well defined for all events in $\mathcal{F}$.
\end{remark}

\begin{example}
	Consider choosing a real number uniformly at random from the interval $[0,1]$. Here the sample space\index{Sample space} is $\Omega = [0,1]$. Unlike the discrete case, the event space\index{Event space} $\mathcal{F}$ cannot simply be the power set of $[0,1]$, since not all subsets admit a well-defined probability measure. Instead, the event space is chosen as the Borel $\sigma$-algebra $\mathcal{B}([0,1])$, which includes sets such as open intervals $(0.2, 0.5)$, closed intervals $[0, 0.1]$, and countable unions and intersections thereof.
\end{example}


\begin{definition}[Independence]
	\label{def:independence}
	Events $E_1$ and $E_2$  in a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ are said to be independent iff\index{Independent events}
	\begin{equation}
		\mathbb{P}(E_1 \cap E_2) = \mathbb{P}(E_1) \mathbb{P}(E_2).
		\label{eq:ind}
	\end{equation}
\end{definition}

\begin{definition}[Conditional Probability]
	\label{def:conditional_probability}
	For events $E_1$ and $E_2$ in a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ with $\mathbb{P}(E_2) > 0$, the conditional probability\index{Conditional probability} of $E_1$ given $E_2$ is defined as follows
	\begin{equation}
		\mathbb{P}(E_1|E_2) \equiv \frac{\mathbb{P}(E_1 \cap E_2)}{\mathbb{P}(E_2)}.
		\label{eq:cond}
	\end{equation}
\end{definition}

\begin{definition}[Conditional Independence]
\label{def:conditional_independence}
Events $E_1$ and $E_2$ are conditionally independent given $E_3$ if
\begin{equation}
\mathbb{P}(E_1 \cap E_2 | E_3) = \mathbb{P}(E_1|E_3)\mathbb{P}(E_2|E_3).
\end{equation}
\end{definition}

\begin{theorem}[Chain Rule]
	\label{theorem:chain_rule}
	Let $E_1, E_2, E_3 \in \mathcal{F}$ be events in a probability space $(\Omega, \mathcal{F}, \mathbb{P})$. The chain rule\index{Chain rule} states that
	\begin{equation}
		\mathbb{P}(E_1 \cap E_2 \cap E_3) 
		=\mathbb{P}(E_1 \mid E_2 \cap E_3)\mathbb{P}(E_2 \mid E_3)\mathbb{P}(E_3).
		\label{eq:prod}
	\end{equation}
\end{theorem}

\begin{proof}
	From the definition of conditional probability in \dfref{def:conditional_probability}
	\begin{equation}
		\mathbb{P}(E_1 \cap E_2 \cap E_3) = \mathbb{P}(E_1|E_2 \cap E_n)\mathbb{P}(E_2 \cap E_3).
		\label{eq:p1}
	\end{equation}
	Using the definition of conditional probability again
	\begin{equation}
		\mathbb{P}(E_2 \cap E_3) = \mathbb{P}(E_2| E_3)\mathbb{P}(E_3).
	\end{equation}
	which leads to \thref{theorem:chain_rule}.
\end{proof}

\begin{theorem}[Bayes theorem]
	\label{theorem:bayes_theorem}
	For events $E_1,E_2 \in \mathcal{F}$ in a probability space $(\Omega, \mathcal{F}, \mathbb{P})$, Bayes theorem\index{Bayes theorem} can be formulated as follows
	\begin{equation}
		\mathbb{P}(E_1| E_2) = \frac{\mathbb{P}(E_2| E_1)\mathbb{P}(E_1)}{\mathbb{P}(E_2)}.
		\label{bayes_theorem}
	\end{equation}
\end{theorem}

\begin{proof}
	Bayes theorem follows directly from applying \thref{theorem:chain_rule} and applying the concept of symmetry as follows
	\begin{equation}
		\begin{split}
			\mathbb{P}(E_1 \cap E_2) &= \mathbb{P}(E_1| E_2)\mathbb{P}(E_2) \\
			& = \mathbb{P}(E_2|E_1)\mathbb{P}(E_1)
		\end{split}
		\label{eq:c2}
	\end{equation}
	from which
	\begin{equation}
		\mathbb{P}(E_1| E_2) = \frac{\mathbb{P}(E_2| E_1)\mathbb{P}(E_1)}{\mathbb{P}(E_2)}
	\end{equation}
	which is \thref{theorem:bayes_theorem}.
\end{proof}

\begin{theorem}[Law of Total Probability / Marginalization]
	\label{theorem:law_of_total_probability}
	Let $\{E_1, E_2, \dots, E_n\}$ be a finite partition\index{Partition}\index{Law of Total Probability}\index{Marginalization}, in the sense of \dfref{def:partition}, of the sample space\index{Sample space} $\Omega$ in a probability space $(\Omega, \mathcal{F}, \mathbb{P})$. Then, for any event $A \in \mathcal{F}$,
	\begin{equation}
		\mathbb{P}(A) = \sum_{i=1}^n \mathbb{P}(A \cap E_i).
		\label{eq:law_total_probability}
	\end{equation}
\end{theorem}

\begin{proof}
	Consider an event $A\in \mathcal{F}$ and a partition $\{E_1,E_2,\dots E_n\}$ of $\Omega$ such that $\cup_{i}E_i=\Omega$. For mutually exclusive events (which a partition by definition is), finite additivity can be used such that
	\begin{equation}
		\sum_{i}\mathbb{P}(A \cap E_i) = \mathbb{P}\bigg(\bigcup_{i}(A \cap E_i)\bigg).
		\label{eq:qq1}
	\end{equation} 
	$\bigcup_{i}(A \cap E_i)$ is the union of all intersections between $A$ and the $E$'s. However, since the $E$'s form a partition of $\Omega$, they together form $\Omega$ and the intersection between $\Omega$ and $A$ is $A$, meaning
	\begin{equation}
		\begin{split}
			\bigcup_{i}(A \cap E_i)  &= (A,\bigcup_{i}E_i)\\
			&= (A \cap \Omega)\\
			& =A.
		\end{split}
		\label{eq:qq2}
	\end{equation}
	Combining \EQref{eq:qq1} and \EQref{eq:qq2} then yields
	\begin{equation}
		\mathbb{P}(A) = \sum_{i} \mathbb{P}(A \cap E_i)
	\end{equation}
	which is \thref{theorem:law_of_total_probability}.
\end{proof}

\begin{example}
	\index{Example: Fair die}
	For the roll with the fair die considered in \exref{ex:die1}\index{Die example}, \exref{ex:die1a} and \exref{ex:die2}, the sample space\index{Sample space} is $\Omega = \{ \epsdice{1}, \epsdice{2}, \epsdice{3}, \epsdice{4}, \epsdice{5}, \epsdice{6} \}$. Let $E_1 = \{\epsdice{2}, \epsdice{4}, \epsdice{6}\}$ and $E_2 = \{\epsdice{4}\}$ be two events, then from \dfref{def:conditional_probability}
	\begin{equation}
		\begin{split}
			\mathbb{P}(E_1|E_2) &= \frac{\mathbb{P}(E_1 \cap E_2)}{\mathbb{P}(E_2)}\\
			& = 1
		\end{split}
	\end{equation}
	where $\mathbb{P}(E_1 \cap E_2)= \frac{1}{6}$ since $E_1\cap E_2 = E_2=\{\epsdice{4}\}$ is one of $6$ possible values and $\mathbb{P}(E_2) = \frac{1}{6}$. Intuitively this makes sense because $E_2$ is a set with one member and since $E_2$ is known, the outcome of the experiment is known with certainty in this case.
\end{example}

\begin{definition}[Random Variable]
	\label{def:random_Variable}
	\index{Random variable}
	A random variable $X$ is a measurable function\index{Measurable function} in the sense of \dfref{def:measurable_function},
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	from a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space $(\Omega_X, \mathcal{F}_X)$, where $\Omega_X$ is the codomain of $X$ and $\mathcal{F}_X$ is a $\sigma$-algebra on $\Omega_X$.
\end{definition}

\begin{remark}[Types of Random Variables]
	Random variables provide a numerical representation of the outcomes of a random experiment.  
	They are classified as either discrete, when $\Omega_X$ is countable, or continuous, when $\Omega_X$ is uncountable, often modeled as an interval of $\mathbb{R}$.
\end{remark}

\begin{definition}[Image Measure]
	\label{def:image_measure}
	\index{Image measure}
	Let 
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	be a random variable\index{Random variable} from the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$. Then~\cite{drewitz2019introduction}
	\begin{equation}
		\mathbb{P}\circ X^{-1}\colon \mathcal{F}_X\to [0,1]
	\end{equation}
	defines a probability measure\index{Probability measure} on $(\Omega_X, \mathcal{F}_X)$. $\mathbb{P}\circ X^{-1} \equiv \mathbb{P}_X$ is called the image measure or the pushforward measure\index{Pushforward measure} of $\mathbb{P}$.
\end{definition}

\begin{remark}[Maginalization via Random Variable]
	\label{remark:marginalization}
	\thref{theorem:law_of_total_probability} extends naturally from a finite or countable partition of the sample space\index{Sample space}\index{Law of Total Probability} to the case where the partition is induced by a random variable\index{Random variable} $X$. Let
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	be a random variable\index{Random variable} from the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$. Then, for any event $A \in \mathcal{F}$, \thref{theorem:law_of_total_probability} can be written rigorously in terms of the image measure\index{Image measure} $\mathbb{P}_X = \mathbb{P} \circ X^{-1}$ as
	\begin{equation}
		\mathbb{P}(A) = \int_{\Omega_X} \mathbb{P}(A \mid X^{-1}(\{x\})) \, d\mathbb{P}_X(x),
	\end{equation}
	where $\mathbb{P}(A \mid X^{-1}(\{x\}))$ is the conditional probability of $A$ given the event $X^{-1}(\{x\}) \subseteq \Omega$. 
\end{remark}

\begin{definition}[Expected value]
	\label{def:expectation_image}
	Let 
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	be a random variable\index{Random variable} from the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$, and let
	\begin{equation}
		\mathbb{P}_X = \mathbb{P} \circ X^{-1}
	\end{equation} 
	be the image measure\index{Image measure} of $X$ on $(\Omega_X, \mathcal{F}_X)$. The expected value\index{Expected value} of $X$, denoted by $\mathbb{E}_X[X]$, is defined as follows
	\begin{equation}
		\mathbb{E}_X[X] \equiv \int_{\Omega_X} x \mathrm{d}\mathbb{P}_X(x).
		\label{eq:expected_value_image}
	\end{equation}
\end{definition}

\begin{theorem}[Non-negativity of expected value]
	Let 
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	be a random variable\index{Random variable} from the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$. $X\geq 0 \Rightarrow \mathbb{E}_X[X]\geq 0$.
\end{theorem}
\begin{proof}
	From \dfref{def:expectation_image} 
	\begin{equation}
		\mathbb{E}_X[X] = \int_{\Omega_X}x \mathrm{d}\mathbb{P}_X(x),
	\end{equation}
	and if $x \ge 0$ for all $x \in \Omega_X$, the integral of a non-negative function with respect to a measure\index{Measure} is non-negative. Hence, $\mathbb{E}_X[X] \ge 0$.
\end{proof}

\begin{theorem}[Linearity of expected value]
	\label{theorem:exp_linear}
	Let 
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	be a random variable\index{Random variable} from the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$. The expected value\index{Expected value} is a linear operator meaning $\mathbb{E}_X[a+X] = a+\mathbb{E}_X[X]$ and $\mathbb{E}_X[aX] = a\mathbb{E}_X[X]$ for any constant $a$.
\end{theorem}
\begin{proof}
	From \dfref{def:expectation_image} 
	\begin{equation}
		\begin{split}
			\mathbb{E}_X[a + X] &= \int_{\Omega_X}(a + x) \mathrm{d}\mathbb{P}_X(x) \\ 
			&= a\int_{\Omega_X} \mathrm{d}\mathbb{P}_X(x) + \int_{\Omega_X} x \mathrm{d}\mathbb{P}_X(x)\\
			&= a + \mathbb{E}_X[X],
		\end{split}
	\end{equation}
	since $\mathbb{P}_X(\Omega_X) = 1$. Similarly,
	\begin{equation}
		\begin{split}
			\mathbb{E}_X[a X] &= \int_{\Omega_X} a x \mathrm{d}\mathbb{P}_X(x) \\
			& = a \int_{\Omega_X} x \mathrm{d}\mathbb{P}_X(x)\\
			 = a \mathbb{E}_X[X].
		\end{split}
	\end{equation}
\end{proof}

\begin{remark}[Law of the Unconscious Statistician]
	\label{th:lotus}
	Let 
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	be a random variable\index{Random variable} from the probability space\index{Probability space}\index{Law of the Unconscious Statistician} $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$, and let 
	\begin{equation}
		g\colon \Omega_X \to \mathbb{R}
	\end{equation} 
	be a generic measurable function\index{Measurable function}. Denote the image measure\index{Image measure} of $X$ by $\mathbb{P}_X $. Then
	\begin{equation}
		\mathbb{E}_X[g(X)] \equiv \int_{\Omega_X} g(x)\mathrm{d}\mathbb{P}_X(x).
		\label{eq:lotus_image}
	\end{equation}
\end{remark}

\begin{definition}[Variance]
	\label{def:variance}
	Let 
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	be a real-valued random variable\index{Random variable} from the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$. The variance\index{Variance} of $X$, denoted by $\operatorname{Var}_X[X]$, is defined as follows\index{Variance}
	\begin{equation}
		\begin{split}
			\operatorname{Var}_X[X]&\equiv \mathbb{E}_X[(X-\mathbb{E}_X[X])^2]\\
			&= \mathbb{E}_X[X^2]-\mathbb{E}_X[X]^2.
		\end{split}
	\end{equation}
\end{definition}

\begin{theorem}[Markov's Inequality]
	\label{thm:markov}
	Let 
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	be a non-negative random variable\index{Random variable} from the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$, and let $a > 0$. Then
	\begin{equation}
		\mathbb{P}_X([a, \infty)) \le \frac{\mathbb{E}_X[X]}{a}.
	\end{equation}
\end{theorem}

\begin{proof}
	Let $1_{[a,\infty)}$ denote the indicator of the event $\{x \in \Omega_X | x \ge a\}$.  
	Since $X(\omega)\ge 0$ and $a>0$,
	\begin{equation}
		a\,1_{[a,\infty)}(X(\omega)) \le X(\omega), \quad \forall \omega \in \Omega.
	\end{equation}
	Taking expectations with respect to $\mathbb{P}_X$ and using linearity,
	\begin{equation}
		a\,\mathbb{E}_X[1_{[a,\infty)}] \le \mathbb{E}_X[X].
	\end{equation}
	By definition of the image measure,
	\begin{equation}
		\begin{split}
			\mathbb{E}_X[1_{[a,\infty)}] &= \int 1_{[a,\infty)}(x) \mathrm{d}\mathbb{P}_X(x)\\
			& = \mathbb{P}_X([a,\infty)).
		\end{split}
	\end{equation}
	Hence,
	\begin{equation}
		a \mathbb{P}_X([a,\infty)) \leq \mathbb{E}_X[X],
	\end{equation}
	and dividing both sides by $a$ yields the inequality.
\end{proof}

\begin{definition}[Probability Density with Respect to a Measure]
	\label{def:prob_density_general}
	\index{Probability density}
	Let
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	be a random variable\index{Random variable} from the probability space $(\Omega, \mathcal{F}, \mathbb{P})$ to the measurable space\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$. Let $\mu$ be a $\sigma$-finite measure\index{$\sigma$-finite measure} on $(\Omega_X, \mathcal{F}_X)$, in the sense of \dfref{def:sigma_finite_measure}. If the image measure\index{Image measure} $\mathbb{P}_X = \mathbb{P} \circ X^{-1}$ is absolutely continuous with respect to $\mu$, then by the Radon-Nikodym theorem~\cite{Navratil1981} there exists a measurable function
	\begin{equation}
		p_X = \frac{d\mathbb{P}_X}{d\mu},
	\end{equation}
	called the probability density of $X$ with respect to $\mu$, such that
	\begin{equation}
		\mathbb{P}_X(B) = \int_B p_X(x) \mathrm{d}\mu(x), \quad \forall B \in \mathcal{F}_X.
	\end{equation}
	Moreover, since $\mathbb{P}_X$ is a probability measure, the density satisfies
	\begin{equation}
		p_X(x) \ge 0, \quad \text{and} \quad
		\int_{\Omega_X} p_X(x) \mathrm{d}\mu(x) = 1.
	\end{equation}
\end{definition}

\begin{remark}[Probability Density Function]
	\label{remark:pdf}
	If $\mu = \lambda$ is the Lebesgue measure (\dfref{def:lebesgue_measure}) on $(\mathbb{R}, \mathcal{B}(\mathbb{R}))$, then the probability density $p_X$ is called the probability density function\index{Probability density function} (PDF). For $\mu = \lambda$, \dfref{def:prob_density_general} gives
	\begin{equation}
		\mathbb{P}_X(B) = \int_B p_X(x) \mathrm{d}\lambda(x),
		\quad \forall B \in \mathcal{B}(\mathbb{R}).
	\end{equation}
\end{remark}

\begin{remark}[Probability Mass Function]
	\label{remark:pmf}
	If $\mu = \nu$ is the counting measure\index{Counting measure} (\dfref{def:counting_measure}) on $\Omega_X$, then the probability density $p_X$ is called the probability mass function (PMF). For $\mu= \nu$, \dfref{def:prob_density_general} gives
	\begin{equation}
		\begin{split}
			\mathbb{P}_X(B) &= \int_B p_X(x) \mathrm{d}\nu(x)\\ 
			&= \sum_{x \in B} p_X(x).
		\end{split}
	\end{equation}
	In particular, for a singleton $B = \{x\}$,
	\begin{equation}
		\mathbb{P}_X(\{x\}) = p_X(x).
	\end{equation}
\end{remark}

\begin{remark}[Expected value of a discrete random variable]
	\label{rem:expected_value_discrete}
	If $X$ is a discrete random variable with probability mass function\index{Probability mass function} $p_X$, then the expected value reduces to
	\begin{equation}
		\mathbb{E}_X[X]=\sum_{x\in \Omega_X} x p_X(x).
		\label{eq:discrete_exp}
	\end{equation}
	\EQref{eq:discrete_exp} follows directly from \dfref{def:expectation_image}, since the image measure $\mathbb{P}_X$ is concentrated on singletons $\{x\}$ in the discrete case.
\end{remark}

\begin{remark}[Expected value of a continuous random variable]
	\label{remark:expectation_continuous}
	Let $X$ be a continuous random variable\index{Random variable} with PDF\index{Probability density function} $p_X$ on $\Omega_X \subseteq \mathbb{R}$. From \dfref{def:expectation_image} and \dfref{def:prob_density_general}	
	\begin{equation}
		\mathbb{E}_X[X] = \int_{\Omega_X} x p_X(x) \mathrm{d}\lambda(x),
	\end{equation}
	where $\lambda$ denotes the Lebesgue measure\index{Lebesgue measure} on $\mathbb{R}$. In practice, it is customary to write $d\lambda(x)$ simply as $dx$, so that
	\begin{equation}
		\mathbb{E}_X[X] = \int_{\Omega_X} x p_X(x) \mathrm{d}x.
	\end{equation}
	Here, $dx$ is understood as integration with respect to the Lebesgue measure.
\end{remark}

\begin{example}
	Let $X$ be a continuous random variable\index{Random variable} with PDF\index{Probability density function} $p_X$ on $\Omega_X\subseteq \mathbb{R}$. For the interval (event) $[a,b] \subseteq \Omega_X$,
	\begin{equation}
		\begin{split}
			\mathbb{P}(X^{-1}([a,b])) 
			&= \mathbb{P}_X([a,b])\\ 
			&= \int_{[a,b]} p_X(x) \mathrm{d}\lambda(x)\\ 
			&= \int_a^b p_X(x) \mathrm{d}x.
		\end{split}
	\end{equation}
\end{example}

\begin{definition}[Joint Probability Measure]
	\label{def:joint}
	\index{Joint probability measure}
	Let
	\begin{equation}
		X\colon \Omega \to \Omega_X, \quad Y\colon \Omega \to \Omega_Y
	\end{equation}
	be random variables\index{Random variable} from the probability space $(\Omega, \mathcal{F}, \mathbb{P})$ to measurable spaces\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$ and $(\Omega_Y, \mathcal{F}_Y)$.	The joint probability measure of $X$ and $Y$ is the image measure
	\begin{equation}
		\mathbb{P}_{X,Y} = \mathbb{P}\circ(X,Y)^{-1}
	\end{equation}
	defined on the measurable space 
	\begin{equation}
		(\Omega_{X_1}\times\Omega_{Y}, \mathcal{F}_{X}\otimes\mathcal{F}_{Y}).
	\end{equation}	
	All probability measures\index{Probability measure} related to the random variables can be derived from the joint probability measure via \thref{theorem:law_of_total_probability}.
\end{definition}

\begin{remark}[Marginalization from a Joint Measure]
	Let
	\begin{equation}
		X\colon \Omega \to \Omega_X, \quad Y\colon \Omega \to \Omega_Y
	\end{equation}
	be random variables\index{Random variable} from the probability space $(\Omega, \mathcal{F}, \mathbb{P})$ to measurable spaces\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$ and $(\Omega_Y, \mathcal{F}_Y)$. Suppose $A\in \mathcal{F}_X$ and let $\mathbb{P}_{X,Y}$ denote the joint probability measure on the measurable space $(\Omega_{X_1}\times\Omega_{Y}, \mathcal{F}_{X}\otimes\mathcal{F}_{Y})$, then from \thref{theorem:law_of_total_probability}
	\begin{equation}
			\mathbb{P}_{X}(A) = \mathbb{P}_{X,Y}(A \times \Omega_Y).
	\end{equation}
\end{remark}


\begin{theorem}[Law of total expectation]
	\label{theorem:total_expectation}
	\index{Law of total expectation}
	Let
	\begin{equation}
		X\colon \Omega \to \Omega_X, \quad Y\colon \Omega \to \Omega_Y
	\end{equation}
	be random variables\index{Random variable} from the probability space $(\Omega, \mathcal{F}, \mathbb{P})$ to measurable spaces\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$ and $(\Omega_Y, \mathcal{F}_Y)$. Let $\mathbb{P}_{X,Y}$ denote the joint probability measure on the measurable space $(\Omega_X \times \Omega_Y, \mathcal{F}_X \otimes \mathcal{F}_Y)$. Then
	\begin{equation}
		\mathbb{E}_X[X] = \mathbb{E}_Y\big[\mathbb{E}_{X|Y}[X \mid Y]\big].
	\end{equation}
\end{theorem}


\begin{proof}
	Let
	\begin{equation}
		X\colon \Omega \to \Omega_X, \quad Y\colon \Omega \to \Omega_Y
	\end{equation}
	be random variables\index{Random variable} from the probability space $(\Omega, \mathcal{F}, \mathbb{P})$ to the measurable spaces\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$ and $(\Omega_Y, \mathcal{F}_Y)$. Let $\mathbb{P}_{X,Y}$ denote the joint probability measure on the measurable space $(\Omega_X \times \Omega_Y, \mathcal{F}_X \otimes \mathcal{F}_Y)$. By Fubini's theorem and \dfref{def:conditional_probability},
	\begin{equation}
		\begin{split}
			\mathbb{E}_X[X] 
			&= \int_{\Omega_X} x \mathrm{d}\mathbb{P}_X(x)\\
			&= \int_{\Omega_X}\int_{\Omega_Y} x \mathrm{d}\mathbb{P}_{X,Y}(x,y)\\
			&= \int_{\Omega_Y}\int_{\Omega_X} x \mathrm{d}\mathbb{P}_{X|Y}(x)\mathrm{d}\mathbb{P}_Y(y)\\
			&= \mathbb{E}_Y[\mathbb{E}_{X|Y}[X\mid Y]].
		\end{split}
	\end{equation}
	or equivalently in terms of the probability densities
	\begin{equation}
		\begin{split}
			\mathbb{E}_X[X] 
			&= \int_{\Omega_X} x p_X(x) \mathrm{d}\mu_X(x)\\
			&= \int_{\Omega_Y} \int_{\Omega_X} x p_{X,Y}(x,y) \mathrm{d}\mu_X(x) \mathrm{d}\mu_Y(y)\\
			&= \int_{\Omega_Y} p_Y(y) \left( \int_{\Omega_X} x p_{X|Y}(x\mid y) \mathrm{d}\mu_X(x) \right) \mathrm{d}\mu_Y(y)\\
			&= \mathbb{E}_Y[\mathbb{E}_{X|Y}[X\mid Y]].
		\end{split}
	\end{equation}
\end{proof}

\begin{theorem}[Expectation of product of independent random variables]
	\label{theorem:expectation_independent}
	\index{Independent random variables}
	Let $X\colon \Omega \to \Omega_X$ and $Y\colon \Omega \to \Omega_Y$ be continuous random variables\index{Random variable} defined on the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$. If the random variables are independent the expectation can be written
	\begin{equation}
		\mathbb{E}_{X,Y}[XY]=\mathbb{E}_X[X]\mathbb{E}_Y[Y].
	\end{equation}
\end{theorem}

\begin{proof}
	\index{Probability density function}
	If the random variables are independent, then according to \dfref{def:independence}
	\begin{equation}
		\mathbb{P}_{X,Y}(\{x,y\})=\mathbb{P}_{X}(\{x\})\mathbb{P}_{Y}(\{y\})
	\end{equation}
	meaning
	\begin{equation}
		\begin{split}
			\mathbb{E}_{X,Y}[XY] &= \int_{\Omega_X}\int_{\Omega_Y}xy\mathrm{d}\mathbb{P}_{X,Y}(x,y)\\
			&= \int_{\Omega_X}x\mathrm{d}\mathbb{P}_X(x)\int_{\Omega_Y}y\mathrm{d}\mathbb{P}_Y(y)\\
			&= \mathbb{E}_X[X]\mathbb{E}_Y[Y].\\
		\end{split}
	\end{equation}
\end{proof}

\begin{definition}[Covariance]
	\label{def:covariance}
	\index{Covariance}
	Let $X\colon \Omega \to \Omega_X$ and $Y\colon \Omega \to \Omega_Y$ be continuous random variables defined on the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$, then the covariance of $X$ and $Y$, denoted by $\operatorname{Cov}_{X,Y}[X,Y]$, is defined as follows
	\begin{equation}
		\begin{split}
			\operatorname{Cov}_{X,Y}[X,Y]&=\mathbb{E}_{X,Y}[(X-\mathbb{E}_X[X])(Y-\mathbb{E}_Y[Y])]\\
			&=\mathbb{E}_{X,Y}[XY]-\mathbb{E}_X[X]\mathbb{E}_Y[Y],
		\end{split}
	\end{equation}
\end{definition}
\begin{theorem}[Covariance of independent random variables]
	\label{theorem:covariance_of_independent_variables}
	Let $X\colon \Omega \to \Omega_X$ and $Y\colon \Omega \to \Omega_Y$ be continuous random variables\index{Random variable} defined on the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$. If $X$ and $Y$ are independent, then their covariance is
	\begin{equation}
		\operatorname{Cov}_{X,Y}[X,Y] = 0.
	\end{equation}
\end{theorem}
\begin{proof}
	Using \thref{theorem:expectation_independent} in \dfref{def:covariance} yields $\operatorname{Cov}_{X,Y}[X,Y]=0$.
\end{proof}

\begin{definition}[Correlation]
	\label{def:correlation}
	\index{Correlation}
	Let $X\colon \Omega \to \Omega_X$ and $Y\colon \Omega \to \Omega_Y$ be continuous random variables\index{Random variable} defined on the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$. The correlation between $X$ and $Y$, denoted by $\operatorname{Corr}[X,Y]$, is defined as
	\begin{equation}
		\begin{split}
			\operatorname{Corr}_{X,Y}[X,Y] &= \frac{\operatorname{Cov}_{X,Y}[X,Y]}{\sqrt{\operatorname{Var}_X[X]  \operatorname{Var}_Y[Y]}} \\
			&= \frac{\mathbb{E}_{X,Y}[XY]-\mathbb{E}_X[X]\mathbb{E}_Y[Y]}{\sqrt{\left(\mathbb{E}_X[X^2] - \mathbb{E}_X[X]^2\right) \left(\mathbb{E}_Y[Y^2] - \mathbb{E}_Y[Y]^2\right)}}.
		\end{split}
	\end{equation}
\end{definition}

\begin{remark}[Correlation vs. Covariance]
	Correlation and covariance are both measures of the relationship between two random variables\index{Random variable}. While covariance indicates the extent to which two variables change together, correlation provides a standardized measure of this relationship, taking into account the scales of the variables. In particular, the correlation between two variables, denoted by $\operatorname{Corr}_{X,Y}[X, Y]$, is the covariance of $X$ and $Y$ divided by the product of their standard deviations. This normalization makes correlation a unitless quantity that ranges between -1 and 1, where -1 indicates a perfect negative linear relationship, 1 indicates a perfect positive linear relationship, and 0 indicates no linear relationship. In essence, correlation provides a more interpretable measure of the strength and direction of the linear association between two variables compared to covariance.
\end{remark}

\begin{definition}[Change of Variables for PDFs]
	\label{def:change_of_variables}
	\index{Change of variables for PDFs}
	Let $X\colon \Omega \to \Omega_X$ be a continuous random variable\index{Random variable} with probability density function\index{Probability density function} (PDF) $p_X$, defined on a probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$. Suppose $Y = g(X)$, where $g$ is a continuous and differentiable function with differentiable inverse $g^{-1}$. Then the PDF of $Y$, denoted $p_Y$, is given by the change of variables formula~\cite{Sivia2006}
	\begin{equation}
		p_Y(y) = p_X\bigl(g^{-1}(y)\bigr) \, \left| \frac{d}{dy} g^{-1}(y) \right|, \quad y \in \Omega_Y,
	\end{equation}
	where $\Omega_Y = g(\Omega_X)$ is the codomain of $Y$.
\end{definition}

\begin{example}
	\index{Example: Variance of a sum}
	Let $X\colon \Omega \to \Omega_X$ and $Y\colon\Omega \to \Omega_Y$ be continuous random variables\index{Random variable} defined on the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$. Using \dfref{def:variance} and \dfref{def:covariance}, the variance of a sum can be written
	\begin{equation}
		\begin{split}
			\operatorname{Var}_{X,Y}[X+Y] &= \mathbb{E}_{X,Y}[(X+Y-\mathbb{E}_{X,Y}[X+Y])^2]\\
			&= \mathbb{E}_X[(X-\mathbb{E}_X[X])^2]+\mathbb{E}_Y[(Y-\mathbb{E}_Y[Y])^2]\\
			&\quad+2\mathbb{E}_{X,Y}[(X-\mathbb{E}_X[X])(Y-\mathbb{E}_Y[Y])]\\
			& = \operatorname{Var}_X[X]+\operatorname{Var}_Y[Y]+2\operatorname{Cov}_{X,Y}[X,Y].
		\end{split}
	\end{equation}
\end{example}

\begin{example}
	Let $X\colon \Omega \to \Omega_X$ be a continuous random variable\index{Random variable} with probability density function\index{Probability density function} (PDF) $p_X$, defined on a probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$. Suppose 
	\begin{equation}
		\begin{split}
			Y &= g(X)\\ 
			&= aX + b,
		\end{split}
	\end{equation}
	where $a \neq 0$ and $b$ are constants. The inverse function is
	\begin{equation}
		g^{-1}(y) = \frac{y - b}{a}.
	\end{equation}
	Using \dfref{def:change_of_variables}, the PDF of $Y$ is
	\begin{equation}
		\begin{split}
			p_Y(y) &= p_X\bigl(g^{-1}(y)\bigr) \left| \frac{d}{dy} g^{-1}(y) \right| \\
			&= p_X\left(\frac{y - b}{a}\right) \left| \frac{1}{a} \right|.
		\end{split}
	\end{equation}
	Hence,
	\begin{equation}
		p_Y(y) = \frac{1}{|a|} p_X\left(\frac{y - b}{a}\right).
	\end{equation}
\end{example}

\begin{example}
	\index{Example: Variable transformation}
	Let $X\colon \Omega \to \Omega_X$ be a continuous random variable\index{Random variable} with probability density function\index{Probability density function} (PDF) $p_X$, defined on a probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$. Suppose $p_X(x) \propto \operatorname{const}$, and let
	\begin{equation}
		\begin{split}
			Y &= g(X)\\
			& = \frac{e^X}{1 + e^X}.
		\end{split}
	\end{equation}
	The inverse function is
	\begin{equation}
		g^{-1}(y) = \ln\left(\frac{y}{1-y}\right).
	\end{equation}
	Using \dfref{def:change_of_variables}, the PDF of $Y$ is
	\begin{equation}
		\begin{split}
			p_Y(y) &= p_X\bigl(g^{-1}(y)\bigr) \left| \frac{d}{dy} g^{-1}(y) \right| \\
			&= \operatorname{const} \cdot \left| \frac{d}{dy} \ln\left(\frac{y}{1-y}\right) \right| \\
			&= \operatorname{const} \cdot \frac{1}{y(1-y)}, \quad y \in (0,1).
		\end{split}
	\end{equation}
\end{example}


\begin{theorem}[Error Propagation]
	\label{theorem:error_propagation}
	\index{Error propagation}
	Let
	\begin{equation}
		X_1\colon\Omega \to \Omega_{X_1}, \dots, X_n\colon\Omega \to \Omega_{X_n}
	\end{equation}
	be continuous random variables\index{Random variable} defined on a probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$, and let
	\begin{equation}
		g\colon\Omega_{X_1} \times \dots \times \Omega_{X_n} \to \mathbb{R}
	\end{equation}
	be a differentiable function of these variables. Denote for shorthand
	\begin{equation}
		X = (X_1, \dots, X_n)
	\end{equation}
	and
	\begin{equation}
		\mathbb{E}_X[X] = (\mathbb{E}_{X_1}[X_1], \dots, \mathbb{E}_{X_n}[X_n]).
	\end{equation}
	Then the variance of $g(X)$, which quantifies the uncertainty in $g$ due to the uncertainties in $X_1, \dots, X_n$, satisfies the first-order approximation
	\begin{equation}
		\begin{split}
			\operatorname{Var}_X[g(X)] &= \sum_{i=1}^n \left(\frac{\partial g(X)}{\partial X_i}\bigg|_{X = \mathbb{E}_X[X]}\right)^{\!2} \operatorname{Var}_{X_i}[X_i]
			\\&\quad+ \sum_{i \neq j} \frac{\partial g(X)}{\partial X_i}\frac{\partial g(X)}{\partial X_j}\bigg|_{X = \mathbb{E}_X[X]} \operatorname{Cov}_{X_i,X_j}[X_i, X_j]\\
			&\quad+ \mathcal{O}(\|X - \mathbb{E}_X[X]\|^3).
		\end{split}
		\label{eq:var_approx}
	\end{equation}
\end{theorem}

\begin{proof}
	$g(X)$ can be written as a Taylor expansion\index{Taylor expansion} around $\mathbb{E}_X[X]$ as follows
	\begin{equation}
		\begin{split}
			g(X) = &g(\mathbb{E}_X[X]) + \sum_{i=1}^n  \frac{\partial g(X)}{\partial X_i} \bigg|_{X = \mathbb{E}_X[X]} (X_i - \mathbb{E}_{X_i}[X_i])\\
			& + \mathcal{O}(\|X - \mathbb{E}_X[X]\|^2).
		\end{split}
		\label{e1}
	\end{equation}
	Consequently
	\begin{equation}
		\begin{split}
			\mathbb{E}_X[g(X)] &= g(\mathbb{E}_X[X])+ \sum_{i=1}^n \frac{\partial g(X)}{\partial X_i} \bigg|_{X = \mathbb{E}_X[X]}\, \cancelto{0}{\mathbb{E}_{X_i}[X_i - \mathbb{E}_{X_i}[X_i]]}\\
			&\quad  + \mathcal{O}(\|X - \mathbb{E}_X[X]\|^2)\\
			& = g(\mathbb{E}_X[X]) + \mathcal{O}(\|X - \mathbb{E}_X[X]\|^2)\\
		\end{split}
		\label{e2}
	\end{equation}
	meaning the variance of $g$ can be approximated as follows
	\begin{equation}
		\begin{split}
			\operatorname{Var}_X[g(X)] &= \mathbb{E}_X\big[(g(X) - \mathbb{E}_X[g(X)])^2\big] \\
			&= \mathbb{E}_X\bigg[\bigg( \sum_{i=1}^n (X_i - \mathbb{E}_{X_i}[X_i]) \frac{\partial g}{\partial X_i}\bigg|_{X=\mathbb{E}_X[X]}\\
			&\qquad\qquad + \mathcal{O}(\|X - \mathbb{E}_X[X]\|^2)\bigg)^2\bigg] \\
			&= \sum_{i=1}^n \left(\frac{\partial g(X)}{\partial X_i}\bigg|_{X = \mathbb{E}_X[X]}\right)^{\!2} \operatorname{Var}_{X_i}[X_i]
			\\&\quad+ \sum_{i \neq j} \frac{\partial g(X)}{\partial X_i}\frac{\partial g(X)}{\partial X_j}\bigg|_{X = \mathbb{E}_X[X]} \operatorname{Cov}_{X_i,X_j}[X_i, X_j]\\
			&\quad+ \mathcal{O}(\|X - \mathbb{E}_X[X]\|^3).
		\end{split}
	\end{equation}
\end{proof}

\begin{remark}[Error propagation for independent Random Variables]
	\label{remark:error_prop_independent}
	Let
	\begin{equation}
		X_1\colon\Omega \to \Omega_{X_1}, \dots, X_n\colon\Omega \to \Omega_{X_n}
	\end{equation}
	be continuous random variables\index{Random variable} defined on a probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$.	If the random variables $X_1, \dots, X_n$ are independent, then according to \thref{theorem:covariance_of_independent_variables} $\mathrm{Cov}_{X_i,X_j}[X_i, X_j] = 0$ $\forall i \neq j$. In this case, \thref{theorem:error_propagation} simplifies to
	\begin{equation}
		\operatorname{Var}_{X}[g(X)] \approx \sum_{i=1}^n \left(\frac{\partial g(X)}{\partial X_i}\Big|_{X = \mathbb{E}_X[X]}\right)^2 \operatorname{Var}_{X_i}[X_i]
		\label{eq:error_prop}
	\end{equation}
	where 
	\begin{equation}
		X = (X_1, \dots, X_n)
	\end{equation}
	and
	\begin{equation}
		\mathbb{E}_X[X] = (\mathbb{E}_{X_1}[X_1], \dots, \mathbb{E}_{X_n}[X_n]).
	\end{equation}
	\EQref{eq:error_prop} is the commonly used form of the linear error-propagation formula for independent variables.
\end{remark}

\begin{example}
	\index{Example: Error propagation}
	A company produces square plates with dimensions characterized by two independent random variables\index{Normal distribution}\index{Random variable}
	\begin{equation}
		X\sim \operatorname{Norm}(2m,(0.01m)^2), \quad Y\sim \operatorname{Norm}(3m,(0.02m)^2).
	\end{equation} 
	The variance\index{Variance} of the area $XY$ can be determined exactly from \thref{theorem:error_propagation}
	\begin{equation}
		\label{eq:var1}
		\begin{split}
			\operatorname{Var}_{X,Y}[XY]&=\mathbb{E}_{X,Y}[(XY)^2]-(\mathbb{E}_{X,Y}[XY])^2\\
			&=(\operatorname{Var}_X[X]+\mathbb{E}_X[X]\bigg)\bigg(\operatorname{Var}_Y[Y]+\mathbb{E}_Y[Y])-\mathbb{E}_X[X]^2\mathbb{E}_Y[Y]^2\\
			&=\mathbb{E}_Y[Y]^2\operatorname{Var}_X[X]+\mathbb{E}_X[X]^2\operatorname{Var}_Y[Y]+\operatorname{Var}_X[X]\operatorname{Var}_Y[Y]
		\end{split}
	\end{equation}
	where \thref{theorem:expectation_independent} has been applied.	Via the linear approximation from \rmref{remark:error_prop_independent} the variance of the area can be approximated as follows
	\begin{equation}
		\label{eq:var2}
		\begin{split}
			\operatorname{Var}_{X,Y}[XY]|_{\text{linear approx.}}&\approx\sum_{i = X,Y} \bigg( \frac{\partial (XY)}{\partial i}\bigg|_{X = \mathbb{E}_X[X],Y = \mathbb{E}_Y[Y]}  \bigg)^2\operatorname{Var}_i[i]\\
			&=\mathbb{E}_Y[Y]^2\operatorname{Var}_X[X]+\mathbb{E}_X[X]^2\operatorname{Var}_Y[Y]
		\end{split}
	\end{equation}
	Comparing \EQref{eq:var1} and \EQref{eq:var2} the relative difference can be written
	\begin{equation}
		\begin{split}
			\frac{\operatorname{Var}_{X,Y}[XY]|_{\text{linear approx.}}-\operatorname{Var}_{X,Y}[XY]}{\operatorname{Var}_{X,Y}[XY]} &= -\frac{\operatorname{Var}_X[X]\operatorname{Var}_Y[Y]}{\operatorname{Var}_{X,Y}[XY]}\\
			& \simeq -1.6\cdot 10^{-5}.
		\end{split}
	\end{equation}
	
\end{example}

\begin{example}
	Consider a probability space\index{Probability space} describing two children with unknown sexes. Let
	\begin{equation}
		\Omega_{\text{child 1}} = \{\text{\Gentsroom}, \text{\Ladiesroom}\}, \quad
		\Omega_{\text{child 2}} = \{\text{\Gentsroom}, \text{\Ladiesroom}\},
	\end{equation}
	and define
	\begin{equation}
		\Omega = \Omega_{\text{child 1}} \times \Omega_{\text{child 2}} = 
		\{(\text{\Gentsroom},\text{\Gentsroom}), (\text{\Gentsroom},\text{\Ladiesroom}), (\text{\Ladiesroom},\text{\Gentsroom}), (\text{\Ladiesroom},\text{\Ladiesroom})\}.
	\end{equation}	
	Define the random variables\index{Random variable}
	\begin{equation}
		B \colon \Omega \to \{0,1,2\}, \quad G \colon \Omega \to \{0,1,2\},
	\end{equation}
	where $B(\omega)$ and $G(\omega)$ denote the number of boys and girls in outcome $\omega \in \Omega$.  
	The joint probability mass function of $(B,G)$ is, by \dfref{def:prob_density_general},
	\begin{equation}
		p_{B,G}(b,g) = \mathbb{P}_{B,G}(\{(b,g)\}) = \mathbb{P}(\{\omega \in \Omega | B(\omega) = b,\, G(\omega) = g\}).
	\end{equation}
	For instance,
	\begin{equation}
		p_{B,G}(1,1) = \mathbb{P}(\{(\text{\Gentsroom},\text{\Ladiesroom}), (\text{\Ladiesroom},\text{\Gentsroom})\}) = \frac{1}{2}.
	\end{equation}
	Let $A \subseteq \Omega_B \times \Omega_G$ denote the event ``at least one boy'':
	\begin{equation}
		A = \{(b,g) \in \Omega_B \times \Omega_G \mid b \ge 1\}.
	\end{equation}
	Using \dfref{def:conditional_probability} the conditional probability of exactly one girl given at least one boy is (see \rmref{remark:pmf_vs_measure})
	\begin{equation}
		\mathbb{P}_{B,G}(\{(1,1)\} \mid A) = \frac{\mathbb{P}_{B,G}(\{(1,1)\} \cap A)}{\mathbb{P}_{B,G}(A)}.
	\end{equation}
	From the PMF,
	\begin{equation}
		\mathbb{P}_{B,G}(\{(1,1)\} \cap A) = p_{B,G}(1,1) = \frac{1}{2},
	\end{equation}
	and from \thref{theorem:law_of_total_probability}
	\begin{equation}
		\mathbb{P}_{B,G}(A) = \sum_{g} \sum_{b \ge 1} p_{B,G}(b,g) = p_{B,G}(1,1) + p_{B,G}(2,0) = \frac{1}{2} + \frac{1}{4} = \frac{3}{4}.
	\end{equation}
	Hence,
	\begin{equation}
		\mathbb{P}_{B,G}(\{(1,1)\} \mid A) = \frac{2}{3}.
	\end{equation}
\end{example}


\begin{remark}[PMF vs. image measure on events]
	\label{remark:pmf_vs_measure}
	Let $B$ and $G$ be discrete random variables with joint PMF\index{Probability mass function} $p_{B,G}$ and image measure\index{Image measure} $\mathbb{P}_{B,G}$. From \dfref{def:prob_density_general}, the PMF is defined only for single points $(b,g) \in \Omega_B \times \Omega_G$:
	\begin{equation}
		p_{B,G}(b,g) = \mathbb{P}_{B,G}(\{(b,g)\}).
	\end{equation}
	The image measure $\mathbb{P}_{B,G}$, however, is defined on all measurable subsets in the event space\index{Event space} $A \in \mathcal{F}_B\otimes\mathcal{F}_G$. Hence, expressions of the form
	\begin{equation}
		\mathbb{P}_{B,G}(\{(b,g)\} \cap A)
	\end{equation}
	are valid, since $\{(b,g)\} \cap A$ is an element of $\mathcal{F}_B\otimes\mathcal{F}_G$. In contrast, writing
	\begin{equation}
		p_{B,G}(b,g \cap A)
	\end{equation}
	(or similarly) is not valid, because $p_{B,G}$ is defined only on individual points $(b,g)$, not on sets or intersections. The PMF cannot take an event as its argument; only the image measure $\mathbb{P}_{B,G}$ can.
\end{remark}




\begin{example}
	\index{Example: Prosecutor}
	Suppose a crime has been committed. Blood is found at the crime scene for which there is no innocent explanation. It is of the type that is present in $1\%$ of the population. Let $E$ denote the event that a person has the blood type found at the crime scene. Then
	\begin{equation}
		\mathbb{P}(E) = 0.01.
		\label{eq:proseca}
	\end{equation}
	The prosecutor claims: ``There is a $1\%$ chance that the defendant would have the blood type found at the crime scene if he were innocent. Thus, there is a $99\%$ chance that he is guilty.'' This is known as the prosecutor's fallacy. What is wrong with this argument?\newline
	
	The prosecutor's claim can be written as
	\begin{equation}
		\mathbb{P}(E \mid \operatorname{innocent}) = 0.01 \Rightarrow \mathbb{P}(\operatorname{guilty} \mid E) = 0.99.
		\label{eq:prosec1}
	\end{equation}		
	
	To investigate this claim, use \thref{theorem:bayes_theorem} to write
	\begin{equation}
		\begin{split}
			\mathbb{P}(E \mid \operatorname{innocent}) &= \frac{\mathbb{P}(E \cap \operatorname{innocent})}{\mathbb{P}(\operatorname{innocent})} \\
			&= \frac{\mathbb{P}(\operatorname{innocent} \mid E)}{\mathbb{P}(\operatorname{innocent})} \mathbb{P}(E).
		\end{split}
	\end{equation}
	Hence, in general, $\mathbb{P}(E \mid \operatorname{innocent}) \neq \mathbb{P}(E)$. Suppose there are $N$ people in the world, and $M \leq N$ of these have the blood type found at the crime scene. In that case,
	\begin{equation}
		\frac{\mathbb{P}(\operatorname{innocent} \mid E)}{\mathbb{P}(\operatorname{innocent})} = \frac{\frac{M-1}{M}}{\frac{N-1}{N}},
	\end{equation}
	which approaches $1$ in the limit $N,M \rightarrow \infty$. Hence, $\mathbb{P}(E \mid \operatorname{innocent}) \simeq \mathbb{P}(E)$ can be a good approximation, but it is not an exact relation.\newline 
	Assuming $\mathbb{P}(E \mid \operatorname{innocent}) = 0.01$, the prosecutor's claim can be further analyzed using \dfref{def:conditional_probability}, as follows
	\begin{equation}
		\mathbb{P}(\operatorname{guilty} \mid E) + \mathbb{P}(\operatorname{innocent} \mid E) = \frac{\mathbb{P}(\operatorname{guilty} \cap E) + \mathbb{P}(\operatorname{innocent} \cap E)}{\mathbb{P}(E)}.
	\end{equation}
	Innocent and guilty are complementary events that form a partition of the sample space, meaning (\thref{theorem:law_of_total_probability})
	\begin{equation}
		\mathbb{P}(\operatorname{guilty} \cap E) + \mathbb{P}(\operatorname{innocent} \cap E) = \mathbb{P}(E),
	\end{equation}
	and thereby
	\begin{equation}
		\mathbb{P}(\operatorname{guilty} \mid E) + \mathbb{P}(\operatorname{innocent} \mid E) = 1.
	\end{equation}
	This means that if $\mathbb{P}(\operatorname{guilty} \mid E) = 0.99$, then $\mathbb{P}(\operatorname{innocent} \mid E) = 0.01$, and from \thref{theorem:bayes_theorem},
	\begin{equation}
			\mathbb{P}(\operatorname{innocent} \mid E) = \frac{\mathbb{P}(E \mid \operatorname{innocent}) \, \mathbb{P}(\operatorname{innocent})}{\mathbb{P}(E)}
		\label{eq:prosec}
	\end{equation}
	From \EQref{eq:prosec}, it is clear that in general
	\begin{equation}
		\mathbb{P}(E \mid \operatorname{innocent}) \neq \mathbb{P}(\operatorname{innocent} \mid E),
	\end{equation}
	and so even if $\mathbb{P}(E \mid \operatorname{innocent}) = 0.01$, the prosecutor's claim (\EQref{eq:prosec1}) is not true.
\end{example}

\begin{example}
	\index{Example: Bad news from the doctor}
	After your yearly checkup, the doctor has bad news and good news. The bad news is that you tested positive for a serious disease, and that the test is $99\%$ accurate (i.e. the probability of testing positive given that you have the disease is $99\%$, as is the probability of testing negative given that you don't have the disease). The good news is that this is a rare disease, striking only one in $10\,000$ people. What are the chances that you actually have the disease?\newline
	
	Let "s" denote the event of being sick, "h" the event of being healthy, "p" the event of a positive test and "n" the event of a negative test. Using \thref{theorem:bayes_theorem} and \thref{theorem:law_of_total_probability}
	\begin{equation}
		\begin{split}
			\mathbb{P}(\text{s}|\text{p}) &= \frac{\mathbb{P}(\text{p}|\text{s})\mathbb{P}(\text{s})}{\mathbb{P}(\text{p})}\\
			&= \frac{\mathbb{P}(\text{p}|\text{s})\mathbb{P}(\text{s})}{\mathbb{P}(\text{p}|\text{s})\mathbb{P}(\text{s})+\mathbb{P}(\text{p}|\text{h})\mathbb{P}(\text{h})}\\
		\end{split}
	\end{equation}
	where $\mathbb{P}(\text{p}|\text{s}) = 0.99$, $\mathbb{P}(s) = \frac{1}{10\, 000}$, $\mathbb{P}(\text{p}|\text{h})=1-\mathbb{P}(\text{n}|\text{h})$, $\mathbb{P}(\text{n}|\text{h})=0.99$ and $\mathbb{P}(\text{h})=1-\mathbb{P}(\text{s})$. This means
	\begin{equation}
		\mathbb{P}(\text{s}|\text{p}) \simeq 0.0098.
	\end{equation}		
\end{example}

\begin{example}
	\index{Example: Gameshow}
	On a game show, a contestant is told the rules as follows: There are $3$ doors labeled $1,2,3$. A single prize has been hidden behind one of them. You get to select one door. Initially your chosen door will not be opened, instead, the gameshow host will open one of the other two doors in such a way as not to reveal the prize. For example, if you first choose door $1$, the gameshow host will open one of doors $2$ and $3$, and it is guaranteed that he will choose which one to open so that the prize will not be revealed. At this point you will be given a fresh choice of door: You can either stick with your first choice, or you can switch to the other closed door. All the doors will then be opened and you will receive whatever is behind your final choice of door.\newline
	Imagine that the contestant chooses first door $1$; then the gameshow host opens door $3$, revealing nothing. Should the contestant a) stick with door $1$, b) switch to door $2$ or c) it does not matter? You may assume that initially, the prize is equally likely to be behind any of the $3$ doors. \newline
	
	Let $z_i$ denote the prize being behind the $i$'th door, $o_i$ the action of opening the $i$'th door and $c_i$ the action of choosing the $i$'th door. The door with the largest probability of containing the prize should be picked, meaning
	\begin{equation}
		z^*=\argmax_z(\mathbb{P}(z|o_3 \cap c_1)).
	\end{equation}
	Since the host cannot open the door containing the prize, 
	\begin{equation}
		\mathbb{P}(z_3|o_3 \cap c_1)=0
	\end{equation}
	 and only $\mathbb{P}(z_1|o_3 \cap c_1)$ and $\mathbb{P}(z_2|o_3 \cap c_1)$ will have to be considered. Using \thref{theorem:bayes_theorem}
	\begin{equation}
		\mathbb{P}(z_1|o_3 \cap c_1) = \frac{\mathbb{P}(o_3|c_1 \cap z_1)\mathbb{P}(c_1 \cap z_1)}{\mathbb{P}(o_3 \cap c_1)}
	\end{equation}
	where from \thref{theorem:law_of_total_probability}
	\begin{equation}
		\begin{split}
			\mathbb{P}(o_3 \cap c_1)&=\sum_i\mathbb{P}(o_3 \cap c_1 \cap z_i)\\
			&=\mathbb{P}(o_3 \cap c_1 \cap z_1)+\mathbb{P}(o_3 \cap c_1 \cap z_2)+\mathbb{P}(o_3 \cap c_1 \cap z_3)\\
			&= \mathbb{P}(o_3|c_1 \cap z_1)\mathbb{P}(c_1 \cap z_1)+\mathbb{P}(o_3|c_1 \cap z_2)\mathbb{P}(c_1 \cap z_2)\\
			&\quad+\mathbb{P}(o_3|c_1 \cap z_3)\mathbb{P}(c_1 \cap z_3).
		\end{split}
	\end{equation}
	$\mathbb{P}(o_3|c_1 \cap z_3)=0$ since the host will not open the door with the prize. $p(o_3|c_1 \cap z_2)=1$ since the host has no other option in this case. $\mathbb{P}(o_3|c_1 \cap z_1)=\frac{1}{2}$ since the host has two options in this case. There is no connection between the choice of door and position of the prize, so $\mathbb{P}(c_1 \cap z_j)=\mathbb{P}(c_1)\mathbb{P}(z_j)$ and initially $\mathbb{P}(z_j)=\mathbb{P}(z_k)$ $\forall j,k\in \{1,2,3\}$. Hence
	\begin{equation}
		\begin{split}
			\mathbb{P}(z_1|o_3 \cap c_1) &= \frac{\mathbb{P}(o_3|c_1 \cap z_1)}{\sum_i\mathbb{P}(o_3|c_1 \cap z_i)}\\
			&=\frac{1}{3}.
		\end{split}
	\end{equation}
	Similarly
	\begin{equation}
		\begin{split}
			\mathbb{P}(z_2|o_3 \cap c_1) &= \frac{\mathbb{P}(o_3|c_1 \cap z_2)}{\sum_i\mathbb{P}(o_3|c_1 \cap z_i)}\\
			&=\frac{2}{3}.
		\end{split}
	\end{equation}
	Since $\mathbb{P}(z_2|o_3 \cap c_1)>\mathbb{P}(z_1|o_3 \cap c_1)>\mathbb{P}(z_3|o_3 \cap c_1)$, door number $2$ is the optimal choise. Hence,answer "b)" is correct. The intuition behind the answer is the information the contestant has at the time of making the decision; initially, there is no a priori information and so $\mathbb{P}(z_1|o_3 \cap c_1)=\frac{1}{3}$. At this time, there is $\frac{2}{3}$ probability that the prize is behind doors $2,3$. When the gameshow host open door $3$, this probability converge on door $2$.
\end{example}

\begin{example}
	\index{Example: Correlation coefficient}
	\index{Probability density function}
	Let $X\colon\Omega \to \Omega_X$ and $Y\colon\Omega\to \Omega_Y$ be continuous random variables\index{Random variable} defined on the probability space\index{Probability space} $(\Omega,\mathcal{F},\mathbb{P})$ and suppose $X\sim \operatorname{Unif}(a=-1, b=1)$ and $Y=X^2$. Clearly $Y$ is dependent on X (in fact Y is uniquely determined by X). Show that $\operatorname{Corr}_{X,Y}[X,Y]=0$.\newline
	
	Since $Y=X^2$ is uniquely determined by $X$,\index{Expected value}\index{Correlation}\index{Covariance}\index{Variance}
	\begin{equation}
		\operatorname{Corr}_{X,Y}[X,Y] = \operatorname{Corr}_{X}[X,X^2].
	\end{equation}
	Using \dfref{def:correlation} and \dfref{def:covariance}
	\begin{equation}
		\begin{split}
			\operatorname{Corr}_{X}[X,X^2] & = \frac{\operatorname{Cov}_{X}[X,X^2]}{\sqrt{\operatorname{Var}_X[X]\operatorname{Var}_X[X^2]}}\\
			& = \frac{\mathbb{E}_{X}[X^3]-\mathbb{E}_X[X]\mathbb{E}_X[X^2]}{\sqrt{\operatorname{Var}_X[X]\operatorname{Var}_X[X^2]}}\\
		\end{split}
	\end{equation}
	In this case for the nominator\index{Covariance}\index{Expected value}\index{Variance}
	\begin{equation}
		\begin{split}
			\operatorname{Cov}_{X}[X,X^2] &= \int_{\Omega_X} x^3 p_X(x) \mathrm{d}x-\int_{\Omega_X} x'p_X(x') \mathrm{d}x'\int_{\Omega_X} x''^2p_X(x'') \mathrm{d}x''\\
			&= \frac{1}{b-a}\int_{a}^{b}x^3\mathrm{d}x-\frac{1}{(b-a)^2}\int_{a}^{b} x' \mathrm{d}x'\int_{a}^{b} x''^2 \mathrm{d}x''\\
			&= \frac{1}{12}(a-b)^2(a+b)\\
			&=0
		\end{split}
	\end{equation}
	where the last equality comes from the fact that $a+b = 0$ in this case. However, we need to make sure the denominator does not diverge
	\begin{equation}
		\begin{split}
			\operatorname{Var}_X[X]\operatorname{Var}_X[X^2] & =\big(\mathbb{E}_X[X^2]-\mathbb{E}_X[X]^2\big) \big(\mathbb{E}_X[X^4]-\mathbb{E}_X[X^2]^2\big)\\
			& = \frac{1}{540}(b-a)^4(4a^2+7ab+4b^2)\\
			&\neq 0.
		\end{split}
	\end{equation}
	It denominator does not diverge, so the factorized $a+b$ from the nominator makes $\operatorname{Corr}_{X}[X,X^2]=0$.
\end{example}

\begin{example}
	\index{Example: Correlation coefficient}
	Let $X\sim \operatorname{Norm}(\mu =0, \sigma^2 = 1)$ and $Y = WX$, where W is a discrete random variable\index{Random variable} defined by the PMF\index{Probability mass function} $p_W(-1)=p_W(1)=\frac{1}{2}$. It is clear that X and Y are not independent, since Y is a function of X.
	\begin{enumerate}
		\item Show $Y\sim \operatorname{Norm}(\mu =0, \sigma^2 = 1)$.\newline
		
		To show that $Y\sim \operatorname{Norm}(\mu =0, \sigma^2 = 1)$, show that Y has zero mean and unity variance.\index{Variance}\index{Expected value}
		\begin{equation}
			\begin{split}
				\mathbb{E}_Y[Y] &= \mathbb{E}_{W,X}[WX]\\
				&=\mathbb{E}_W[W]\cancelto{0}{\mathbb{E}_X[X]}\\
				&=0.
			\end{split}
		\end{equation}
		The variance
		\begin{equation}
			\begin{split}
				\operatorname{Var}_Y[Y] &= \mathbb{E}_Y[Y^2]-\cancelto{0}{\mathbb{E}_Y[Y]^2}\\
				& = \mathbb{E}_{W,X}[W^2X^2]\\
				&= \mathbb{E}_W[W^2]\mathbb{E}_X[X^2]\\
				& = \mathbb{E}_W[W^2]\operatorname{Var}_X[X]
			\end{split}
		\end{equation}
		since $\operatorname{Var}_X[X]=\mathbb{E}_X[X^2]-\cancelto{0}{\mathbb{E}_X[X]^2}=1$. Now
		\begin{equation}
			\begin{split}
				\mathbb{E}_W[W^2]&= \frac{1}{n}\sum_{i=1}^nw_i^2p_W(w_i)\\
				&= \frac{1}{2}[(-1)^2\frac{1}{2}+1^2\frac{1}{2}]\\
				&= 1
			\end{split}
		\end{equation}
		so $\operatorname{Var}_Y[Y] =1$.
		\item Show $\operatorname{Cov}_{X,Y}[X,Y]=0$. Thus X and Y are uncorrelated but dependent, even though they are Gaussian.\index{Covariance}\index{Expected value}
		
		\begin{equation}
			\begin{split}
				\operatorname{Cov}_{X,Y}[X,Y] &= \operatorname{Cov}_{X,W}[X,WX] \\
				&= \mathbb{E}_{X,W}[WX^2]-\mathbb{E}_X[X]\mathbb{E}_{X,W}[WX]\\
				&= \mathbb{E}_W[W]\mathbb{E}_X[X^2]-\mathbb{E}_W[W]\mathbb{E}_X[X]^2\\
				&= \mathbb{E}_W[W]\operatorname{Var}_X[X]\\
				& = 0
			\end{split}
		\end{equation}
		where for the last equality it has been used that
		\begin{equation}
			\begin{split}
				\begin{split}
					\mathbb{E}_W[W]&= \frac{1}{n}\sum_{i=1}^nw_ip_W(w_i)\\
					&= \frac{1}{2}[(-1)\frac{1}{2}+1\frac{1}{2}]\\
					&= 0
				\end{split}
			\end{split}
		\end{equation}
		
	\end{enumerate}
	
\end{example}

\begin{example}
	\index{Example: Correlation coefficient}	
	According to \dfref{def:variance} the variance\index{Variance}\index{Correlation} is defined as positive definite. This means
	\begin{equation}
		\label{eq:corr_deriv}
		\begin{split}
			0\leq& \operatorname{Var}_{X,Y}\bigg[\frac{X}{\sqrt{\operatorname{Var}_{X}[X]}}\pm\frac{Y}{\sqrt{\operatorname{Var}_{Y}[Y]}}\bigg]\\
			& = \frac{\operatorname{Var}_X[X]}{\operatorname{Var}_{X}[X]}+\frac{\operatorname{Var}_Y[Y]}{\operatorname{Var}_{Y}[Y]}\pm \frac{2}{\sqrt{\operatorname{Var}_{X}[X]\operatorname{Var}_{Y}[Y]}}\operatorname{Cov}_{X,Y}[X,Y]\\
			& = 2\pm 2\operatorname{Corr}_{X,Y}[X,Y].
		\end{split}
	\end{equation}
	 From \EQref{eq:corr_deriv} the result follows
	\begin{equation}
		-1\leq \operatorname{Corr}_{X,Y}[X,Y]\leq 1.
	\end{equation}	
\end{example}

\begin{example}
	\index{Example: Correlation coefficient}
	Let $X:\Omega\to \Omega_X$ be a continuous random variable defined on the probability space $(\Omega,\mathcal{F},\mathbb{P})$ and suppose	$Y=aX+b$ given parameters $a>0$ and $b$. Since $Y$ is uniquely determined by $X$,
	\begin{equation}
		\operatorname{Corr}_{X,Y}[X,Y] = \operatorname{Corr}_{X}[X,aX+b].
	\end{equation}
	Using \dfref{def:correlation} and \dfref{def:covariance}\index{Variance}\index{Covariance}\index{Expected value}
	\begin{equation}
		\operatorname{Corr}_{X}[X,aX+b] = \frac{\operatorname{Cov}_{X}[X,aX+b]}{\sqrt{\operatorname{Var}_X[X]\operatorname{Var}_X[aX+b]}}
		\label{eq:corra}
	\end{equation}
	with
	\begin{equation}
		\begin{split}
			\operatorname{Cov}_{X}[X,aX+b] & = \mathbb{E}_{X}[X(aX+b)]-\mathbb{E}_X[X]\mathbb{E}_X[aX+b]\\
			&= a\mathbb{E}_X[X^2]+b\mathbb{E}_X[X]-a\mathbb{E}_X[X]^2-b\mathbb{E}_X[X]\\
			&=a\operatorname{Var}_X[X]
		\end{split}
		\label{eq:corrb}
	\end{equation}
	and
	\begin{equation}
		\begin{split}
			\operatorname{Var}_X[aX+b] &= a^2\operatorname{Var}_X[X]+\cancelto{0}{\operatorname{Var}_X[b]}+2\cancelto{0}{\operatorname{Cov}_{X,X}[aX,b]}\\
			& = a^2\operatorname{Var}_X[X].
		\end{split}
		\label{eq:corrc}
	\end{equation}
	Combining \EQref{eq:corra}, \EQref{eq:corrb} and \EQref{eq:corrc} yields
	\begin{equation}
		\begin{split}
			\operatorname{Corr}_{X}[X,aX+b] &= \frac{a\operatorname{Var}_X[X]}{\sqrt{a^2\operatorname{Var}_X[X]\operatorname{Var}_X[X]}}\\
			&=\frac{a}{|a|}.
		\end{split}
	\end{equation}
\end{example}

