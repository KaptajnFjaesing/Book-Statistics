\chapter{Introduction to Probability Theory}
\label{chp:probaiblity_theory}
Probability theory provides a mathematical framework for analyzing random experiments, where outcomes cannot be predicted with certainty in advance. Its objective is to systematically study and understand the possible outcomes of such experiments.
\begin{definition}[Sample Space]
	The sample space\index{Sample space}, denoted by $\Omega$, represents the set of all possible outcomes of a random experiment. It encompasses every conceivable result that could occur, serving as the foundation for analyzing probabilities associated with different outcomes.
\end{definition}

\begin{definition}[Event]
	An event\index{Event}, $E$, is a subset of the sample space, denoted by $E \subseteq \Omega$, that corresponds to a specific collection of possible outcomes in a random experiment. Events may consist of single or multiple outcomes and are defined by the occurrence or non-occurrence of particular conditions.
\end{definition}

\begin{example}
	\label{ex:die1}
	Consider the roll of a fair six-sided die. The sample space for this experiment is given by $\Omega = \{ \epsdice{1}, \epsdice{2}, \epsdice{3}, \epsdice{4}, \epsdice{5}, \epsdice{6} \}$. $E = \{\epsdice{2}, \epsdice{4}, \epsdice{6}\}$, is the event of rolling an even number. 
\end{example}

\begin{definition}[Event Space]
	The set containing all valid possible events for a random experiment is referred to as the event space\index{Event space}, $\mathcal{F}$. The notion of "all valid possible events for a random experiment" is formally defined by requiring $\mathcal{F}$ to be a $\sigma$-algebra satisfying the following properties:
	\begin{enumerate}
		\item $\mathcal{F}$ is the set of all subsets of the sample space $\Omega$, including the empty set $\emptyset$ and $\Omega$ itself, along with various combinations of outcomes.
		\item Closure under complementation: If $E$ is in the $\sigma$-algebra ($E \in \mathcal{F}$), then its complement $E^c$ is also in the $\sigma$-algebra.
		\item Closure under countable union and intersection: If the events $E_1, E_2, \dots$ are in the $\sigma$-algebra ($E_i \in \mathcal{F}$ for all $i$), then their countable union $\bigcup_{i=1}^{\infty} E_i$ and intersection $\bigcap_{i=1}^{\infty} E_i$ are also in the $\sigma$-algebra.
	\end{enumerate}
	In the case where the outcomes of the random experiment can take discrete values, these properties are sufficient. However, in the case where the outcomes are continuous, $\mathcal{F}$ is required to be a Borel $\sigma$-algebra, meaning it must further fulfill the closure property under countable intersection with open sets. This ensures that $\mathcal{F}$ contains all sets that can be formed by taking unions, intersections, and complements of open sets, which are essential for defining probabilities in continuous spaces.
\end{definition}


\begin{example}
	\label{ex:die2}
	For the roll with the fair die considered in \exref{ex:die1}, the sample space is $\Omega = \{ \epsdice{1}, \epsdice{2}, \epsdice{3}, \epsdice{4}, \epsdice{5}, \epsdice{6} \}$ and the event space (the set of all possible events) is given by
	\begin{equation}
		\begin{split}
			\mathcal{F}&=\{\emptyset, \{\epsdice{1}\},\{\epsdice{1},\epsdice{3}\},\{\epsdice{3}\},\{\epsdice{1},\epsdice{2},\epsdice{3},\epsdice{4}\},\{\epsdice{5}\},\dots\}\\
			& = 2^\Omega.
		\end{split}
	\end{equation}
\end{example}

\begin{definition}[Measurable Space]
	\label{def:measurable_space}
	The pair \( (\Omega, \mathcal{F}) \) is called a measurable space.
\end{definition}

Probability can loosely be defined~\cite{chan2021introduction} as a measure of the size of an event (a set) relative to the sample space (another set), meaning it is a function that operates on an event (a set). In particular the probability measure maps any valid event, i.e. any $E\in \mathcal{F}$, to a number between $0$ and $1$, representing the relative size of the event to the sample space.

\begin{definition}[Probability Measure]
	\label{def:probability}
	A Probability measure\index{Probability Measure}, $\mathbb{P}$, is a set function \index{Set function} defined on a measurable space (\dfref{def:measurable_space}) $(\Omega, \mathcal{F})$
	\begin{equation}
		\mathbb{P}: \mathcal{F} \mapsto [0,1]
	\end{equation}
	that obey~\cite{kolmogorov1950foundations} \axref{ax:non_neg}-\axref{ax:add}\index{Axioms of probability theory}.
\end{definition}

\begin{axiom}[Non-negativity]
	\label{ax:non_neg}
	For any event $E\in \mathcal{F}$, the probability measure $\mathbb{P}(E)$ is non-negative, satisfying
	\begin{equation}
		\mathbb{P}(E) \geq 0 \quad \forall E \in  \mathcal{F}.
	\end{equation}
\end{axiom}

\begin{axiom}[Normalization]
	\label{ax:norm}
	The probability of the universal set $\Omega$ is 1, satisfying
	\begin{equation}
		\mathbb{P}(\Omega) = 1.
	\end{equation}
\end{axiom}

\begin{axiom}[Additivity]
	\label{ax:add}
	For any countable sequence of mutually exclusive events $\mathit{E}_1, \mathit{E}_2, \ldots\in \mathcal{F}$, the probability of their union is the sum of their individual probabilities, such that
	\begin{equation}
		\mathbb{P}\left(\bigcup_{i=1}^{\infty} \mathit{E}_i\right) = \sum_{i=1}^{\infty} \mathbb{P}(\mathit{E}_i) \quad \forall \mathit{E}_i \in \mathcal{F} \text{ where } \bigcap_{i=1}^{\infty} \mathit{E}_i = \emptyset.
	\end{equation}
\end{axiom}
Together, the probability measure, the sample space and the algebra form the tuple $(\Omega, \mathcal{F}, \mathbb{P})$ which define what a probability space\index{Probability space}. The non-negativity and normalization axioms are largely matters of convention, although it is non-trivial that probability measures take at least the two values $0$ and $1$, and that they have a maximal value (unlike various other measures, such as length, volume, and so on, which are unbounded). The axioms are supplemented by two definitions.

\begin{definition}[Conditional Probability]
	\label{def:conditional_probability}
	For events $E_1$ and $E_2$ in a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ with $\mathbb{P}(E_2) > 0$, the conditional probability\index{Conditional probability} of $E_1$ given $E_2$ is defined viz
	\begin{equation}
		\mathbb{P}(E_1|E_2) \equiv \frac{\mathbb{P}(E_1, E_2)}{\mathbb{P}(E_2)},
		\label{eq:cond}
	\end{equation}
	where $\mathbb{P}(E_1,E_2)= \mathbb{P}(E_1\cap E_2)$ to ease the notation.
\end{definition}
\begin{definition}[Independence]
	\label{def:independence}
	Events $E_1$ and $E_2$  in a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ are said to be independent if
	\begin{equation}
		\mathbb{P}(E_1,E_2) = \mathbb{P}(E_1) \mathbb{P}(E_2).
		\label{eq:ind}
	\end{equation}
\end{definition}

\begin{definition}[Conditional Independence]
\label{def:conditional_independence}
Events $E_1$ and $E_2$ are conditionally independent given $E_3$ if
\begin{equation}
\mathbb{P}(E_1, E_2 | E_3) = \mathbb{P}(E_1|E_3)\mathbb{P}(E_2|E_3).
\end{equation}
\end{definition}


From \axref{ax:non_neg}-\axref{ax:add}, \dfref{eq:cond} and \dfref{eq:ind}, the chain rule, the concept of marginalization, conditional independence and the law of total probability can be derived. 
\begin{theorem}[Chain Rule]
	\label{theorem:chain_rule}
	Given $\{E_1, E_2, \ldots, E_n\}\subseteq \mathcal{F}$ denotes a set of events in a probability space $(\Omega, \mathcal{F}, \mathbb{P})$, the chain rule\index{Chain rule} for this set of events can be written
	\begin{equation}
		\begin{split}
			\mathbb{P}(E_1, \dots E_n) = \mathbb{P}(E_1)\prod_{j=2}^{n}\mathbb{P}(E_j|E_1,\dots E_{j-1}).
		\end{split}
		\label{eq:prod}
	\end{equation}
\end{theorem}
\begin{proof}
	From the definition of conditional probability in \EQref{eq:cond}
	\begin{equation}
		\mathbb{P}(E_1, E_2, \ldots, E_n) = \mathbb{P}(E_1|E_2, \dots, E_n)\mathbb{P}(E_2, \dots, E_n).
		\label{eq:p1}
	\end{equation}
	Using the definition of conditional probability again
	\begin{equation}
		\mathbb{P}(E_2, \ldots, E_n) = \mathbb{P}(E_2| \ldots, E_n)\mathbb{P}(\dots, E_n).
	\end{equation}
	Continuing in this way, \EQref{eq:prod} follows.
\end{proof}
\EQref{eq:prod} illustrates how to decompose the joint probability of multiple events into a product of conditional probabilities. The idea is to calculate the probability of each event in the sequence conditioned on the occurrence of the previous events in the chain. The chain rule is particularly powerful when dealing with complex systems where events may be interdependent. It allows breaking down joint probabilities into more manageable conditional probabilities, making it easier to analyze and model intricate relationships between events. Whether in the context of statistical modeling or machine learning, the chain rule plays a key role in calculating the joint probability of multiple events and provides a foundation for more advanced probabilistic reasoning.

\begin{theorem}[Bayes theorem]
	\label{theorem:bayes_theorem}
	For events $E_1,E_2,E_3 \in \mathcal{F}$ in a probability space $(\Omega, \mathcal{F}, \mathbb{P})$, Bayes theorem\index{Bayes theorem} can be formulated viz
	\begin{equation}
		\mathbb{P}(E_1| E_2,E_3) = \frac{\mathbb{P}(E_2| E_1,E_3)\mathbb{P}(E_1,E_2)}{\mathbb{P}(E_2,E_3)}.
		\label{bayes_theorem}
	\end{equation}
\end{theorem}

\begin{proof}
	Bayes theorem follows directly from applying the chain rule and applying the concept of symmetry viz
	\begin{equation}
		\begin{split}
			\mathbb{P}(E_1,E_2,E_3) &= \mathbb{P}(E_1| E_2,E_3)\mathbb{P}(E_2,E_3) \\
			& = \mathbb{P}(E_2|E_1,E_3)\mathbb{P}(E_1,E_3)
		\end{split}
		\label{eq:c2}
	\end{equation}
	from which
	\begin{equation}
		\mathbb{P}(E_1| E_2,E_3) = \frac{\mathbb{P}(E_2| E_1,E_3)\mathbb{P}(E_1,E_2)}{\mathbb{P}(E_2,E_3)}
	\end{equation}
	which is Bayes theorem.
\end{proof}


\begin{theorem}[Law of Total Probability]
	\label{theorem:law_of_total_probability}
	Let $\{E_1,E_2,\dots E_n\}$ be a partition\index{Marginalization}\index{Law of Total Probability} of the sample space $\Omega$ of the probability space $(\Omega, \mathcal{F}, \mathbb{P})$, then for any $A\subseteq \Omega$,
	\begin{equation}
		\mathbb{P}(A) = \sum_{i} \mathbb{P}(A,E_i).
		\label{eq:marg}
	\end{equation}
	In continuous cases, the summation is replaced by integration.
\end{theorem}

\begin{proof}
	Consider an event $A\subseteq \Omega$ and a partition $\{E_1,E_2,\dots E_n\}$ of $\Omega$ such that $\cup_{i}E_i=\Omega$. For mutually exclusive events (which a partition by definition is), finite additivity can be used such that
	\begin{equation}
		\sum_{i}\mathbb{P}(A,E_i) = \mathbb{P}\bigg(\bigcup_{i}(A,E_i)\bigg).
		\label{eq:qq1}
	\end{equation} 
	$\bigcup_{i}(A,E_i)$ is the union of all intersections between $A$ and the $E$'s. However, since the $E$'s form a partition of $\Omega$, they together form $\Omega$ and the intersection between $\Omega$ and $A$ is $A$, meaning
	\begin{equation}
		\begin{split}
			\bigcup_{i}(A,E_i)  &= (A,\bigcup_{i}E_i)\\
			&= (A,\Omega)\\
			& =A.
		\end{split}
	\label{eq:qq2}
	\end{equation}
	Combining \EQref{eq:qq1}-\EQref{eq:qq2} then yields
	\begin{equation}
		\mathbb{P}(A) = \sum_{i} \mathbb{P}(A, E_i).
	\end{equation}
	
\end{proof}

\begin{example}
	\index{Example: Fair die}
	Consider the roll of a fair six-sided die. The sample space for this experiment is given by $\Omega = \{ \epsdice{1}, \epsdice{2}, \epsdice{3}, \epsdice{4}, \epsdice{5}, \epsdice{6} \}$. Let $E_1 = \{\epsdice{2}, \epsdice{4}, \epsdice{6}\}$ and $E_2 = \{\epsdice{4}\}$ be two events, then from \EQref{eq:cond}
	\begin{equation}
		\begin{split}
			\mathbb{P}(E_1|E_2) &= \frac{\mathbb{P}(E_1, E_2)}{\mathbb{P}(E_2)}\\
			& = 1
		\end{split}
	\end{equation}
	where $\mathbb{P}(E_1,E_2)= \frac{1}{6}$ since $E_1,E_2 = E_1\cap E_2 = E_2=\{\epsdice{4}\}$ is one of $6$ possible values and $\mathbb{P}(E_2) = \frac{1}{6}$. Intuitively this makes sense because $E_2$ is a set with one member and since $E_2$ is known, the outcome of the experiment is known with certainty in this case.
\end{example}

\begin{definition}[Random Variable]
	\label{def:random_Variable}
	\index{Random variable}
	A random variable $X$ is a function
	\begin{equation}
		X: \Omega \mapsto \Omega_X
	\end{equation}
	that maps outcomes from a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space $(\Omega_X, \mathcal{F}_X)$, where $\Omega_X$ is the codomain of $X$ and $\mathcal{F}_X$ is a $\sigma$-algebra on $\Omega_X$. The $\sigma$-algebra $\mathcal{F}_X$ ensures that $X$ is measurable, meaning that for any set $B \in \mathcal{F}_X$, the preimage $X^{-1}(B)$ must belong to $\mathcal{F}$. Formally, this can be written as
	\begin{equation}
		X^{-1}(B) = \{\omega \in \Omega | X(\omega) \in B\} \in \mathcal{F} \quad \forall B \in \mathcal{F}_X.
	\end{equation}
	Random variables are classified as either discrete or continuous, based on the discrete or continuous nature of their sample space. Discrete random variables have countable sample spaces, while continuous random variables have uncountable sample spaces, often modeled as intervals on the real line. The role of random variables is to provide a numerical representation of the outcomes of a random experiment, allowing quantification and analysis of the likelihood of different numerical outcomes. 
\end{definition}

\begin{definition}[Image Measure]
	\label{def:image_measure}
	\index{Image measure}
	Let $X: \Omega \mapsto \Omega_X$ be a random variable that maps from the probability space $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space $(\Omega_X, \mathcal{F}_X)$. Then~\cite{drewitz2019introduction}
	\begin{equation}
		\mathbb{P}\circ X^{-1}: \mathcal{F}_X\mapsto [0,1]
	\end{equation}
	defines a probability measure on $(\Omega_X, \mathcal{F}_X)$. $\mathbb{P}\circ X^{-1} \equiv \mathbb{P}_X$ is called the image measure or the pushforward measure\index{Pushforward measure} of $\mathbb{P}$.
\end{definition}

\begin{definition}[Expected value via image measure]
	\label{def:expectation_image}
	Let $X$ be a real-valued random variable defined on a probability space $(\Omega, \mathcal{F},\mathbb{P})$, and let
	\begin{equation}
		\mathbb{P}_X = \mathbb{P} \circ X^{-1}
	\end{equation} 
	be the image (pushforward) measure (\dfref{def:image_measure}) of $X$ on $(\Omega_X, \mathcal{F}_X)$. The expected value of $X$, denoted by $\mathbb{E}[X]$, can be defined viz
	\begin{equation}
		\mathbb{E}[X] \equiv \int_{\Omega_X} x \mathbb{P}_X(dx).
		\label{eq:expected_value_image}
	\end{equation}
\end{definition}

\begin{theorem}[Non-negativity of expected value]
	If $X\geq 0$ for a random variable $X$, then $\mathbb{E}[X]\geq 0$.
\end{theorem}
\begin{theorem}[Linearity of expected value]
	\label{theorem:exp_linear}
	The expectation is a linear operator meaning $\mathbb{E}[a+X] = a+\mathbb{E}[X]$ and $\mathbb{E}[aX] = a\mathbb{E}[X]$ for any constant $a$.
\end{theorem}
\begin{theorem}[Law of the Unconscious Statistician]
	\label{th:lotus}
	Let $X$ be a random variable defined on a probability space $(\Omega, \mathcal{F}, \mathbb{P})$, and let $g: \Omega_X \to \mathbb{R}$ be any measurable function. Denote the image (pushforward) measure (\dfref{def:image_measure}) of $X$ by $\mathbb{P}_X = \mathbb{P} \circ X^{-1}$. Then
	\begin{equation}
		\mathbb{E}[g(X)] \equiv \int_{\Omega_X} g(x) \mathbb{P}_X(dx).
		\label{eq:lotus_image}
	\end{equation}
\end{theorem}

\begin{definition}[Variance]
	\label{def:variance}
	Let $X$ be a real-valued random variable defined on a probability space $(\Omega, \mathcal{F},\mathbb{P})$, then the variance of $X$, denoted by $\operatorname{Var}[X]$, is defined viz\index{Variance}
	\begin{equation}
		\begin{split}
			\operatorname{Var}[X]&\equiv \mathbb{E}[(X-\mathbb{E}[X])^2]\\
			&= \mathbb{E}[X^2]-\mathbb{E}[X]^2.
		\end{split}
	\end{equation}
\end{definition}

\begin{theorem}[Markov's Inequality]
Let $X$ be a non-negative random variable and $a > 0$. Then
\begin{equation}
\mathbb{P}(X \geq a) \leq \frac{\mathbb{E}[X]}{a}.
\end{equation}
\end{theorem}
\begin{proof}
	Let $1_{\{X\ge a\}}$ denote the indicator of the event $\{X\ge a\}$. Since $X$ is non-negative and $a>0$
	\begin{equation}
		a1_{\{X\ge a\}} \le X.
	\end{equation}
	Taking expectations and using \thref{theorem:exp_linear}
	\begin{equation}
		a\,\mathbb{E}\big[1_{\{X\ge a\}}\big] \le \mathbb{E}[X].
	\end{equation}
	But $\mathbb{E}[1_{\{X\ge a\}}]=\mathbb{P}(X\ge a)$, so
	\begin{equation}
		a\,\mathbb{P}(X\ge a) \le \mathbb{E}[X],
	\end{equation}
	and rearranging yields Markov's inequality
	\begin{equation}
		\mathbb{P}(X\ge a) \le \frac{\mathbb{E}[X]}{a}.
	\end{equation}
\end{proof}

\begin{definition}[Probability Mass Function]
	\label{def:pmf}
	In case of a discrete random variable $X: \Omega \mapsto \Omega_X$ that maps from the probability space $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space $(\Omega_X, \mathcal{F}_X)$, the image measure (\dfref{def:image_measure})\index{Image measure} is defined as the probability mass function\index{Probability Mass Function (PMF)}
	\begin{equation}
		\begin{split}
			p( X = x) &\equiv  \mathbb{P}_X(\{x\})\\
			& = \mathbb{P}(X^{-1}(\{x\})).
		\end{split}
		\label{eq:disc}
	\end{equation}
	According to \axref{ax:non_neg}-\axref{ax:add}
	\begin{equation}
		\sum_{x\in \Omega_X} p(X=x) = 1
	\end{equation} 
	and
	\begin{equation}
		p(X=x) \geq 0, \quad \forall x\in \Omega_X.
	\end{equation}
\end{definition}

\begin{theorem}[Expected value of discrete random variable]
	The expected value of a discrete random variable $X$ with probability mass function $p$ can be written
	\begin{equation}
		\mathbb{E}[X]=\sum_{x\in \Omega_X}xp(X = x).
	\end{equation}
\end{theorem}

\begin{definition}[Probability Density Function]
	\label{def:pdf}
	Let $X: \Omega \to \Omega_X$ be a continuous random variable on a probability space $(\Omega, \mathcal{F}, \mathbb{P})$, and let $(\Omega_X, \mathcal{F}_X)$ be a measurable space. Denote the image (pushforward) measure (\dfref{def:image_measure}) of $X$ by
	\begin{equation}
		\mathbb{P}_X(B) \equiv \mathbb{P}(X^{-1}(B)), \quad \forall B \in \mathcal{F}_X.
	\end{equation}
	If there exists a non-negative measurable function
	\begin{equation}
		f: \Omega_X \to \mathbb{R}_{\ge 0}
	\end{equation} 
	such that
	\begin{equation}
		\mathbb{P}_X(B) = \int_B d\lambda(x) f(x), \quad \forall B \in \mathcal{B}(\Omega_X),
	\end{equation}
	where $\lambda$ denotes the Lebesgue measure\index{Lebesgue measure} and $\mathcal{B}(\Omega_X)$ is the Borel $\sigma$-algebra on $\Omega_X$, then $f$ is called the probability density function (PDF)\index{Probability Density Function (PDF)} of $X$. The PDF satisfies
	\begin{equation}
		f(x) \ge 0 \quad \forall x \in \Omega_X, 
		\qquad 
		\int_{\Omega_X} d\lambda(x) f(x) = 1.
	\end{equation}
\end{definition}

\begin{example}
	Let $X$ be a continuous random variable with PDF $f$. For an interval $[a,b] \subseteq \Omega_X$,
	\begin{equation}
		\begin{split}
			\mathbb{P}(a \le X \le b) 
			&= \mathbb{P}_X([a,b])\\ 
			&= \int_{[a,b]} d\lambda(x) f(x) \\ 
			&= \int_a^b dx f(x).
		\end{split}
	\end{equation}
\end{example}

\begin{theorem}[Expected value of continuous random variable]
	\label{theorem:expectaion_continuous}
	The expected value of a continuous random variable $X$ with probability density function $f$ can be written 
	\begin{equation}
		\mathbb{E}[X]=\int_{\Omega_X} dx xf(x).
	\end{equation}
\end{theorem}
\begin{theorem}[Total expectation]
	\label{theorem:total_expectation}
	\index{Total expectation}
	Let $X: \Omega \mapsto \Omega_X$ and $Y: \Omega \mapsto \Omega_Y$ be continuous random variables defined on the probability space $(\Omega, \mathcal{F}, \mathbb{P})$. Then
	\begin{equation}
		\mathbb{E}_X[X] = \mathbb{E}_Y[\mathbb{E}_{X|Y}[X| Y]],
	\end{equation}
	where the subscript indicates the probability distribution the expectation is taken with respect to.
\end{theorem}
\begin{proof}
	\begin{equation}
		\begin{split}
			\mathbb{E}_X[X] &= \int_{\Omega_X} dx x f(X=x)\\
			& = \int_{\Omega_Y} dy\int_{\Omega_X}dx x f(X=x,Y=y)\\
			& =  \int_{\Omega_Y} dy f(Y=y) \int_{\Omega_X}dx x f(X=x|Y=y)\\
			& =  \int_{\Omega_Y} dy f(Y=y) \underbrace{\int_{\Omega_X}dx x f(X=x|Y=y)}_{= \mathbb{E}_{X|Y}[X|Y]}\\
			& = \mathbb{E}_Y[\mathbb{E}_{X|Y}[X|Y]].
		\end{split}
	\end{equation}
\end{proof}

\begin{theorem}[Expectation of product of independent random variables]
	\label{theorem:expectation_independent}
	\index{Independent random variables}
	Let $X: \Omega \mapsto \Omega_X$ and $Y: \Omega \mapsto \Omega_Y$ be continuous random variables defined on the probability space $(\Omega, \mathcal{F}, \mathbb{P})$, such that
	\begin{equation}
	f(X=x,Y=y)=f(X=x)f(Y=y),	
	\end{equation}
	then $\mathbb{E}_{XY}[XY]=\mathbb{E}_X[X]\mathbb{E}_Y[Y]$.
\end{theorem}

\begin{proof}
	\begin{equation}
		\begin{split}
			\mathbb{E}_{XY}[XY] &= \int_{\Omega_X}dx\int_{\Omega_Y}dy x y f(X=x,Y=y)\\
			&= \int_{\Omega_X}dx x f(X=x)\int_{\Omega_Y}dy yf(Y=y)\\
			&= \mathbb{E}_X[X]\mathbb{E}_Y[Y]\\
		\end{split}
	\end{equation}
\end{proof}

\begin{definition}[Covariance]
	\label{def:covariance}
	\index{Covariance}
	Let $X: \Omega \mapsto \Omega_X$ and $Y: \Omega \mapsto \Omega_Y$ be continuous random variables defined on the probability space $(\Omega, \mathcal{F}, \mathbb{P})$, then the covariance of $X$ and $Y$, denoted by $\operatorname{Cov}[X,Y]$, is defined viz
	\begin{equation}
		\begin{split}
			\operatorname{Cov}[X,Y]&=\mathbb{E}_{XY}[(X-\mathbb{E}_X[X])(Y-\mathbb{E}_Y[Y])]\\
			&=\mathbb{E}_{XY}[XY]-\mathbb{E}_X[X]\mathbb{E}_Y[Y],
		\end{split}
	\end{equation}
\end{definition}
\begin{theorem}[Covariance of independent random variables]
	\label{theorem:covariance_of_independent_variables}
	Let $X: \Omega \to \Omega_X$ and $Y: \Omega \to \Omega_Y$ be continuous random variables defined on the probability space $(\Omega, \mathcal{F}, \mathbb{P})$. If $X$ and $Y$ are independent, then their covariance is
	\begin{equation}
		\operatorname{Cov}[X,Y] = 0.
	\end{equation}
	
\end{theorem}
\begin{proof}
	Using $\mathbb{E}_{XY}[XY]=\mathbb{E}_X[X]\mathbb{E}_Y[Y]$ (\thref{theorem:expectation_independent}) in \dfref{def:covariance} yield $\operatorname{Cov}[X,Y]=0$.
\end{proof}

\begin{definition}[Correlation]
	\index{Correlation}
	Let $X$ and $Y$ be real-valued random variables defined on a probability space $(\Omega, \mathcal{F},\mathbb{P})$. The correlation between $X$ and $Y$, denoted by $\operatorname{Corr}[X,Y]$, is defined as
	\begin{equation}
		\begin{split}
			\operatorname{Corr}[X,Y] &= \frac{\operatorname{Cov}[X,Y]}{\sqrt{\operatorname{Var}[X]  \operatorname{Var}[Y]}} \\
			&= \frac{\mathbb{E}_{XY}[XY]-\mathbb{E}_X[X]\mathbb{E}_Y[Y]}{\sqrt{\left(\mathbb{E}_X[X^2] - \mathbb{E}_X[X]^2\right) \left(\mathbb{E}_Y[Y^2] - \mathbb{E}_Y[Y]^2\right)}}.
		\end{split}
	\end{equation}
\end{definition}

Correlation and covariance are both measures of the relationship between two random variables. While covariance indicates the extent to which two variables change together, correlation provides a standardized measure of this relationship, taking into account the scales of the variables. In particular, the correlation between two variables, denoted by $\operatorname{Corr}[X, Y]$, is the covariance of $X$ and $Y$ divided by the product of their standard deviations. This normalization makes correlation a unitless quantity that ranges between -1 and 1, where -1 indicates a perfect negative linear relationship, 1 indicates a perfect positive linear relationship, and 0 indicates no linear relationship. In essence, correlation provides a more interpretable measure of the strength and direction of the linear association between two variables compared to covariance.

\newpage
\begin{definition}[Change of Variables for PDFs]
	\label{def:change_of_variables}
	\index{Change of variables for PDFs}
	Let $X$ be a continuous random variable with probability density function (PDF) $f(X =x)$, defined on a probability space $(\Omega, \mathcal{F},\mathbb{P})$. Suppose $Y = g(X)$ is a continuous and differentiable function of $X$, and let $g^{-1}$ denote the inverse function of $g$. If $Y = g(X)$ and the inverse function $g^{-1}$ exists and is differentiable, the PDF of the random variable $Y$, denoted $f(Y=y)$, can be obtained by the change of variables formula viz~\cite{Sivia2006}
	\begin{equation}
		f(Y = y) = f(X = g^{-1}(y)) \left| \frac{d}{d Y} \left( g^{-1}(Y) \right) \right|_{Y=y}.
		\label{eq:change_of_variables}
	\end{equation}
\end{definition}

\begin{example}
	Let $X$ be a continuous random variable with PDF $f(X =x)$, and let $Y = g(X) = aX + b$, where $a \neq 0$ and $b$ are constants. The inverse function is given by
	\begin{equation}
		g^{-1}(y) = \frac{y - b}{a}
	\end{equation}
	Using \dfref{def:change_of_variables}
	\begin{equation}
		\begin{split}
			f(Y=y) &= f\left( X = g^{-1}(y) \right) \left| \frac{d}{d Y} \left( g^{-1}(Y) \right) \right|_{Y=y} \\
			&= f\left(X =  \frac{y - b}{a} \right) \left| \frac{d}{d Y} \left( \frac{Y - b}{a} \right) \right|_{Y=y} \\
			&= f\left(X = \frac{y - b}{a} \right) \left| \frac{1}{a} \right|.
		\end{split}
	\end{equation}
	Thus, the PDF of $Y$ is
	\begin{equation}
		f(Y= y) = \frac{1}{|a|} f\left(X =  \frac{y - b}{a} \right).
	\end{equation}
\end{example}

\begin{example}
	\index{Example: Variable transformation}
	\emph{Let $X = \ln\big(\frac{Y}{1-Y}\big)$ be a continuous random variable with a constant PDF, i.e. $f(X=x)\propto \operatorname{const}$. The inverse function is given by}
	\begin{equation}
		g^{-1}(y) = \ln\bigg(\frac{y}{1-y}\bigg).
	\end{equation}
	Using \dfref{def:change_of_variables}
	\begin{equation}
		\begin{split}
			f(Y=y) &= f\left( X = g^{-1}(y) \right) \left| \frac{d}{d Y} \left( g^{-1}(Y) \right) \right|_{Y=y}\\
			& = \operatorname{const}\cdot \frac{1-Y}{Y}\bigg(\frac{1}{1-Y}+\frac{Y}{(1-Y)^2}\bigg)\bigg|_{Y=y}\\
			&=\operatorname{const}\cdot Y^{-1}(1-Y)^{-1}|_{Y=y}\\
			&=\operatorname{Beta}(Y=y|a=0,b=0).
		\end{split}
	\end{equation}
\end{example}

\begin{definition}[Error Propagation]
	\label{def:error_propagation}
	Let $X_1, \dots, X_n$ be continuous random variables defined on a probability space $(\Omega, \mathcal{F}, \mathbb{P})$, and let 
	$g:\mathbb{R}^n \to \mathbb{R}$ be a differentiable function of these variables. The variance of $g$, which quantifies the uncertainty in $g$ due to the uncertainties in the random variables $X_1, \dots, X_n$, can be written
	\begin{equation}
		\begin{split}
			\operatorname{Var}[g] &= \mathbb{E}\big[(g - \mathbb{E}[g])^2\big] \\
			&= \sum_{i=1}^n  \frac{\partial g}{\partial X_i}\bigg|_{X = \mathbb{E}[X]}^2\operatorname{Var}[X_i] + \sum_{i \neq j} \frac{\partial g}{\partial X_i} \frac{\partial g}{\partial X_j}\bigg|_{X=\mathbb{E}[X]} \operatorname{Cov}[X_i, X_j]\\
			&\quad + \mathcal{O}(\|X - \mathbb{E}[X]\|^3).
		\end{split}
		\label{eq:var_approx}
	\end{equation}
\end{definition}

\begin{proof}
	With the notation $X = (X_1, \dots, X_n)$ and $\mathbb{E}[X] = (\mathbb{E}[X_1], \dots, \mathbb{E}[X_n])$ $g(X)$ can be written as a Taylor expansion around $\mathbb{E}[X]$ viz
	\begin{equation}
		g(X) = g(\mathbb{E}[X]) + \sum_{i=1}^n  \frac{\partial g}{\partial X_i} \bigg|_{X = \mathbb{E}[X]} (X_i - \mathbb{E}[X_i]) + \mathcal{O}(\|X - \mathbb{E}[X]\|^2).
		\label{e1}
	\end{equation}
	Consequently
	\begin{equation}
		\begin{split}
			\mathbb{E}[g(X)] &= g(\mathbb{E}[X])+ \sum_{i=1}^n \frac{\partial g}{\partial X_i} \bigg|_{X = \mathbb{E}[X]}\, \cancelto{0}{\mathbb{E}[X_i - \mathbb{E}[X_i]]}  + \mathcal{O}(\|X - \mathbb{E}[X]\|^2)\\
			& = g(\mathbb{E}[X]) + \mathcal{O}(\|X - \mathbb{E}[X]\|^2)\\
		\end{split}
		\label{e2}
	\end{equation}
	meaning the variance of $g$ can be approximated viz
	\begin{equation}
		\begin{split}
			\operatorname{Var}[g] &= \mathbb{E}\big[(g - \mathbb{E}[g])^2\big] \\
			&= \mathbb{E}\bigg[\bigg( \sum_{i=1}^n (X_i - \mathbb{E}[X_i]) \frac{\partial g}{\partial X_i}\bigg|_{X=\mathbb{E}[X]} + \mathcal{O}(\|X - \mathbb{E}[X]\|^2)\bigg)^2\bigg] \\
			&= \sum_{i=1}^n  \frac{\partial g}{\partial X_i}\bigg|_{X = \mathbb{E}[X]}^2\operatorname{Var}[X_i] + \sum_{i \neq j} \frac{\partial g}{\partial X_i} \frac{\partial g}{\partial X_j}\bigg|_{X=\mathbb{E}[X]} \operatorname{Cov}[X_i, X_j]\\
			&\quad + \mathcal{O}(\|X - \mathbb{E}[X]\|^3).
		\end{split}
	\end{equation}
\end{proof}

\begin{remark}[Independent Random Variables]
	\label{remark:error_prop_independent}
	If the random variables $X_1, \dots, X_n$ are independent, then $\mathrm{Cov}[X_i, X_j] = 0$ for all \(i \neq j\) (see \thref{theorem:covariance_of_independent_variables}). In this case, \dfref{def:error_propagation} simplifies to
	\begin{equation}
		\operatorname{Var}[g(X_1, \dots, X_n)] \approx \sum_{i=1}^n \left(\frac{\partial g}{\partial X_i}\Big|_{X = \mathbb{E}[X]}\right)^2 \operatorname{Var}[X_i].
	\end{equation}
	This is the commonly used form of the linear error-propagation formula for independent variables.
\end{remark}

\begin{example}
	\index{Example: Error propagation}
	A company produce square plates. Let the plate dimensions be characterized by two independent random variables\index{Normal distribution} $X\sim \operatorname{Norm}(2m,(0.01m)^2)$ and $Y\sim \operatorname{Norm}(3m,(0.02m)^2)$ and the area given by $XY$. Determine the variance of $XY$. From \dfref{def:error_propagation}, the exact variance is
	\begin{equation}
		\label{eq:var1}
		\begin{split}
			\operatorname{Var}[XY]&=\mathbb{E}[(XY)^2]-(\mathbb{E}[XY])^2\\
			&=\bigg(\operatorname{Var}[X]+\mathbb{E}[X]\bigg)\bigg(\operatorname{Var}[Y]+\mathbb{E}[Y]\bigg)-\mathbb{E}[X]^2\mathbb{E}[Y]^2\\
			&=\mathbb{E}[Y]^2\operatorname{Var}[X]+\mathbb{E}[X]^2\operatorname{Var}[Y]+\operatorname{Var}[X]\operatorname{Var}[Y]
		\end{split}
	\end{equation}
	where it has been used that $X$ and $Y$ are independent, such that $\mathbb{E}[(XY)^2]=\mathbb{E}[X^2]\mathbb{E}[Y^2]$.	Via the linear approximation from \rmref{remark:error_prop_independent}
	\begin{equation}
		\label{eq:var2}
		\begin{split}
			\operatorname{Var}[XY]&\approx\sum_{i = X,Y} \bigg( \frac{\partial (XY)}{\partial i}\bigg|_{X = \mathbb{E}[X],Y = \mathbb{E}[Y]}  \bigg)^2\operatorname{Var}[i]\\
			&=\mathbb{E}[Y]^2\operatorname{Var}[X]+\mathbb{E}[X]^2\operatorname{Var}[Y]
		\end{split}
	\end{equation}
	Comparing \EQref{eq:var1} and \EQref{eq:var2} the relative difference can be written
	\begin{equation}
		\begin{split}
			\frac{\operatorname{Var}[XY]-\operatorname{Var}[XY]|_{\text{linear approximation}}}{\operatorname{Var}[XY]} &= \frac{\operatorname{Var}[X]\operatorname{Var}[Y]}{\operatorname{Var}[XY]}\\
			& \simeq 1.6\cdot 10^{-5}.
		\end{split}
	\end{equation}
	
\end{example}

\begin{example}
	\index{Example: Father with Amnesia}
	Consider a thought experiment in which a father with amnesia is told he has two children, but does not know the sex of them. The sample space can be constructed from the sample space\index{Sample space} for each child
	\begin{equation}
		\begin{split}
			\Omega_{\text{child 1}} &= \{\text{\Gentsroom,\Ladiesroom}\},\\
			\Omega_{\text{child2}} &= \{\text{\Gentsroom,\Ladiesroom}\}\\
		\end{split}
	\end{equation}
	such that
	\begin{equation}
		\begin{split}
			\Omega &= \Omega_{\text{child 1}}\times \Omega_{\text{child 2}}\\
			&= \{(\text{\Gentsroom,\Gentsroom}),(\text{\Gentsroom,\Ladiesroom}),(\text{\Ladiesroom,\Gentsroom}),(\text{\Ladiesroom,\Ladiesroom})\}.
		\end{split}
	\end{equation}
	Assuming the sex of a child is like a coin\index{Coin experiment} flip, it is most likely, a priori, that the father has one boy and one girl with probability $\frac{1}{2}$, i.e.  $\mathbb{P}(\{(\text{\Gentsroom,\Ladiesroom})\})=\frac{1}{2}$. The other possibilities (two boys or two girls) have probability $\frac{1}{4}$, meaning $\mathbb{P}(\{(\text{\Gentsroom,\Gentsroom})\})=\frac{1}{4}$ and $\mathbb{P}(\{(\text{\Ladiesroom,\Ladiesroom})\})=\frac{1}{4}$. In order to simplify the formalism, define the random variables $B: \Omega \mapsto \{0,1,2\}$ and $G: \Omega \mapsto \{0,1,2\}$ that maps the events in $\mathcal{F}$ to a number of boys $B(E)\forall E\in \mathcal{F}$ and girls $G(E)\forall E\in \mathcal{F}$ \index{Random variable}. The probability mass function associated to $B$ and $G$ is given by \dfref{def:pmf}\index{PMF}, such that e.g.
	\begin{equation}
		p(B = 1, G = 1)= \mathbb{P}(\{(\text{\Gentsroom,\Ladiesroom})\}).
	\end{equation}

	\begin{enumerate}
		\item Suppose the father ask his wife whether he has any boys, and she says yes. What is the probability that one child is a girl?
		
		The exact framing of the question is important here; "any boys" means "at least one boy"
		\begin{equation}
			p(G=1,B\geq 1) = \frac{p(B\geq1|G=1)p(G=1)}{p(B\geq 1)}.
		\end{equation}
		Given the father has two children, if he has exactly one girl, then the other must be a boy, so $p(B\geq 1|G=1)=1$. $p(G=1)=\frac{1}{2}$ since it is a priori assumed to be equally likely to be a boy or girl. 
		\begin{equation}
			p(B\geq 1)=1-p(G=2,B=0)=\frac{3}{4},
		\end{equation}
		so
		\begin{equation}
			p(G=1|B\geq 1) = \frac{2}{3}.
		\end{equation}
		
		\item Suppose instead the father meets one of his children and it is a boy.What is the probability that the other is a girl?
		
		Since one child is known to be a boy, what is asked about is
		\begin{equation}
			p(G=1|B=1)=\frac{1}{2}.
		\end{equation}
	\end{enumerate}
\end{example}


\begin{example}
	\index{Example: Prosecutor}
	Suppose a crime has been committed. Blood is found at the crime scene for which there is no innocent explanation. It is of the type that is present in $1\%$ of the population. Let $E$ denote the event that a person has the blood type found at the crime scene. Then
	\begin{equation}
		\mathbb{P}(E) = 0.01.
		\label{eq:proseca}
	\end{equation}
	
	The prosecutor claims: ``There is a $1\%$ chance that the defendant would have the crime blood type if he were innocent. Thus, there is a $99\%$ chance that he is guilty.'' This is known as the prosecutor's fallacy. What is wrong with this argument?\newline
	
	The prosecutor's claim can be written as
	\begin{equation}
		\mathbb{P}(E \mid \operatorname{innocent}) = 0.01 \Rightarrow \mathbb{P}(\operatorname{guilty} \mid E) = 0.99.
		\label{eq:prosec1}
	\end{equation}		
	
	To investigate this claim, note that from \dfref{def:conditional_probability}, 
	\begin{equation}
		\begin{split}
			\mathbb{P}(E \mid \operatorname{innocent}) &= \frac{\mathbb{P}(E, \operatorname{innocent})}{\mathbb{P}(\operatorname{innocent})} \\
			&= \frac{\mathbb{P}(\operatorname{innocent} \mid E)}{\mathbb{P}(\operatorname{innocent})} \mathbb{P}(E).
		\end{split}
	\end{equation}
	Hence, in general, $\mathbb{P}(E \mid \operatorname{innocent}) \neq \mathbb{P}(E)$. Suppose there are $N$ people in the world, and $M \leq N$ of these have the blood type found at the crime scene. In that case,
	\begin{equation}
		\frac{\mathbb{P}(\operatorname{innocent} \mid E)}{\mathbb{P}(\operatorname{innocent})} = \frac{\frac{M-1}{M}}{\frac{N-1}{N}},
	\end{equation}
	which approaches $1$ in the limit $N \rightarrow \infty$. Hence, $\mathbb{P}(E \mid \operatorname{innocent}) \simeq \mathbb{P}(E)$ can be a good approximation, but it is not an exact relation.\newline 
	Assuming $\mathbb{P}(E \mid \operatorname{innocent}) = 0.01$, the prosecutor's claim can be further analyzed using \dfref{def:conditional_probability}, viz.
	\begin{equation}
		\mathbb{P}(\operatorname{guilty} \mid E) + \mathbb{P}(\operatorname{innocent} \mid E) = \frac{\mathbb{P}(\operatorname{guilty}, E) + \mathbb{P}(\operatorname{innocent}, E)}{\mathbb{P}(E)}.
	\end{equation}
	Innocent and guilty are complementary events that form a partition of the sample space, meaning (\thref{theorem:law_of_total_probability})
	\begin{equation}
		\mathbb{P}(\operatorname{guilty}, E) + \mathbb{P}(\operatorname{innocent}, E) = \mathbb{P}(E),
	\end{equation}
	and thereby
	\begin{equation}
		\mathbb{P}(\operatorname{guilty} \mid E) + \mathbb{P}(\operatorname{innocent} \mid E) = 1.
	\end{equation}
	This means that if $\mathbb{P}(\operatorname{guilty} \mid E) = 0.99$, then $\mathbb{P}(\operatorname{innocent} \mid E) = 0.01$, and from \thref{theorem:bayes_theorem},
	\begin{equation}
			\mathbb{P}(\operatorname{innocent} \mid E) = \frac{\mathbb{P}(E \mid \operatorname{innocent}) \, \mathbb{P}(\operatorname{innocent})}{\mathbb{P}(E)}
		\label{eq:prosec}
	\end{equation}
	From equation \eqref{eq:prosec}, it is clear that in general
	\begin{equation}
		\mathbb{P}(E \mid \operatorname{innocent}) \neq \mathbb{P}(\operatorname{innocent} \mid E),
	\end{equation}
	and so even if $\mathbb{P}(E \mid \operatorname{innocent}) = 0.01$, the prosecutor's claim (\EQref{eq:prosec1}) is not true.
\end{example}


\begin{example}
	\index{Example: Variance of a sum}
	Show that the variance of a sum is $\operatorname{Var}[X+Y]=\operatorname{Var}[X]+\operatorname{Var}[Y]+2\operatorname{Cov}[X,Y]$.
	
	\begin{equation}
		\begin{split}
			\operatorname{Var}[X+Y] &= \mathbb{E}_{XY}[(X+Y-\mathbb{E}_{XY}[X+Y])^2]\\
			&= \mathbb{E}_X[(X-\mathbb{E}_X[X])^2]+\mathbb{E}_Y[(Y-\mathbb{E}_Y[Y])^2]\\
			&\quad+2\mathbb{E}_{XY}[(X-\mathbb{E}_X[X])(Y-\mathbb{E}_Y[Y])]\\
			& = \operatorname{Var}[X]+\operatorname{Var}[Y]+2\operatorname{Cov}[X,Y].
		\end{split}
	\end{equation}
\end{example}

\newpage
\begin{example}
	\index{Example: Bad news from the doctor}
	After your yearly checkup, the doctor has bad news and good news. The bad news is that you tested positive for a serious disease, and that the test is $99\%$ accurate (i.e. the probability of testing positive given that you have the disease is $99\%$, as is the probability of testing negative given that you don't have the disease). The good news is that this is a rare disease, striking only one in $10\,000$ people. What are the chances that you actually have the disease?\newline
	
	Let "s" denote the event of being sick, "h" the event of being healthy, "p" the event of a positive test and "n" the event of a negative test, then  
	\begin{equation}
		\begin{split}
			\mathbb{P}(\text{s}|\text{p}) &= \frac{\mathbb{P}(\text{p}|\text{s})\mathbb{P}(\text{s})}{\mathbb{P}(\text{p})}\\
			&= \frac{\mathbb{P}(\text{p}|\text{s})\mathbb{P}(\text{s})}{\mathbb{P}(\text{p}|\text{s})\mathbb{P}(\text{s})+\mathbb{P}(\text{p}|\text{h})\mathbb{P}(\text{h})}\\
		\end{split}
	\end{equation}
	where $\mathbb{P}(\text{p}|\text{s}) = 0.99$, $\mathbb{P}(s) = \frac{1}{10\, 000}$, $\mathbb{P}(\text{p}|\text{h})=1-\mathbb{P}(\text{n}|\text{h})$, $\mathbb{P}(\text{n}|\text{h})=0.99$ and $\mathbb{P}(\text{h})=1-\mathbb{P}(\text{s})$. This means
	\begin{equation}
		\mathbb{P}(\text{s}|\text{p}) \simeq 0.0098.
	\end{equation}		
\end{example}

\begin{example}
	\index{Example: Gameshow}
	On a game show, a contestant is told the rules as follows: There are $3$ doors labeled $1,2,3$. A single prize has been hidden behind one of them. You get to select one door. Initially your chosen door will not be opened, instead, the gameshow host will open one of the other two doors in such a way as not to reveal the prize. For example, if you first choose door $1$, the gameshow host will open one of doors $2$ and $3$, and it is guaranteed that he will choose which one to open so that the prize will not be revealed. At this point you will be given a fresh choice of door: You can either stick with your first choice, or you can switch to the other closed door. All the doors will then be opened and you will receive whatever is behind your final choice of door.\newline
	Imagine that the contestant chooses first door $1$; then the gameshow host opens door $3$, revealing nothing. Should the contestant a) stick with door $1$, b) switch to door $2$ or c) it does not matter? You may assume that initially, the prize is equally likely to be behind any of the $3$ doors. \newline
	
	Let $z_i$ denote the prize being behind the $i$'th door, $o_i$ the action of opening the $i$'th door and $c_i$ the action of choosing the $i$'th door. The door with the largest probability of containing the prize should be picked, meaning
	\begin{equation}
		z^*=\argmax_z(\mathbb{P}(z|o_3,c_1)).
	\end{equation}
	Since the host cannot open the door containing the prize, $\mathbb{P}(z_3|o_3,c_1)=0$ and only $\mathbb{P}(z_1|o_3,c_1)$ and $\mathbb{P}(z_2|o_3,c_1)$ will have to be considered. For $z_1$
	\begin{equation}
		\mathbb{P}(z_1|o_3,c_1) = \frac{\mathbb{P}(o_3|c_1,z_1)\mathbb{P}(c_1,z_1)}{\mathbb{P}(o_3,c_1)}
	\end{equation}
	with
	\begin{equation}
		\begin{split}
			\mathbb{P}(o_3,c_1)&=\sum_i\mathbb{P}(o_3,c_1,z_i)\\
			&=\mathbb{P}(o_3,c_1,z_1)+\mathbb{P}(o_3,c_1,z_2)+\mathbb{P}(o_3,c_1,z_3)\\
			&= \mathbb{P}(o_3|c_1,z_1)\mathbb{P}(c_1,z_1)+\mathbb{P}(o_3|c_1,z_2)\mathbb{P}(c_1,z_2)\\
			&\quad+\mathbb{P}(o_3|c_1,z_3)\mathbb{P}(c_1,z_3).
		\end{split}
	\end{equation}
	$\mathbb{P}(o_3|c_1,z_3)=0$ since the host will not open the door with the prize. $p(o_3|c_1,z_2)=1$ since the host has no other option in this case. $\mathbb{P}(o_3|c_1,z_1)=\frac{1}{2}$ since the host has two options in this case. There is no connection between the choice of door and position of the prize, so $\mathbb{P}(c_1, z_j)=\mathbb{P}(c_1)\mathbb{P}(z_j)$ and initially $\mathbb{P}(z_j)=\mathbb{P}(z_k)$ $\forall j,k\in \{1,2,3\}$. Hence
	\begin{equation}
		\begin{split}
			\mathbb{P}(z_1|o_3,c_1) &= \frac{\mathbb{P}(o_3|c_1,z_1)}{\sum_i\mathbb{P}(o_3|c_1,z_i)}\\
			&=\frac{1}{3}.
		\end{split}
	\end{equation}
	Similarly
	\begin{equation}
		\begin{split}
			\mathbb{P}(z_2|o_3,c_1) &= \frac{\mathbb{P}(o_3|c_1,z_2)}{\sum_i\mathbb{P}(o_3|c_1,z_i)}\\
			&=\frac{2}{3}.
		\end{split}
	\end{equation}
	Since $\mathbb{P}(z_2|o_3,c_1)>\mathbb{P}(z_1|o_3,c_1)>\mathbb{P}(z_3|o_3,c_1)$, door number $2$ is the optimal choise. Hence,answer "b)" is correct. The intuition behind the answer is the information the contestant has at the time of making the decision; initially, there is no a priori information and so $\mathbb{P}(z_1|o_3,c_1)=\frac{1}{3}$. At this time, there is $\frac{2}{3}$ probability that the prize is behind doors $2,3$. When the gameshow host open door $3$, this probability converge on door $2$.
\end{example}

\newpage
\begin{example}
	\index{Example: Correlation coefficient}
	Let $X\sim \operatorname{Unif}(a=-1, b=1)$ and $Y=X^2$. Clearly $Y$ is dependent on X (in fact Y is uniquely determined by X). However, show that $\operatorname{Corr}[X,Y]=0$.
	
	\begin{equation}
		\begin{split}
			\operatorname{Corr}[X,Y] & = \frac{\operatorname{Cov}[X,Y]}{\sqrt{\operatorname{Var}[X]\operatorname{Var}[Y]}}\\
			& = \frac{\mathbb{E}_{XY}[XY]-\mathbb{E}_X[X]\mathbb{E}_Y[Y]}{\sqrt{\operatorname{Var}[X]\operatorname{Var}[Y]}}\\
		\end{split}
	\end{equation}
	In this case for the nominator
	\begin{equation}
		\begin{split}
			\operatorname{Cov}[X,Y] &= \int dx x^3 p(x)-\int dx' x'p(x')\int dx'' x''^2p(x'')\\
			&= \frac{1}{b-a}\int_{a}^{b}x^3dx-\frac{1}{(b-a)^2}\int_{a}^{b}dx' x'\int_{a}^{b}dx'' x''^2\\
			&= \frac{1}{12}(a-b)^2(a+b)\\
			&=0
		\end{split}
	\end{equation}
	where the last equality comes from the fact that $a+b = 0$ in this case. However, we need to make sure the denominator does not diverge
	\begin{equation}
		\begin{split}
			\operatorname{Var}[X]\operatorname{Var}[X^2] & =\big(\mathbb{E}_X[X^2]-\mathbb{E}_X[X]^2\big) \big(\mathbb{E}_X[X^4]-\mathbb{E}_X[X^2]^2\big)\\
			& = \frac{1}{540}(b-a)^4(4a^2+7ab+4b^2)\\
			&\neq 0.
		\end{split}
	\end{equation}
	It denominator does not diverge, so the factorized $a+b$ from the nominator makes $\operatorname{Corr}[X,X^2]=0$.
\end{example}

\begin{example}
	\index{Example: Correlation coefficient}
	Let $X\sim \operatorname{Norm}(\mu =0, \sigma^2 = 1)$ and $Y = WX$, where W is a discrete random variable defined by $p(W=-1)=p(W=1)=\frac{1}{2}$. It is clear that X and Y are not independent, since Y is a function of X.
	\begin{enumerate}
		\item Show $Y\sim \operatorname{Norm}(\mu =0, \sigma^2 = 1)$.\newline
		
		To show that $Y\sim \operatorname{Norm}(\mu =0, \sigma^2 = 1)$, show that Y has zero mean and unity variance.
		\begin{equation}
			\begin{split}
				\mathbb{E}_Y[Y] &= \mathbb{E}_{WX}[WX]\\
				&=\mathbb{E}_W[W]\cancelto{0}{\mathbb{E}_X[X]}\\
				&=0.
			\end{split}
		\end{equation}
		The variance
		\begin{equation}
			\begin{split}
				\operatorname{Var}[Y] &= \mathbb{E}_Y[Y^2]-\cancelto{0}{\mathbb{E}_Y[Y]^2}\\
				& = \mathbb{E}_{WX}[W^2X^2]\\
				&= \mathbb{E}_W[W^2]\mathbb{E}_X[X^2]\\
				& = \mathbb{E}_W[W^2]\operatorname{Var}[X]
			\end{split}
		\end{equation}
		since $\operatorname{Var}[X]=\mathbb{E}_X[X^2]-\cancelto{0}{\mathbb{E}_X[X]^2}=1$. Now
		\begin{equation}
			\begin{split}
				\mathbb{E}_W[W^2]&= \frac{1}{n}\sum_{i=1}^nw_i^2p(W = w_i)\\
				&= \frac{1}{2}[(-1)^2\frac{1}{2}+1^2\frac{1}{2}]\\
				&= 1
			\end{split}
		\end{equation}
		so $\operatorname{Var}[Y] =1$.
		\item Show $\operatorname{Cov}[X,Y]=0$. Thus X and Y are uncorrelated but dependent, even though they are Gaussian.
		
		\begin{equation}
			\begin{split}
				\operatorname{Cov}[X,Y] &= \operatorname{Cov}[X,WX] \\
				&= \mathbb{E}_{WX}[WX^2]-\mathbb{E}_X[X]\mathbb{E}_{WX}[WX]\\
				&= \mathbb{E}_W[W]\mathbb{E}_X[X^2]-\mathbb{E}_W[W]\mathbb{E}_X[X]^2\\
				&= \mathbb{E}_W[W]\operatorname{Var}[X]\\
				& = 0
			\end{split}
		\end{equation}
		where for the last equality it has been used that
		\begin{equation}
			\begin{split}
				\begin{split}
					\mathbb{E}_W[W]&= \frac{1}{n}\sum_{i=1}^nw_ip(W = w_i)\\
					&= \frac{1}{2}[(-1)\frac{1}{2}+1\frac{1}{2}]\\
					&= 0
				\end{split}
			\end{split}
		\end{equation}
		
	\end{enumerate}
	
\end{example}

\newpage
\begin{example}
	\index{Example: Correlation coefficient}
	Prove that $-1\leq \operatorname{Corr}[X,Y]\leq 1$.\newline
	
	Since the variance is defined as positive definite
	\begin{equation}
		\label{eq:corr_deriv}
		\begin{split}
			0\leq& \operatorname{Var}\bigg[\frac{X}{\sigma_X}\pm\frac{Y}{\sigma_Y}\bigg]\\
			& = \frac{\operatorname{Var}[X]}{\sigma_X^2}+\frac{\operatorname{Var}[Y]}{\sigma_Y^2}\pm \frac{2}{\sigma_X\sigma_Y}\operatorname{Cov}[X,Y]\\
			& = \frac{\operatorname{Var}[X]}{\sigma_X^2}+\frac{\operatorname{Var}[Y]}{\sigma_Y^2}\pm 2\operatorname{Corr}[X,Y]\\
			& = 2\pm 2\operatorname{Corr}[X,Y]
		\end{split}
	\end{equation}
	where for the last equality it has been used that $\sigma_i^2=\operatorname{Var}[i]$. From equation \eqref{eq:corr_deriv} the result follows
	\begin{equation}
		-1\leq \operatorname{Corr}[X,Y]\leq 1.
	\end{equation}	
\end{example}

\begin{example}
	\index{Example: Correlation coefficient}
	Show that if $Y=aX+b$ for some parameters $a>0$ and $b$, then $\operatorname{Corr}[X,Y]=1$. Similarly show that if $a<0$, then $\operatorname{Corr}[X,Y]=-1$.
	
	\begin{equation}
		\operatorname{Corr}[X,Y] = \frac{\operatorname{Cov}[X,Y]}{\sqrt{\operatorname{Var}[X]\operatorname{Var}[Y]}}
	\end{equation}
	\begin{equation}
		\begin{split}
			\operatorname{Cov}[X,Y] & = \mathbb{E}_{XY}[XY]-\mathbb{E}_X[X]\mathbb{E}_Y[Y]\\
			&= \mathbb{E}_X[X(aX+b)]-\mathbb{E}_X[X]\mathbb{E}_X[aX+b]\\
			&= a\mathbb{E}_X[X^2]+b\mathbb{E}_X[X]-a\mathbb{E}_X[X]^2-b\mathbb{E}_X[X]\\
			&=a\operatorname{Var}[X]
		\end{split}
	\end{equation}
	\begin{equation}
		\begin{split}
			\operatorname{Var}[Y] &= \operatorname{Var}[aX+b]\\
			&= a^2\operatorname{Var}[X]+\cancelto{0}{\operatorname{Var}[b]}+2\cancelto{0}{\operatorname{Cov}[aX,b]}\\
			& = a^2\operatorname{Var}[X]
		\end{split}
	\end{equation}
	\begin{equation}
		\begin{split}
			\operatorname{Corr}[X,Y] &= \frac{a\operatorname{Var}[X]}{\sqrt{a^2\operatorname{Var}[X]\operatorname{Var}[X]}}\\
			&=\frac{a}{|a|}		
		\end{split}
	\end{equation}
	Hence, the sign of "$a$" determine if $\operatorname{Corr}[X,Y]=\pm 1$ for the particular $Y$ of this example.
\end{example}

\begin{example}
	\index{Example: Secretary problem}
	Let $n$ denote the total number of candidates, presented sequentially in uniformly random order. After observing the $k$-th candidate, an irrevocable decision must be made: either to accept or reject the candidate. The objective is to maximize the probability of selecting the candidate with the highest rank among all $n$ candidates.\newline
	
	Let $r \in \{0,1,\dots,n-1\}$ denote the number of candidates to be automatically rejected. Define the strategy $\sigma_r$ as follows: reject the first $r$ candidates, then select the first subsequent candidate whose observed rank exceeds all ranks observed among the first $r$ candidates. Let $\mathbb{P}_n(r)$ denote the probability that strategy $\sigma_r$ selects the best candidate. For $k \in \{r+1,\dots,n\}$, the probability that the $k$-th candidate is the best and is selected by $\sigma_r$ is
	\begin{equation}
		\mathbb{P}(\text{best at position } k \text{ and selected}) = \frac{1}{n} \cdot \frac{r}{k-1}.
	\end{equation}
	Summation over all admissible positions yields
	\begin{equation}
		\begin{split}
			\mathbb{P}_n(r) &= \sum_{k=r+1}^{n} \frac{r}{n(k-1)}\\
			& = \frac{r}{n} \sum_{k=r}^{n-1} \frac{1}{k}.
		\end{split}
	\end{equation}  
	For large $n$, the sum may be approximated by an integral:
	\begin{equation}
		\begin{split}
			\mathbb{P}_n(r) &\approx \frac{r}{n} \int_{r}^{n} \frac{dx}{x}\\
			& = \frac{r}{n} \ln\frac{n}{r}.
		\end{split}
	\end{equation}
	Setting $r = \alpha n$, $\alpha \in (0,1)$, gives
	\begin{equation}
		\mathbb{P}_n(\alpha n) \approx \alpha \ln \frac{1}{\alpha}.
	\end{equation}
	The maximum occurs at
	\begin{equation}
		\begin{split}
			\frac{d}{d\alpha} \big(\alpha \ln \tfrac{1}{\alpha}\big) &= \ln \frac{1}{\alpha} - 1\\
			& = 0
		\end{split}
	\end{equation}
	meaning
	\begin{equation}
		\alpha = \frac{1}{e}.
	\end{equation}
	The optimal stopping strategy consists of rejecting the first $\frac{n}{e}$ candidates, then selecting the first candidate superior to all previously observed. The maximum probability of success converges to $\mathbb{P}_n \to \frac{1}{e} \approx 0.368$ as $n \to \infty$. This strategy extends naturally to situations where candidates arrive sequentially over time. In the continuous-time setting, the first $1/e$ fraction of the time interval is used purely for observation, and thereafter the first candidate exceeding all previous observations is selected.
\end{example}