\chapter{Introduction to Probability Theory}
\label{chp:probaiblity_theory}
Probability theory is a foundational branch of mathematics that provides the formal framework for reasoning about uncertainty. At its core, it studies random experiments and the likelihood of their outcomes. This chapter reviews the essential principles and axioms of probability, laying the groundwork for statistical inference and decision-making under uncertainty.

\begin{definition}[Sample Space]
	\label{def:sample_space}
	The sample space\index{Sample space}, denoted by $\Omega$, is the set of all possible outcomes (i.e. the universal set, see \dfref{def:universal_set}) of a random experiment.
\end{definition}

\begin{definition}[Event]
	An event\index{Event}, $E$, is a subset of the sample space\index{Sample space}, denoted by $E \subseteq \Omega$, that corresponds to a specific collection of possible outcomes in a random experiment. Events may consist of single or multiple outcomes and are defined by the occurrence or non-occurrence of particular conditions.
\end{definition}

\begin{definition}[$\sigma$-algebra]
	\label{def:sigma_algebra}
	A $\sigma$-algebra\index{$\sigma$-algebra} over a sample space\index{Sample space} $\Omega$ is a collection of subsets $\mathcal{G}$ of $\Omega$ that contains both $\emptyset$ and $\Omega$, is closed under complementation (that is, if $E \in \mathcal{G}$ then $E^c \in \mathcal{G}$), and is closed under countable unions (and therefore also under countable intersections).
\end{definition}

\begin{example}
	\label{ex:die1}
	Consider the roll of a fair six-sided die\index{Example: Die}. The sample space\index{Sample space} for this experiment is given by $\Omega = \{ \epsdice{1}, \epsdice{2}, \epsdice{3}, \epsdice{4}, \epsdice{5}, \epsdice{6} \}$. $E = \{\epsdice{2}, \epsdice{4}, \epsdice{6}\}$, is the event of rolling an even number. 
\end{example}

\begin{example}
	\label{ex:die1a}
	For the roll with the fair die considered in \exref{ex:die1}\index{Example: Die}, the trivial $\sigma$-algebra on $\Omega$ is given by
	\begin{equation}
		\mathcal{G}_{\text{trivial}} = \{\emptyset, \Omega\}.
	\end{equation}
	In this case, the only events that can be described are the impossible event $\emptyset$ and the certain event $\Omega$. For instance, the event of rolling an even number $E = \{\epsdice{2}, \epsdice{4}, \epsdice{6}\}$ is not in $\mathcal{G}_{\text{trivial}}$.
\end{example}

\begin{definition}[Borel $\sigma$-algebra]
	\label{def:borel_sigma_algebra}
	The Borel $\sigma$-algebra\index{Borel $\sigma$-algebra}, denoted $\mathcal{B}(\mathbb{R})$, is the smallest $\sigma$-algebra on $\mathbb{R}$ that contains all open subsets of $\mathbb{R}$.  Equivalently, $\mathcal{B}(\mathbb{R})$ is generated by the collection of open intervals $(a,b) \subset \mathbb{R}$. Thus, $\mathcal{B}(\mathbb{R})$ contains all sets that can be formed from open intervals through countable unions, intersections, and complements.  
\end{definition}

\begin{definition}[Event Space]
	\label{def:event_space}
	The event space\index{Event space}, denoted by $\mathcal{F}$, is the collection of all subsets of the sample space $\Omega$ that are considered valid events for a random experiment. Formally, $\mathcal{F}$ is required to be a $\sigma$-algebra\index{$\sigma$-algebra}, ensuring it is closed under complementation, countable unions, and countable intersections.
\end{definition}

\begin{remark}[Typical Event Spaces]
	For a discrete sample space\index{Sample space} $\Omega$, $\mathcal{F}$ is typically the power set of $\Omega$ (\dfref{def:power_set}). For a continuous sample space, $\mathcal{F}$ is typically the Borel $\sigma$-algebra (\dfref{def:borel_sigma_algebra}), generated by open sets in $\mathbb{R}$ (i.e. $\mathcal{B}(\mathbb{R})$).
\end{remark}

\begin{definition}[Measurable Space]
	\label{def:measurable_space}
	A measurable space is a pair $(\Omega, \mathcal{F})$, where $\Omega$ is the sample space\index{Sample space} of a random experiment and $\mathcal{F}$ is the corresponding event space.
\end{definition}

\begin{example}
	\label{ex:die2}
	For the roll with the fair die considered in \exref{ex:die1}\index{Example: Die}, the event space is given by
	\begin{equation}
		\begin{split}
			\mathcal{F}&=\{\emptyset, \{\epsdice{1}\},\{\epsdice{1},\epsdice{3}\},\{\epsdice{3}\},\{\epsdice{1},\epsdice{2},\epsdice{3},\epsdice{4}\},\{\epsdice{5}\},\dots,\Omega\}\\
			& = 2^\Omega.
		\end{split}
	\end{equation}
\end{example}

\begin{definition}[Measure]
	\label{def:measure}
	\index{Measure}
	Let $(\Omega, \mathcal{F})$ be a measurable space, where $\Omega$ is the sample space\index{Sample space} and $\mathcal{F}$ is the event space. A measure $\mu$ is a set function
	\begin{equation}
		\mu\colon \mathcal{F} \to [0,\infty]
	\end{equation}
	that satisfies \axref{ax:non_neg} (non-negativity) and \axref{ax:add} (additivity).
\end{definition}

\begin{axiom}[Non-negativity]
	\label{ax:non_neg}
	For any event $E\in \mathcal{F}$, the measure $\mu(E)$ is non-negative, satisfying
	\begin{equation}
		\mu(E) \geq 0 \quad \forall E \in  \mathcal{F}.
	\end{equation}
\end{axiom}

\begin{axiom}[Additivity]
	\label{ax:add}
	For any countable sequence of mutually exclusive events $E_1, E_2, \ldots\in \mathcal{F}$, the measure of their union is the sum of their individual measures, such that
	\begin{equation}
		\mu\left(\bigcup_{i=1}^{\infty} \mathit{E}_i\right) = \sum_{i=1}^{\infty} \mu(\mathit{E}_i) \quad \forall \mathit{E}_i \in \mathcal{F} \text{ where } \bigcap_{i=1}^{\infty} \mathit{E}_i = \emptyset.
	\end{equation}
\end{axiom}

\begin{definition}[$\sigma$-finite Measure]
	\label{def:sigma_finite_measure}
	\index{$\sigma$-finite measure}
	Let $(\Omega, \mathcal{F})$ be a measurable space, where $\Omega$ is the sample space\index{Sample space} and $\mathcal{F}$ is the event space. A measure $\mu$ on $(\Omega, \mathcal{F})$ is called $\sigma$-finite if there exists a countable collection of sets $A_i \in \mathcal{F}$ $\forall i\in \mathbb{N}$ such that 
	\begin{equation}
		\Omega = \bigcup_{i=1}^\infty A_i
		\quad\text{and}\quad 
		\mu(A_i) < \infty \;\; \forall i\in\mathbb{N}.
	\end{equation}
\end{definition}

\begin{definition}[Measurable Function]
	\label{def:measurable_function}
	\index{Measurable function}
	Let $(\Omega,\mathcal{F})$ and $(\Omega_X,\mathcal{F}_X)$ be measurable spaces. A function
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	is said to be measurable if
	\begin{equation}
		X^{-1}(B) \in \mathcal{F} \quad \forall B \in \mathcal{F}_X,
	\end{equation}
	where
	\begin{equation}
		X^{-1}(B) = \{\omega \in \Omega \colon X(\omega) \in B\}.
	\end{equation}
	In words, the preimage of every measurable set in $\mathcal{F}_X$ is a measurable set in $\mathcal{F}$.
\end{definition}

\begin{definition}[Lebesgue Measure]
	\label{def:lebesgue_measure}
	\index{Lebesgue measure}
	Let $(\Omega, \mathcal{F})$ be a continuous measurable space, where $\Omega$ is the sample space\index{Sample space} and $\mathcal{F} = \mathcal{B}(\mathbb{R})$ is the event space. The Lebesgue measure $\lambda$ is a measure, in the sense of \dfref{def:measure}, defined on $\mathcal{F}$ such that, for every interval $(a,b] \subseteq \mathbb{R}$,
	\begin{equation}
		\lambda((a,b]) = b-a.
	\end{equation}
	In higher dimensions, the Lebesgue measure $\lambda$ extends naturally to the $n$-dimensional Euclidean space $\mathbb{R}^n$, coinciding with the usual notions of length ($n=1$), area ($n=2$), and volume ($n=3$).
\end{definition}

\begin{definition}[Counting Measure]
	\label{def:counting_measure}
	\index{Counting measure}
	Let $(\Omega, \mathcal{F})$ be a discrete measurable space, where $\Omega$ is the sample space\index{Sample space} and $\mathcal{F}$ is the event space. The counting measure $\nu$ is a measure, in the sense of \dfref{def:measure}, defined on $\mathcal{F}$ such that for every event $E \in \mathcal{F}$,
	\begin{equation}
		\nu(E) = |E|,
	\end{equation}
	where $|E|$ denotes the cardinality of $E$ (finite or countably infinite). In particular, for finite sets $E$, $\nu(E)$ equals the number of elements in $E$, and for countably infinite sets, $\nu(E) = \infty$.
\end{definition}

\begin{definition}[Probability Measure]
	\label{def:probability}
	\index{Probability Measure}
	Let $(\Omega, \mathcal{F})$ be a measurable space, where $\Omega$ is the sample space\index{Sample space} and $\mathcal{F}$ is the event space. A probability measure $\mathbb{P}$ is a measure, in the sense of \dfref{def:measure}, defined on $(\Omega, \mathcal{F})$ that, in addition to satisfying \axref{ax:non_neg} (non-negativity) and \axref{ax:add} (additivity), satisfies the normalization property
	\begin{equation}
		\mathbb{P}(\Omega) = 1.
	\end{equation}
\end{definition}

\begin{definition}[Objective Probability Measure]
	\label{def:objective_probability}
	Let $\mathbb{P}$ denote a probability measure\index{Probability measure} defined on the measurable space\index{Measurable space} $(\Omega, \mathcal{F})$. Interpreting the probability measure as an objective probability measure\index{Objective probability measure}~\cite{Leamer1978,freedman2007} consists in viewing $\mathbb{P}(E)$ as the long-run relative frequency of the event $E\in\mathcal{F}$ over repeated independent trials, provided that the limit exists.
\end{definition}

\begin{definition}[Subjective Probability Measure]
	\label{def:subjective_probability}
	Let $\mathbb{P}$ denote a probability measure\index{Probability measure} defined on the measurable space\index{Measurable space} $(\Omega, \mathcal{F})$. Interpreting the probability measure as a subjective probability measure\index{Subjective probability measure}~\cite{shafer1987,hoff2009first} consists in assigning values to events based on rational degrees of belief\index{Rational belief} derived from prior knowledge, constraints, or partial information, in a way that avoids internal inconsistencies (i.e., satisfies Dutch-book coherence~\cite{vineberg2011}).
\end{definition}

\begin{definition}[Probability Space]
	\label{def:probability_space}
	A probability space\index{Probability space} is a triple $(\Omega, \mathcal{F}, \mathbb{P})$, where $\Omega$ is the sample space\index{Sample space},	$\mathcal{F}$ is the event space and $\mathbb{P}$ is a probability measure on the measurable space $(\Omega, \mathcal{F})$.
\end{definition}


\begin{remark}[Reason for Borel $\sigma$-algebra]
	The restriction to Borel sets\index{Borel set} in continuous sample spaces\index{Sample space} avoids paradoxical constructions such as non-measurable sets (e.g., the Vitali set~\cite{vitali1905sui}), which cannot be consistently assigned a probability~\cite{fremlin2000measure}, ensuring that the probability measure is well defined on all events in $\mathcal{F}$~\cite{billingsley1995probability}.
\end{remark}

\begin{example}
	\label{ex:borel_continuous_events}
	Consider a random experiment where a real number is chosen uniformly from the interval $[0,1]$. The sample space\index{Sample space} is therefore $\Omega = [0,1]$. The event space\index{Event space} $\mathcal{F}$ cannot be the power set of $[0,1]$, since not all subsets admit a well-defined probability measure. Instead, $\mathcal{F}$ is chosen as the Borel $\sigma$-algebra $\mathcal{B}([0,1])$, which includes sets such as open intervals, closed intervals, and countable unions or intersections thereof. 
	For example, the event 
	\begin{equation}
		E = (0.2, 0.5)
	\end{equation}
	represents the outcome that the selected real number lies between $0.2$ and $0.5$.
\end{example}

\begin{definition}[Independence]
	\label{def:independence}
	Two events $E_1, E_2 \in \mathcal{F}$ in a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ are said to be independent\index{Independent events} if and only if
	\begin{equation}
		\mathbb{P}(E_1 \cap E_2) = \mathbb{P}(E_1) \mathbb{P}(E_2).
	\end{equation}
\end{definition}

\begin{definition}[Conditional Probability]
	\label{def:conditional_probability}
	Let $E_1, E_2 \in \mathcal{F}$ be events in a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ with $\mathbb{P}(E_2) > 0$. 
	The conditional probability\index{Conditional probability} of $E_1$ given $E_2$ is defined by
	\begin{equation}
		\mathbb{P}(E_1 \mid E_2) = \frac{\mathbb{P}(E_1 \cap E_2)}{\mathbb{P}(E_2)}.
	\end{equation}
\end{definition}

\begin{definition}[Conditional Independence]
	\label{def:conditional_independence}
	Events $E_1$ and $E_2$ are conditionally independent\index{Conditional independent} given $E_3 \in \mathcal{F}$ if
	\begin{equation}
		\mathbb{P}(E_1 \cap E_2 \mid E_3) = \mathbb{P}(E_1 \mid E_3)\,\mathbb{P}(E_2 \mid E_3),
	\end{equation}
	provided $\mathbb{P}(E_3) > 0$.
\end{definition}

\begin{theorem}[Chain Rule]
	\label{theorem:chain_rule}
	Let $E_1, E_2, E_3 \in \mathcal{F}$ be events in a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ with $\mathbb{P}(E_3) > 0$. Then the chain rule\index{Chain rule} states that
	\begin{equation}
		\mathbb{P}(E_1 \cap E_2 \cap E_3) 
		= \mathbb{P}(E_1 \mid E_2 \cap E_3)\,\mathbb{P}(E_2 \mid E_3)\,\mathbb{P}(E_3).
	\end{equation}
\end{theorem}
\begin{proof}
	From the definition of conditional probability in \dfref{def:conditional_probability}
	\begin{equation}
		\mathbb{P}(E_1 \cap E_2 \cap E_3) = \mathbb{P}(E_1|E_2 \cap E_n)\mathbb{P}(E_2 \cap E_3).
		\label{eq:p1}
	\end{equation}
	Using the definition of conditional probability again
	\begin{equation}
		\mathbb{P}(E_2 \cap E_3) = \mathbb{P}(E_2| E_3)\mathbb{P}(E_3).
	\end{equation}
	which leads to \thref{theorem:chain_rule}.
\end{proof}

\begin{theorem}[Bayes theorem]
	\label{theorem:bayes_theorem}
	For events $E_1, E_2 \in \mathcal{F}$ in a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ with $\mathbb{P}(E_2) > 0$, Bayes theorem\index{Bayes theorem} states that
	\begin{equation}
		\mathbb{P}(E_1 \mid E_2) = \frac{\mathbb{P}(E_2 \mid E_1)\,\mathbb{P}(E_1)}{\mathbb{P}(E_2)}.
		\label{bayes_theorem}
	\end{equation}
\end{theorem}


\begin{proof}
	Bayes theorem follows directly from applying \thref{theorem:chain_rule} and applying the concept of symmetry as follows
	\begin{equation}
		\begin{split}
			\mathbb{P}(E_1 \cap E_2) &= \mathbb{P}(E_1| E_2)\mathbb{P}(E_2) \\
			& = \mathbb{P}(E_2|E_1)\mathbb{P}(E_1)
		\end{split}
		\label{eq:c2}
	\end{equation}
	from which
	\begin{equation}
		\mathbb{P}(E_1| E_2) = \frac{\mathbb{P}(E_2| E_1)\mathbb{P}(E_1)}{\mathbb{P}(E_2)}
	\end{equation}
	which is \thref{theorem:bayes_theorem}.
\end{proof}

\begin{theorem}[Law of Total Probability / Marginalization]
	\label{theorem:law_of_total_probability}
	Let $\{E_1, \dots, E_n\}$ be a finite partition\index{Partition}\index{Law of Total Probability}\index{Marginalization}, in the sense of \dfref{def:partition}, of the sample space\index{Sample space} $\Omega$ in a probability space $(\Omega, \mathcal{F}, \mathbb{P})$. Then, for any event $A \in \mathcal{F}$,
	\begin{equation}
		\mathbb{P}(A) = \sum_{i=1}^n \mathbb{P}(A \cap E_i).
		\label{eq:law_total_probability}
	\end{equation}
\end{theorem}

\begin{proof}
	Consider an event $A\in \mathcal{F}$ and a partition $\{E_1,\dots E_n\}$ of $\Omega$ such that $\cup_{i}E_i=\Omega$. For mutually exclusive events (which a partition by definition is), \axref{ax:add} can be used such that
	\begin{equation}
		\sum_{i}\mathbb{P}(A \cap E_i) = \mathbb{P}\bigg(\bigcup_{i}(A \cap E_i)\bigg).
		\label{eq:qq1}
	\end{equation} 
	$\bigcup_{i}(A \cap E_i)$ is the union of all intersections between $A$ and the $E$'s. However, since the $E$'s form a partition of $\Omega$, they together form $\Omega$ and the intersection between $\Omega$ and $A$ is $A$, meaning
	\begin{equation}
		\begin{split}
			\bigcup_{i}(A \cap E_i)  &= (A,\bigcup_{i}E_i)\\
			&= (A \cap \Omega)\\
			& =A.
		\end{split}
		\label{eq:qq2}
	\end{equation}
	Combining \EQref{eq:qq1} and \EQref{eq:qq2} yields
	\begin{equation}
		\mathbb{P}(A) = \sum_{i} \mathbb{P}(A \cap E_i)
	\end{equation}
	which is \thref{theorem:law_of_total_probability}.
\end{proof}

\begin{example}
	\index{Example: Fair die}
	For the roll with the fair die considered in \exref{ex:die1}\index{Die example}, the sample space\index{Sample space} is $\Omega = \{ \epsdice{1}, \epsdice{2}, \epsdice{3}, \epsdice{4}, \epsdice{5}, \epsdice{6} \}$. Let $E_1 = \{\epsdice{2}, \epsdice{4}, \epsdice{6}\}$ and $E_2 = \{\epsdice{4}\}$ be two events, then from \dfref{def:conditional_probability}
	\begin{equation}
		\begin{split}
			\mathbb{P}(E_1|E_2) &= \frac{\mathbb{P}(E_1 \cap E_2)}{\mathbb{P}(E_2)}\\
			& = 1
		\end{split}
	\end{equation}
	where $\mathbb{P}(E_1 \cap E_2)= \frac{1}{6}$ since $E_1\cap E_2 = E_2=\{\epsdice{4}\}$ is one of $6$ possible values and $\mathbb{P}(E_2) = \frac{1}{6}$. Intuitively this makes sense because $E_2$ is a set with one member and since $E_2$ is known, the outcome of the experiment is known with certainty in this case.
\end{example}

\begin{definition}[Random Variable]
	\label{def:random_Variable}
	\index{Random variable}
	A random variable $X$ is a measurable function\index{Measurable function} in the sense of \dfref{def:measurable_function},
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	from a probability space $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space $(\Omega_X, \mathcal{F}_X)$, where $\Omega_X$ is the codomain of $X$ and $\mathcal{F}_X$ is a $\sigma$-algebra on $\Omega_X$.
\end{definition}

\begin{remark}[Types of Random Variables]
	Random variables provide a numerical representation of the outcomes of a random experiment.  
	They are classified as either discrete, when $\Omega_X$ is countable, or continuous, when $\Omega_X$ is uncountable, often modeled as an interval of $\mathbb{R}$.
\end{remark}

\begin{definition}[Image Measure]
	\label{def:image_measure}
	\index{Image measure}
	Let 
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	be a random variable\index{Random variable} from the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$. Then~\cite{drewitz2019introduction}
	\begin{equation}
		\mathbb{P}\circ X^{-1}\colon \mathcal{F}_X\to [0,1]
	\end{equation}
	defines a probability measure\index{Probability measure} on $(\Omega_X, \mathcal{F}_X)$. $\mathbb{P}\circ X^{-1} \equiv \mathbb{P}_X$ is called the image measure or the pushforward measure\index{Pushforward measure} of $\mathbb{P}$.
\end{definition}

\begin{definition}[Expected value]
	\label{def:expectation_image}
	Let 
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	be a random variable\index{Random variable} from the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$, and let
	\begin{equation}
		\mathbb{P}_X = \mathbb{P} \circ X^{-1}
	\end{equation} 
	be the image measure\index{Image measure} of $X$ on $(\Omega_X, \mathcal{F}_X)$. The expected value\index{Expected value} of $X$, denoted by $\mathbb{E}_X[X]$, is defined as follows
	\begin{equation}
		\mathbb{E}_X[X] \equiv \int_{\Omega_X} x \mathrm{d}\mathbb{P}_X(x).
		\label{eq:expected_value_image}
	\end{equation}
\end{definition}

\begin{theorem}[Non-negativity of expected value]
	Let 
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	be a random variable\index{Random variable} from the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$. $X\geq 0 \Rightarrow \mathbb{E}_X[X]\geq 0$.
\end{theorem}
\begin{proof}
	From \dfref{def:expectation_image} 
	\begin{equation}
		\mathbb{E}_X[X] = \int_{\Omega_X}x \mathrm{d}\mathbb{P}_X(x),
	\end{equation}
	and if $x \ge 0$ for all $x \in \Omega_X$, the integral of a non-negative function with respect to a measure\index{Measure} is non-negative. Hence, $\mathbb{E}_X[X] \ge 0$.
\end{proof}

\begin{theorem}[Linearity of expected value]
	\label{theorem:exp_linear}
	Let 
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	be a random variable\index{Random variable} from the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$. The expected value\index{Expected value} is a linear operator meaning $\mathbb{E}_X[a+X] = a+\mathbb{E}_X[X]$ and $\mathbb{E}_X[aX] = a\mathbb{E}_X[X]$ for any constant $a$.
\end{theorem}
\begin{proof}
	From \dfref{def:expectation_image} 
	\begin{equation}
		\begin{split}
			\mathbb{E}_X[a + X] &= \int_{\Omega_X}(a + x) \mathrm{d}\mathbb{P}_X(x) \\ 
			&= a\int_{\Omega_X} \mathrm{d}\mathbb{P}_X(x) + \int_{\Omega_X} x \mathrm{d}\mathbb{P}_X(x)\\
			&= a + \mathbb{E}_X[X],
		\end{split}
	\end{equation}
	since 
	\begin{equation}
		\begin{split}
			\mathbb{P}_X(\Omega_X) &= \int_{\Omega_X} \mathrm{d}\mathbb{P}_X(x) \\
			& = 1.
		\end{split}
	\end{equation}
	Similarly,
	\begin{equation}
		\begin{split}
			\mathbb{E}_X[a X] &= \int_{\Omega_X} a x \mathrm{d}\mathbb{P}_X(x) \\
			& = a \int_{\Omega_X} x \mathrm{d}\mathbb{P}_X(x)\\
			& = a \mathbb{E}_X[X].
		\end{split}
	\end{equation}
\end{proof}


\newpage
\begin{remark}[Law of the Unconscious Statistician]
	\label{th:lotus}
	\dfref{def:expectation_image} naturally extends to measurable functions via the law of the unconscious statistician. Let 
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	be a random variable\index{Random variable} from the probability space\index{Probability space}\index{Law of the Unconscious Statistician} $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$, and let 
	\begin{equation}
		g\colon \Omega_X \to \mathbb{R}
	\end{equation} 
	be a generic measurable function\index{Measurable function}. Denote the image measure\index{Image measure} of $X$ by $\mathbb{P}_X $. Then
	\begin{equation}
		\mathbb{E}_X[g(X)] \equiv \int_{\Omega_X} g(x)\mathrm{d}\mathbb{P}_X(x).
		\label{eq:lotus_image}
	\end{equation}
\end{remark}

\begin{definition}[Variance]
	\label{def:variance}
	Let 
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	be a real-valued random variable\index{Random variable} from the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$. The variance\index{Variance} of $X$, denoted by $\operatorname{Var}_X[X]$, is defined as follows\index{Variance}
	\begin{equation}
		\begin{split}
			\operatorname{Var}_X[X]&\equiv \mathbb{E}_X[(X-\mathbb{E}_X[X])^2]\\
			&= \mathbb{E}_X[X^2]-\mathbb{E}_X[X]^2.
		\end{split}
	\end{equation}
\end{definition}

\begin{definition}[Probability Density with Respect to a Measure]
	\label{def:prob_density_general}
	\index{Probability density}
	Let
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	be a random variable\index{Random variable} from the probability space $(\Omega, \mathcal{F}, \mathbb{P})$ to the measurable space\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$. Let $\mu_X$ be a $\sigma$-finite measure\index{$\sigma$-finite measure} on $(\Omega_X, \mathcal{F}_X)$, in the sense of \dfref{def:sigma_finite_measure}. If the image measure\index{Image measure} $\mathbb{P}_X = \mathbb{P} \circ X^{-1}$ is absolutely continuous with respect to $\mu_X$, then by the Radon-Nikodym theorem~\cite{Navratil1981} there exists a measurable function
	\begin{equation}
		p_X = \frac{d\mathbb{P}_X}{d\mu_X},
	\end{equation}
	called the probability density of $X$ with respect to $\mu_X$, such that
	\begin{equation}
		\mathbb{P}_X(B) = \int_B p_X(x) \mathrm{d}\mu_X(x), \quad \forall B \in \mathcal{F}_X.
	\end{equation}
	Moreover, since $\mathbb{P}_X$ is a probability measure, the density satisfies
	\begin{equation}
		p_X(x) \ge 0, \quad \text{and} \quad
		\int_{\Omega_X} p_X(x) \mathrm{d}\mu_X(x) = 1.
	\end{equation}
\end{definition}

\begin{remark}[Probability Density Function]
	\label{remark:pdf}
	In the case of a continuous sample space, the measure $\mu_X = \lambda_X$ is the Lebesgue measure\index{Lebesgue measure} (\dfref{def:lebesgue_measure}) on $\Omega_X$. The probability density $p_X$ is then called the probability density function\index{Probability density function} (PDF) of $X$. 
\end{remark}

\begin{remark}[Probability Mass Function]
	\label{remark:pmf}
	In the case of a discrete sample space, the measure $\mu_X = \nu_X$ is the counting measure\index{Counting measure} (\dfref{def:counting_measure}) on $\Omega_X$. The probability density $p_X$ is then called the probability mass function\index{Probability mass function} (PMF) of $X$, and
	\begin{equation}
		\begin{split}
			\mathbb{P}_X(B)&= \int_B p_X(x) \mathrm{d}\nu_X(x)\\
			&= \sum_{x \in B} p_X(x) \quad \forall B \in \mathcal{F}_X.
		\end{split}
	\end{equation}
\end{remark}


\begin{remark}[Expected value of a discrete random variable]
	\label{rem:expected_value_discrete}
	Let $X$ be a discrete random variable with PMF\index{Probability mass function} $p_X$. From \dfref{def:expectation_image} and \rmref{remark:pmf} the expected value of $X$ can be written
	\begin{equation}
		\mathbb{E}_X[X]=\sum_{x\in \Omega_X} x p_X(x).
		\label{eq:discrete_exp}
	\end{equation}
\end{remark}

\begin{remark}[Expected value of a continuous random variable]
	\label{remark:expectation_continuous}
	Let $X$ be a continuous random variable\index{Random variable} with PDF\index{Probability density function} $p_X$ then from \dfref{def:expectation_image} and \rmref{remark:pdf} the expected value of $X$ can be written
	\begin{equation}
		\mathbb{E}_X[X] = \int_{\Omega_X} x p_X(x) \mathrm{d}\lambda_X(x),
	\end{equation}
	where $\lambda_X$ denotes the Lebesgue measure\index{Lebesgue measure} on $\mathbb{R}$. In practice, it is customary to write $d\lambda_X(x)$ simply as $dx$.
\end{remark}


\begin{example}
	Let $X$ be a continuous random variable\index{Random variable} with PDF\index{Probability density function} $p_X$ on $\Omega_X\subseteq \mathbb{R}$. For the interval (event) $[a,b] \subseteq \Omega_X$,
	\begin{equation}
		\begin{split}
			\mathbb{P}(X^{-1}([a,b])) 
			&= \mathbb{P}_X([a,b])\\ 
			&= \int_{[a,b]} p_X(x) \mathrm{d}\lambda_X(x)\\ 
			&= \int_a^b p_X(x) \mathrm{d}x.
		\end{split}
	\end{equation}
\end{example}

\begin{definition}[Joint Probability Measure]
	\label{def:joint}
	\index{Joint probability measure}
	Let
	\begin{equation}
		X\colon \Omega \to \Omega_X, \quad Y\colon \Omega \to \Omega_Y
	\end{equation}
	be random variables\index{Random variable} from the probability space $(\Omega, \mathcal{F}, \mathbb{P})$ to the measurable spaces\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$ and $(\Omega_Y, \mathcal{F}_Y)$, respectively.	The joint probability measure of $X$ and $Y$ is the image measure
	\begin{equation}
		\mathbb{P}_{X,Y} = \mathbb{P}\circ(X,Y)^{-1}
	\end{equation}
	defined on the measurable space 
	\begin{equation}
		(\Omega_{X_1}\times\Omega_{Y}, \mathcal{F}_{X}\otimes\mathcal{F}_{Y}).
	\end{equation}	
	All probability measures\index{Probability measure} related to the random variables can be derived from the joint probability measure via \thref{theorem:law_of_total_probability}.
\end{definition}

\begin{remark}[Marginalization over a Joint Measure]
	\label{remark:marginalization}
	Let
	\begin{equation}
		X\colon \Omega \to \Omega_X, \quad Y\colon \Omega \to \Omega_Y
	\end{equation}
	be random variables\index{Random variable} from the probability space $(\Omega, \mathcal{F}, \mathbb{P})$ to measurable spaces\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$ and $(\Omega_Y, \mathcal{F}_Y)$, respectively. Suppose $A\in \mathcal{F}_X$ and let $\mathbb{P}_{X,Y}$ denote the joint probability measure on the measurable space $(\Omega_{X}\times\Omega_{Y}, \mathcal{F}_{X}\otimes\mathcal{F}_{Y})$, then from \thref{theorem:law_of_total_probability}
	\begin{equation}
			\begin{split}
				\mathbb{P}_X(A) &= \mathbb{P}_{X,Y}(A \times \Omega_Y)\\
				& = \int_{A}\int_{\Omega_Y}p_{X,Y}(x,y)\mathrm{d}\mu_Y(y)\mathrm{d}\mu_X(x), \quad \forall A \in \mathcal{F}_X,
			\end{split}
	\end{equation}
	where $p_{X,Y}$ is the probability density with respect to $\mu_{X,Y} = \mu_X \otimes \mu_Y$.
\end{remark}

\begin{theorem}[Law of total expectation]
	\label{theorem:total_expectation}
	\index{Law of total expectation}
	Let
	\begin{equation}
		X\colon \Omega \to \Omega_X, \quad Y\colon \Omega \to \Omega_Y
	\end{equation}
	be random variables\index{Random variable} from the probability space $(\Omega, \mathcal{F}, \mathbb{P})$ to measurable spaces\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$ and $(\Omega_Y, \mathcal{F}_Y)$, respectively. Let $\mathbb{P}_{X,Y}$ denote the joint probability measure on the measurable space $(\Omega_X \times \Omega_Y, \mathcal{F}_X \otimes \mathcal{F}_Y)$. Then
	\begin{equation}
		\mathbb{E}_X[X] = \mathbb{E}_Y\big[\mathbb{E}_{X|Y}[X \mid Y]\big].
	\end{equation}
\end{theorem}

\begin{proof}
	By Fubini's theorem and \dfref{def:conditional_probability},
	\begin{equation}
		\begin{split}
			\mathbb{E}_X[X] 
			&= \int_{\Omega_X} x \mathrm{d}\mathbb{P}_X(x)\\
			&= \int_{\Omega_X}\int_{\Omega_Y} x \mathrm{d}\mathbb{P}_{X,Y}(x,y)\\
			&= \int_{\Omega_Y}\int_{\Omega_X} x \mathrm{d}\mathbb{P}_{X|Y=y}(x)\mathrm{d}\mathbb{P}_Y(y)\\
			&= \mathbb{E}_Y[\mathbb{E}_{X|Y}[X\mid Y]].
		\end{split}
	\end{equation}
	or equivalently in terms of the probability densities
	\begin{equation}
		\begin{split}
			\mathbb{E}_X[X] 
			&= \int_{\Omega_X} x p_X(x) \mathrm{d}\mu_X(x)\\
			&= \int_{\Omega_Y} \int_{\Omega_X} x p_{X,Y}(x,y) \mathrm{d}\mu_X(x) \mathrm{d}\mu_Y(y)\\
			&= \int_{\Omega_Y} p_Y(y) \left( \int_{\Omega_X} x p_{X|Y}(x\mid y) \mathrm{d}\mu_X(x) \right) \mathrm{d}\mu_Y(y)\\
			&= \mathbb{E}_Y[\mathbb{E}_{X|Y}[X\mid Y]]
		\end{split}
	\end{equation}
	where $p_{X,Y}$ is the probability density with respect to $\mu_{X,Y} = \mu_X \otimes \mu_Y$.
\end{proof}

\begin{theorem}[Expectation of product of independent random variables]
	\label{theorem:expectation_independent}
	\index{Independent random variables}
	Let $X\colon \Omega \to \Omega_X$ and $Y\colon \Omega \to \Omega_Y$ be continuous random variables\index{Random variable} defined on the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$. If the random variables are independent\index{Independen random variables} the expectation can be written
	\begin{equation}
		\mathbb{E}_{X,Y}[XY]=\mathbb{E}_X[X]\mathbb{E}_Y[Y].
	\end{equation}
\end{theorem}

\begin{proof}
	\index{Probability density function}
	If the random variables are independent, then according to \dfref{def:independence}
	\begin{equation}
		\mathbb{P}_{X,Y}(\{x,y\})=\mathbb{P}_{X}(\{x\})\mathbb{P}_{Y}(\{y\})
	\end{equation}
	meaning
	\begin{equation}
		\begin{split}
			\mathbb{E}_{X,Y}[XY] &= \int_{\Omega_X}\int_{\Omega_Y}xy\mathrm{d}\mathbb{P}_{X,Y}(x,y)\\
			&= \int_{\Omega_X}x\mathrm{d}\mathbb{P}_X(x)\int_{\Omega_Y}y\mathrm{d}\mathbb{P}_Y(y)\\
			&= \mathbb{E}_X[X]\mathbb{E}_Y[Y].\\
		\end{split}
	\end{equation}
\end{proof}

\begin{definition}[Covariance]
	\label{def:covariance}
	\index{Covariance}
	Let $X\colon \Omega \to \Omega_X$ and $Y\colon \Omega \to \Omega_Y$ be continuous random variables defined on the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$, then the covariance of $X$ and $Y$, denoted by $\operatorname{Cov}_{X,Y}[X,Y]$, is defined as follows
	\begin{equation}
		\begin{split}
			\operatorname{Cov}_{X,Y}[X,Y]&=\mathbb{E}_{X,Y}[(X-\mathbb{E}_X[X])(Y-\mathbb{E}_Y[Y])]\\
			&=\mathbb{E}_{X,Y}[XY]-\mathbb{E}_X[X]\mathbb{E}_Y[Y],
		\end{split}
	\end{equation}
\end{definition}
\begin{theorem}[Covariance of independent random variables]
	\label{theorem:covariance_of_independent_variables}
	Let 
	\begin{equation}
		X\colon \Omega \to \Omega_X \quad \text{and}\quad Y\colon \Omega \to \Omega_Y
	\end{equation}
	 be continuous random variables\index{Random variable} defined on the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$. If $X$ and $Y$ are independent\index{Independen random variables}, then their covariance is
	\begin{equation}
		\operatorname{Cov}_{X,Y}[X,Y] = 0.
	\end{equation}
\end{theorem}
\begin{proof}
	Using \thref{theorem:expectation_independent} in \dfref{def:covariance} yields $\operatorname{Cov}_{X,Y}[X,Y]=0$.
\end{proof}

\begin{definition}[Correlation]
	\label{def:correlation}
	\index{Correlation}
	Let $X\colon \Omega \to \Omega_X$ and $Y\colon \Omega \to \Omega_Y$ be continuous random variables\index{Random variable} defined on the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$. The correlation between $X$ and $Y$, denoted by $\operatorname{Corr}_{X,Y}[X,Y]$, is defined as
	\begin{equation}
		\begin{split}
			\operatorname{Corr}_{X,Y}[X,Y] &= \frac{\operatorname{Cov}_{X,Y}[X,Y]}{\sqrt{\operatorname{Var}_X[X]  \operatorname{Var}_Y[Y]}} \\
			&= \frac{\mathbb{E}_{X,Y}[XY]-\mathbb{E}_X[X]\mathbb{E}_Y[Y]}{\sqrt{\left(\mathbb{E}_X[X^2] - \mathbb{E}_X[X]^2\right) \left(\mathbb{E}_Y[Y^2] - \mathbb{E}_Y[Y]^2\right)}}.
		\end{split}
	\end{equation}
\end{definition}

\begin{remark}[Correlation vs. Covariance]
	Correlation and covariance are both measures of the relationship between two random variables\index{Random variable}. While covariance indicates the extent to which two variables change together, correlation provides a standardized measure of this relationship, taking into account the scales of the variables.
\end{remark}

\begin{definition}[Change of Variables for PDFs]
	\label{def:change_of_variables}
	\index{Change of variables for PDFs}
	Let
	\begin{equation}
		X\colon \Omega \to \Omega_X
	\end{equation}
	be a random variables\index{Random variable} from the probability space $(\Omega, \mathcal{F}, \mathbb{P})$ to the measurable space\index{Measurable space} $(\Omega_X, \mathcal{F}_X)$, and let 
	\begin{equation}
		\mathbb{P}_X(B) = \int_B p_X(x)\mathrm{d}\lambda_X(x), \quad \forall B\in \mathcal{F}_X.
	\end{equation}
	Let
	\begin{equation}
		g\colon \Omega_X\to \Omega_Y
	\end{equation}
	be a continuous differentiable bijection with continuous differentiable inverse $g^{-1}$, and define
	\begin{equation}
		Y= g(X).
	\end{equation}
	Then $Y$ admits a PDF $p_Y$ with respect to the Lebesgue measure on $\Omega_Y = g(\Omega_X)$, given by~\cite{Sivia2006}
	\begin{equation}
		p_Y(y) = p_X\bigl(g^{-1}(y)\bigr), \left| \frac{d}{dy} g^{-1}(y) \right|, \quad y \in \Omega_Y.
	\end{equation}
\end{definition}

\begin{example}
	\index{Example: Variance of a sum}
	Let $X\colon \Omega \to \Omega_X$ and $Y\colon\Omega \to \Omega_Y$ be continuous random variables\index{Random variable} defined on the probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$. Using \dfref{def:variance} and \dfref{def:covariance}, the variance of a sum can be written
	\begin{equation}
		\begin{split}
			\operatorname{Var}_{X,Y}[X+Y] &= \mathbb{E}_{X,Y}[(X+Y-\mathbb{E}_{X,Y}[X+Y])^2]\\
			&= \mathbb{E}_X[(X-\mathbb{E}_X[X])^2]+\mathbb{E}_Y[(Y-\mathbb{E}_Y[Y])^2]\\
			&\quad+2\mathbb{E}_{X,Y}[(X-\mathbb{E}_X[X])(Y-\mathbb{E}_Y[Y])]\\
			& = \operatorname{Var}_X[X]+\operatorname{Var}_Y[Y]+2\operatorname{Cov}_{X,Y}[X,Y].
		\end{split}
	\end{equation}
\end{example}

\begin{example}
	Let $X\colon \Omega \to \Omega_X$ be a continuous random variable\index{Random variable} with probability density function\index{Probability density function} (PDF) $p_X$, defined on a probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$. Suppose 
	\begin{equation}
		\begin{split}
			Y &= g(X)\\ 
			&= aX + b,
		\end{split}
	\end{equation}
	where $a \neq 0$ and $b$ are constants. The inverse function is
	\begin{equation}
		g^{-1}(y) = \frac{y - b}{a}.
	\end{equation}
	Using \dfref{def:change_of_variables}, the PDF of $Y$ is
	\begin{equation}
		\begin{split}
			p_Y(y) &= p_X\bigl(g^{-1}(y)\bigr) \left| \frac{d}{dy} g^{-1}(y) \right| \\
			&= p_X\left(\frac{y - b}{a}\right) \left| \frac{1}{a} \right|.
		\end{split}
	\end{equation}
	Hence,
	\begin{equation}
		p_Y(y) = \frac{1}{|a|} p_X\left(\frac{y - b}{a}\right).
	\end{equation}
\end{example}

\begin{example}
	\index{Example: Variable transformation}
	Let $X\colon \Omega \to \Omega_X$ be a continuous random variable\index{Random variable} with probability density function\index{Probability density function} (PDF) $p_X$, defined on a probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$. Suppose $p_X(x) \propto \operatorname{const}$, and let
	\begin{equation}
		\begin{split}
			Y &= g(X)\\
			& = \frac{e^X}{1 + e^X}.
		\end{split}
	\end{equation}
	The inverse function is
	\begin{equation}
		g^{-1}(y) = \ln\left(\frac{y}{1-y}\right).
	\end{equation}
	Using \dfref{def:change_of_variables}, the PDF of $Y$ is
	\begin{equation}
		\begin{split}
			p_Y(y) &= p_X\bigl(g^{-1}(y)\bigr) \left| \frac{d}{dy} g^{-1}(y) \right| \\
			&= \operatorname{const} \cdot \left| \frac{d}{dy} \ln\left(\frac{y}{1-y}\right) \right| \\
			&= \operatorname{const} \cdot \frac{1}{y(1-y)}, \quad y \in (0,1).
		\end{split}
	\end{equation}
\end{example}


\begin{theorem}[Error Propagation]
	\label{theorem:error_propagation}
	\index{Error propagation}
	Let
	\begin{equation}
		X_1\colon\Omega \to \Omega_{X_1}, \dots, X_n\colon\Omega \to \Omega_{X_n}
	\end{equation}
	be continuous random variables\index{Random variable} defined on a probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$, and let
	\begin{equation}
		g\colon\Omega_{X_1} \times \dots \times \Omega_{X_n} \to \mathbb{R}
	\end{equation}
	be a differentiable function of these variables. Denote for shorthand
	\begin{equation}
		X = (X_1, \dots, X_n)
	\end{equation}
	and
	\begin{equation}
		\mathbb{E}_X[X] = (\mathbb{E}_{X_1}[X_1], \dots, \mathbb{E}_{X_n}[X_n]).
	\end{equation}
	Then the variance of $g(X)$, which quantifies the uncertainty in $g$ due to the uncertainties in $X_1, \dots, X_n$, satisfies the first-order approximation
	\begin{equation}
		\begin{split}
			\operatorname{Var}_X[g(X)] &= \sum_{i=1}^n \left(\frac{\partial g(X)}{\partial X_i}\bigg|_{X = \mathbb{E}_X[X]}\right)^{\!2} \operatorname{Var}_{X_i}[X_i]
			\\&\quad+ \sum_{i \neq j} \frac{\partial g(X)}{\partial X_i}\frac{\partial g(X)}{\partial X_j}\bigg|_{X = \mathbb{E}_X[X]} \operatorname{Cov}_{X_i,X_j}[X_i, X_j]\\
			&\quad+ \mathcal{O}(\|X - \mathbb{E}_X[X]\|^3).
		\end{split}
		\label{eq:var_approx}
	\end{equation}
\end{theorem}

\begin{proof}
	$g(X)$ can be written as a Taylor expansion\index{Taylor expansion} around $\mathbb{E}_X[X]$ as follows
	\begin{equation}
		\begin{split}
			g(X) = &g(\mathbb{E}_X[X]) + \sum_{i=1}^n  \frac{\partial g(X)}{\partial X_i} \bigg|_{X = \mathbb{E}_X[X]} (X_i - \mathbb{E}_{X_i}[X_i])\\
			& + \mathcal{O}(\|X - \mathbb{E}_X[X]\|^2).
		\end{split}
		\label{e1}
	\end{equation}
	Consequently
	\begin{equation}
		\begin{split}
			\mathbb{E}_X[g(X)] &= g(\mathbb{E}_X[X])+ \sum_{i=1}^n \frac{\partial g(X)}{\partial X_i} \bigg|_{X = \mathbb{E}_X[X]}\, \cancelto{0}{\mathbb{E}_{X_i}[X_i - \mathbb{E}_{X_i}[X_i]]}\\
			&\quad  + \mathcal{O}(\|X - \mathbb{E}_X[X]\|^2)\\
			& = g(\mathbb{E}_X[X]) + \mathcal{O}(\|X - \mathbb{E}_X[X]\|^2)\\
		\end{split}
		\label{e2}
	\end{equation}
	meaning the variance of $g$ can be approximated as follows
	\begin{equation}
		\begin{split}
			\operatorname{Var}_X[g(X)] &= \mathbb{E}_X\big[(g(X) - \mathbb{E}_X[g(X)])^2\big] \\
			&= \mathbb{E}_X\bigg[\bigg( \sum_{i=1}^n (X_i - \mathbb{E}_{X_i}[X_i]) \frac{\partial g}{\partial X_i}\bigg|_{X=\mathbb{E}_X[X]}\\
			&\qquad\qquad + \mathcal{O}(\|X - \mathbb{E}_X[X]\|^2)\bigg)^2\bigg] \\
			&= \sum_{i=1}^n \left(\frac{\partial g(X)}{\partial X_i}\bigg|_{X = \mathbb{E}_X[X]}\right)^{\!2} \operatorname{Var}_{X_i}[X_i]
			\\&\quad+ \sum_{i \neq j} \frac{\partial g(X)}{\partial X_i}\frac{\partial g(X)}{\partial X_j}\bigg|_{X = \mathbb{E}_X[X]} \operatorname{Cov}_{X_i,X_j}[X_i, X_j]\\
			&\quad+ \mathcal{O}(\|X - \mathbb{E}_X[X]\|^3).
		\end{split}
	\end{equation}
\end{proof}

\begin{remark}[Error propagation for independent Random Variables]
	\label{remark:error_prop_independent}
	Let
	\begin{equation}
		X_1\colon\Omega \to \Omega_{X_1}, \dots, X_n\colon\Omega \to \Omega_{X_n}
	\end{equation}
	be continuous random variables\index{Random variable} defined on a probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$.	If the random variables $X_1, \dots, X_n$ are independent\index{Independen random variables}, then according to \thref{theorem:covariance_of_independent_variables} $\mathrm{Cov}_{X_i,X_j}[X_i, X_j] = 0$ $\forall i \neq j$. In this case, \thref{theorem:error_propagation} simplifies to
	\begin{equation}
		\operatorname{Var}_{X}[g(X)] \approx \sum_{i=1}^n \left(\frac{\partial g(X)}{\partial X_i}\Big|_{X = \mathbb{E}_X[X]}\right)^2 \operatorname{Var}_{X_i}[X_i]
		\label{eq:error_prop}
	\end{equation}
	where 
	\begin{equation}
		X = (X_1, \dots, X_n)
	\end{equation}
	and
	\begin{equation}
		\mathbb{E}_X[X] = (\mathbb{E}_{X_1}[X_1], \dots, \mathbb{E}_{X_n}[X_n]).
	\end{equation}
\end{remark}

\begin{example}
	\index{Example: Error propagation}
	A company produces square plates with dimensions characterized by two independent\index{Independen random variables} random variables\index{Normal distribution}\index{Random variable}
	\begin{equation}
		X\sim \operatorname{Norm}(2m,(0.01m)^2), \quad Y\sim \operatorname{Norm}(3m,(0.02m)^2).
	\end{equation} 
	The variance\index{Variance} of the area $XY$ can be determined exactly as follows
	\begin{equation}
		\label{eq:var1}
		\begin{split}
			\operatorname{Var}_{X,Y}[XY]&=\mathbb{E}_{X,Y}[(XY)^2]-(\mathbb{E}_{X,Y}[XY])^2\\
			&=(\operatorname{Var}_X[X]+\mathbb{E}_X[X]\bigg)\bigg(\operatorname{Var}_Y[Y]+\mathbb{E}_Y[Y])-\mathbb{E}_X[X]^2\mathbb{E}_Y[Y]^2\\
			&=\mathbb{E}_Y[Y]^2\operatorname{Var}_X[X]+\mathbb{E}_X[X]^2\operatorname{Var}_Y[Y]+\operatorname{Var}_X[X]\operatorname{Var}_Y[Y]
		\end{split}
	\end{equation}
	where \thref{theorem:expectation_independent} has been applied.	Via the linear approximation from \rmref{remark:error_prop_independent} the variance of the area can be approximated as follows
	\begin{equation}
		\label{eq:var2}
		\begin{split}
			\operatorname{Var}_{X,Y}[XY]|_{\text{linear approx.}}&\approx\sum_{i = X,Y} \bigg( \frac{\partial (XY)}{\partial i}\bigg|_{X = \mathbb{E}_X[X],Y = \mathbb{E}_Y[Y]}  \bigg)^2\operatorname{Var}_i[i]\\
			&=\mathbb{E}_Y[Y]^2\operatorname{Var}_X[X]+\mathbb{E}_X[X]^2\operatorname{Var}_Y[Y]
		\end{split}
	\end{equation}
	Comparing \EQref{eq:var1} and \EQref{eq:var2} the relative difference can be written
	\begin{equation}
		\begin{split}
			\frac{\operatorname{Var}_{X,Y}[XY]|_{\text{linear approx.}}-\operatorname{Var}_{X,Y}[XY]}{\operatorname{Var}_{X,Y}[XY]} &= -\frac{\operatorname{Var}_X[X]\operatorname{Var}_Y[Y]}{\operatorname{Var}_{X,Y}[XY]}\\
			& \simeq -1.6\cdot 10^{-5}.
		\end{split}
	\end{equation}
	
\end{example}

\begin{example}
	Consider a probability space\index{Probability space} $(\Omega, \mathcal{F}, \mathbb{P})$ describing two children with unknown sexes. Let
	\begin{equation}
		\Omega_{\text{child 1}} = \{\text{\Gentsroom}, \text{\Ladiesroom}\}, \quad
		\Omega_{\text{child 2}} = \{\text{\Gentsroom}, \text{\Ladiesroom}\},
	\end{equation}
	and define the sample space as the Cartesian product
	\begin{equation}
		\Omega = \Omega_{\text{child 1}} \times \Omega_{\text{child 2}} =
		\{(\text{\Gentsroom},\text{\Gentsroom}), (\text{\Gentsroom},\text{\Ladiesroom}), (\text{\Ladiesroom},\text{\Gentsroom}), (\text{\Ladiesroom},\text{\Ladiesroom})\}.
	\end{equation}
	The associated algebra of subsets is denoted $\mathcal{F} = 2^{\Omega}$, and the probability measure $\mathbb{P}$ assigns equal mass to each outcome, that is,
	\begin{equation}
		\mathbb{P}(\{\omega\}) = \frac{1}{4}, \quad \omega \in \Omega.
	\end{equation}
	Define the random variables\index{Random variable}
	\begin{equation}
		B \colon \Omega \to \Omega_B, \quad G \colon \Omega \to \Omega_G,
	\end{equation}
	where $B(\omega)$ and $G(\omega)$ denote the number of boys and girls, respectively, in outcome $\omega \in \Omega$, and where
	\begin{equation}
		\Omega_B = \Omega_G = \{0,1,2\}.
	\end{equation}
	Let $\mathcal{F}_B = 2^{\Omega_B}$ and $\mathcal{F}_G = 2^{\Omega_G}$ denote the corresponding algebras. The pair $(B,G)$ defines a measurable mapping
	\begin{equation}
		(B,G)\colon (\Omega, \mathcal{F}) \to (\Omega_B \times \Omega_G, \mathcal{F}_B \otimes \mathcal{F}_G),
	\end{equation}
	where $(\Omega_B \times \Omega_G, \mathcal{F}_B \otimes \mathcal{F}_G)$ is the product measurable space\index{Product measurable space}.	The joint probability measure\index{Joint probability measure} of $(B,G)$ is the image measure
	\begin{equation}
		\mathbb{P}_{B,G} = \mathbb{P} \circ (B,G)^{-1},
	\end{equation}
	defined on $(\Omega_B \times \Omega_G, \mathcal{F}_B \otimes \mathcal{F}_G)$.
	Its corresponding probability mass function (PMF)\index{Probability mass function} $p_{B,G}$ is the Radon–Nikodym derivative of $\mathbb{P}_{B,G}$ with respect to the counting measure\index{Counting measure} $\nu_{B,G} = \nu_B \otimes \nu_G$, i.e.,
	\begin{equation}
		\begin{split}
			p_{B,G}(b,g) &= \frac{\mathrm{d}\mathbb{P}_{B,G}}{\mathrm{d}\nu_{B,G}}(b,g)\\
			& = \mathbb{P}_{B,G}(\{(b,g)\})\\
			& = \mathbb{P}(\{\omega \in \Omega \colon B(\omega)=b,\, G(\omega)=g\}).
		\end{split}
	\end{equation}
	For instance,
	\begin{equation}
		p_{B,G}(1,1)
		= \mathbb{P}(\{(\text{\Gentsroom},\text{\Ladiesroom}), (\text{\Ladiesroom},\text{\Gentsroom})\})
		= \frac{1}{2}.
	\end{equation}
	Let $A \subseteq \Omega_B \times \Omega_G$ denote the event ``at least one boy'':
	\begin{equation}
		A = \{(b,g) \in \Omega_B \times \Omega_G \colon b \ge 1\}.
	\end{equation}
	Using \dfref{def:conditional_probability}, the conditional probability of exactly one girl given at least one boy is (see \rmref{remark:pmf_vs_measure})
	\begin{equation}
		\mathbb{P}_{B,G}(\{(1,1)\} \mid A)
		= \frac{\mathbb{P}_{B,G}(\{(1,1)\} \cap A)}{\mathbb{P}_{B,G}(A)}.
	\end{equation}
	From the PMF,
	\begin{equation}
		\mathbb{P}_{B,G}(\{(1,1)\} \cap A)
		= p_{B,G}(1,1)
		= \frac{1}{2},
	\end{equation}
	and by the law of total probability (\thref{theorem:law_of_total_probability}),
	\begin{equation}
		\mathbb{P}_{B,G}(A)
		= \sum_{g} \sum_{b \ge 1} p_{B,G}(b,g)
		= p_{B,G}(1,1) + p_{B,G}(2,0)
		= \frac{1}{2} + \frac{1}{4}
		= \frac{3}{4}.
	\end{equation}
	Hence,
	\begin{equation}
		\mathbb{P}_{B,G}(\{(1,1)\} \mid A)
		= \frac{2}{3}.
	\end{equation}
\end{example}




\begin{remark}[PMF vs. image measure on events]
	\label{remark:pmf_vs_measure}
	Let $B$ and $G$ be discrete random variables\index{Random variable} with joint PMF\index{Probability mass function} $p_{B,G}$ and image measure\index{Image measure} $\mathbb{P}_{B,G}$. From \dfref{def:prob_density_general}, the PMF\index{Probability mass function} is defined only for single points $(b,g) \in \Omega_B \times \Omega_G$:
	\begin{equation}
		p_{B,G}(b,g) = \mathbb{P}_{B,G}(\{(b,g)\}).
	\end{equation}
	The image measure $\mathbb{P}_{B,G}$, however, is defined on all measurable subsets in the event space\index{Event space} $A \in \mathcal{F}_B\otimes\mathcal{F}_G$. Hence, expressions of the form
	\begin{equation}
		\mathbb{P}_{B,G}(\{(b,g)\} \cap A)
	\end{equation}
	are valid, since $\{(b,g)\} \cap A$ is an element of $\mathcal{F}_B\otimes\mathcal{F}_G$. In contrast, writing
	\begin{equation}
		p_{B,G}(b,g \cap A)
	\end{equation}
	(or similarly) is not valid, because $p_{B,G}$ is defined only on individual points $(b,g)$, not on sets or intersections. The PMF cannot take an event as its argument; only the image measure $\mathbb{P}_{B,G}$ can.
\end{remark}




\begin{example}
	\index{Example: Prosecutor}
	Suppose a crime has been committed. Blood is found at the crime scene for which there is no innocent explanation. It is of the type that is present in $1\%$ of the population. Let $E$ denote the event that a person has the blood type found at the crime scene. Then
	\begin{equation}
		\mathbb{P}(E) = 0.01.
		\label{eq:proseca}
	\end{equation}
	The prosecutor claims: ``There is a $1\%$ chance that the defendant would have the blood type found at the crime scene if he were innocent. Thus, there is a $99\%$ chance that he is guilty.'' This is known as the prosecutor's fallacy. What is wrong with this argument?\newline
	
	The prosecutor's claim can be written as
	\begin{equation}
		\mathbb{P}(E \mid \operatorname{innocent}) = 0.01 \Rightarrow \mathbb{P}(\operatorname{guilty} \mid E) = 0.99.
		\label{eq:prosec1}
	\end{equation}		
	
	To investigate this claim, use \thref{theorem:bayes_theorem} to write
	\begin{equation}
		\begin{split}
			\mathbb{P}(E \mid \operatorname{innocent}) &= \frac{\mathbb{P}(E \cap \operatorname{innocent})}{\mathbb{P}(\operatorname{innocent})} \\
			&= \frac{\mathbb{P}(\operatorname{innocent} \mid E)}{\mathbb{P}(\operatorname{innocent})} \mathbb{P}(E).
		\end{split}
	\end{equation}
	Hence, in general, $\mathbb{P}(E \mid \operatorname{innocent}) \neq \mathbb{P}(E)$. Suppose there are $N$ people in the world, and $M \leq N$ of these have the blood type found at the crime scene. In that case,
	\begin{equation}
		\frac{\mathbb{P}(\operatorname{innocent} \mid E)}{\mathbb{P}(\operatorname{innocent})} = \frac{\frac{M-1}{M}}{\frac{N-1}{N}},
	\end{equation}
	which approaches $1$ in the limit $N,M \rightarrow \infty$. Hence, $\mathbb{P}(E \mid \operatorname{innocent}) \simeq \mathbb{P}(E)$ can be a good approximation, but it is not an exact relation.\newline 
	Assuming $\mathbb{P}(E \mid \operatorname{innocent}) = 0.01$, the prosecutor's claim can be further analyzed using \dfref{def:conditional_probability}, as follows
	\begin{equation}
		\mathbb{P}(\operatorname{guilty} \mid E) + \mathbb{P}(\operatorname{innocent} \mid E) = \frac{\mathbb{P}(\operatorname{guilty} \cap E) + \mathbb{P}(\operatorname{innocent} \cap E)}{\mathbb{P}(E)}.
	\end{equation}
	Innocent and guilty are complementary events that form a partition of the sample space, meaning (\thref{theorem:law_of_total_probability})
	\begin{equation}
		\mathbb{P}(\operatorname{guilty} \cap E) + \mathbb{P}(\operatorname{innocent} \cap E) = \mathbb{P}(E),
	\end{equation}
	and thereby
	\begin{equation}
		\mathbb{P}(\operatorname{guilty} \mid E) + \mathbb{P}(\operatorname{innocent} \mid E) = 1.
	\end{equation}
	This means that if $\mathbb{P}(\operatorname{guilty} \mid E) = 0.99$, then $\mathbb{P}(\operatorname{innocent} \mid E) = 0.01$, and from \thref{theorem:bayes_theorem},
	\begin{equation}
			\mathbb{P}(\operatorname{innocent} \mid E) = \frac{\mathbb{P}(E \mid \operatorname{innocent}) \, \mathbb{P}(\operatorname{innocent})}{\mathbb{P}(E)}
		\label{eq:prosec}
	\end{equation}
	From \EQref{eq:prosec}, it is clear that in general
	\begin{equation}
		\mathbb{P}(E \mid \operatorname{innocent}) \neq \mathbb{P}(\operatorname{innocent} \mid E),
	\end{equation}
	and so even if $\mathbb{P}(E \mid \operatorname{innocent}) = 0.01$, the prosecutor's claim (\EQref{eq:prosec1}) is not true.
\end{example}

\begin{example}
	\index{Example: Bad news from the doctor}
	After your yearly checkup, the doctor has bad news and good news. The bad news is that you tested positive for a serious disease, and that the test is $99\%$ accurate (i.e. the probability of testing positive given that you have the disease is $99\%$, as is the probability of testing negative given that you don't have the disease). The good news is that this is a rare disease, striking only one in $10\,000$ people. What are the chances that you actually have the disease?\newline
	
	Let "s" denote the event of being sick, "h" the event of being healthy, "p" the event of a positive test and "n" the event of a negative test. Using \thref{theorem:bayes_theorem} and \thref{theorem:law_of_total_probability}
	\begin{equation}
		\begin{split}
			\mathbb{P}(\text{s}|\text{p}) &= \frac{\mathbb{P}(\text{p}|\text{s})\mathbb{P}(\text{s})}{\mathbb{P}(\text{p})}\\
			&= \frac{\mathbb{P}(\text{p}|\text{s})\mathbb{P}(\text{s})}{\mathbb{P}(\text{p}|\text{s})\mathbb{P}(\text{s})+\mathbb{P}(\text{p}|\text{h})\mathbb{P}(\text{h})}\\
		\end{split}
	\end{equation}
	where $\mathbb{P}(\text{p}|\text{s}) = 0.99$, $\mathbb{P}(s) = \frac{1}{10\, 000}$, $\mathbb{P}(\text{p}|\text{h})=1-\mathbb{P}(\text{n}|\text{h})$, $\mathbb{P}(\text{n}|\text{h})=0.99$ and $\mathbb{P}(\text{h})=1-\mathbb{P}(\text{s})$. This means
	\begin{equation}
		\mathbb{P}(\text{s}|\text{p}) \simeq 0.0098.
	\end{equation}		
\end{example}

\begin{example}
	\index{Example: Gameshow}
	On a game show, a contestant is told the rules as follows: There are $3$ doors labeled $1,2,3$. A single prize has been hidden behind one of them. You get to select one door. Initially your chosen door will not be opened, instead, the gameshow host will open one of the other two doors in such a way as not to reveal the prize. For example, if you first choose door $1$, the gameshow host will open one of doors $2$ and $3$, and it is guaranteed that he will choose which one to open so that the prize will not be revealed. At this point you will be given a fresh choice of door: You can either stick with your first choice, or you can switch to the other closed door. All the doors will then be opened and you will receive whatever is behind your final choice of door.\newline
	Imagine that the contestant chooses first door $1$; then the gameshow host opens door $3$, revealing nothing. Should the contestant a) stick with door $1$, b) switch to door $2$ or c) it does not matter? Assume that initially, the prize is equally likely to be behind any of the $3$ doors. \newline
	
	Let $z_i$ denote the prize being behind the $i$'th door, $o_i$ the action of opening the $i$'th door and $c_i$ the action of choosing the $i$'th door. The door with the largest probability of containing the prize should be picked, meaning
	\begin{equation}
		z^*=\argmax_z(\mathbb{P}(z|o_3 \cap c_1)).
	\end{equation}
	Since the host cannot open the door containing the prize, 
	\begin{equation}
		\mathbb{P}(z_3|o_3 \cap c_1)=0
	\end{equation}
	 and only $\mathbb{P}(z_1|o_3 \cap c_1)$ and $\mathbb{P}(z_2|o_3 \cap c_1)$ will have to be considered. Using \thref{theorem:bayes_theorem}
	\begin{equation}
		\mathbb{P}(z_1|o_3 \cap c_1) = \frac{\mathbb{P}(o_3|c_1 \cap z_1)\mathbb{P}(c_1 \cap z_1)}{\mathbb{P}(o_3 \cap c_1)}
	\end{equation}
	where from \thref{theorem:law_of_total_probability}
	\begin{equation}
		\begin{split}
			\mathbb{P}(o_3 \cap c_1)&=\sum_i\mathbb{P}(o_3 \cap c_1 \cap z_i)\\
			&=\mathbb{P}(o_3 \cap c_1 \cap z_1)+\mathbb{P}(o_3 \cap c_1 \cap z_2)+\mathbb{P}(o_3 \cap c_1 \cap z_3)\\
			&= \mathbb{P}(o_3|c_1 \cap z_1)\mathbb{P}(c_1 \cap z_1)+\mathbb{P}(o_3|c_1 \cap z_2)\mathbb{P}(c_1 \cap z_2)\\
			&\quad+\mathbb{P}(o_3|c_1 \cap z_3)\mathbb{P}(c_1 \cap z_3).
		\end{split}
	\end{equation}
	$\mathbb{P}(o_3|c_1 \cap z_3)=0$ since the host will not open the door with the prize. $p(o_3|c_1 \cap z_2)=1$ since the host has no other option in this case. $\mathbb{P}(o_3|c_1 \cap z_1)=\frac{1}{2}$ since the host has two options in this case. There is no connection between the choice of door and position of the prize, so $\mathbb{P}(c_1 \cap z_j)=\mathbb{P}(c_1)\mathbb{P}(z_j)$ and initially $\mathbb{P}(z_j)=\mathbb{P}(z_k)$ $\forall j,k\in \{1,2,3\}$. Hence
	\begin{equation}
		\begin{split}
			\mathbb{P}(z_1|o_3 \cap c_1) &= \frac{\mathbb{P}(o_3|c_1 \cap z_1)}{\sum_i\mathbb{P}(o_3|c_1 \cap z_i)}\\
			&=\frac{1}{3}.
		\end{split}
	\end{equation}
	Similarly
	\begin{equation}
		\begin{split}
			\mathbb{P}(z_2|o_3 \cap c_1) &= \frac{\mathbb{P}(o_3|c_1 \cap z_2)}{\sum_i\mathbb{P}(o_3|c_1 \cap z_i)}\\
			&=\frac{2}{3}.
		\end{split}
	\end{equation}
	Since $\mathbb{P}(z_2|o_3 \cap c_1)>\mathbb{P}(z_1|o_3 \cap c_1)>\mathbb{P}(z_3|o_3 \cap c_1)$, door number $2$ is the optimal choise. Hence,answer "b)" is correct. The intuition behind the answer is the information the contestant has at the time of making the decision; initially, there is no a priori information and so $\mathbb{P}(z_1|o_3 \cap c_1)=\frac{1}{3}$. At this time, there is $\frac{2}{3}$ probability that the prize is behind doors $2,3$. When the gameshow host open door $3$, this probability converge on door $2$.
\end{example}

\begin{example}
	\index{Example: Correlation coefficient}
	\index{Probability density function}
	Let $X\colon\Omega \to \Omega_X$ and $Y\colon\Omega\to \Omega_Y$ be continuous random variables\index{Random variable} defined on the probability space\index{Probability space} $(\Omega,\mathcal{F},\mathbb{P})$ and suppose $X\sim \operatorname{Unif}(a=-1, b=1)$ and $Y=X^2$. In this case \index{Expected value}\index{Correlation}\index{Covariance}\index{Variance}
	\begin{equation}
		\operatorname{Corr}_{X,Y}[X,Y] = \operatorname{Corr}_{X}[X,X^2].
	\end{equation}
	Using \dfref{def:correlation} and \dfref{def:covariance}
	\begin{equation}
		\begin{split}
			\operatorname{Corr}_{X}[X,X^2] & = \frac{\operatorname{Cov}_{X}[X,X^2]}{\sqrt{\operatorname{Var}_X[X]\operatorname{Var}_X[X^2]}}\\
			& = \frac{\mathbb{E}_{X}[X^3]-\mathbb{E}_X[X]\mathbb{E}_X[X^2]}{\sqrt{\operatorname{Var}_X[X]\operatorname{Var}_X[X^2]}}\\
		\end{split}
	\end{equation}
	In this case for the nominator\index{Covariance}\index{Expected value}\index{Variance}
	\begin{equation}
		\begin{split}
			\operatorname{Cov}_{X}[X,X^2] &= \int_{\Omega_X} x^3 p_X(x) \mathrm{d}x-\int_{\Omega_X} xp_X(x) \mathrm{d}x\int_{\Omega_X} x^2p_X(x) \mathrm{d}x\\
			&= \frac{1}{b-a}\int_{a}^{b}x^3\mathrm{d}x-\frac{1}{(b-a)^2}\int_{a}^{b} x \mathrm{d}x\int_{a}^{b} x^2 \mathrm{d}x\\
			&= \frac{1}{12}(a-b)^2(a+b)\\
			&=0
		\end{split}
	\end{equation}
	where the last equality comes from the fact that $a+b = 0$ in this case. However, we need to make sure the denominator does not diverge
	\begin{equation}
		\begin{split}
			\operatorname{Var}_X[X]\operatorname{Var}_X[X^2] & =\big(\mathbb{E}_X[X^2]-\mathbb{E}_X[X]^2\big) \big(\mathbb{E}_X[X^4]-\mathbb{E}_X[X^2]^2\big)\\
			& = \frac{1}{540}(b-a)^4(4a^2+7ab+4b^2)\\
			&\neq 0.
		\end{split}
	\end{equation}
	It denominator does not diverge, so the factorized $a+b$ from the nominator makes $\operatorname{Corr}_{X}[X,X^2]=0$.
\end{example}

\begin{example}
	\index{Example: Correlation coefficient}	
	According to \dfref{def:variance} the variance\index{Variance}\index{Correlation} is defined as positive definite. This means
	\begin{equation}
		\label{eq:corr_deriv}
		\begin{split}
			0\leq& \operatorname{Var}_{X,Y}\bigg[\frac{X}{\sqrt{\operatorname{Var}_{X}[X]}}\pm\frac{Y}{\sqrt{\operatorname{Var}_{Y}[Y]}}\bigg]\\
			& = \frac{\operatorname{Var}_X[X]}{\operatorname{Var}_{X}[X]}+\frac{\operatorname{Var}_Y[Y]}{\operatorname{Var}_{Y}[Y]}\pm \frac{2}{\sqrt{\operatorname{Var}_{X}[X]\operatorname{Var}_{Y}[Y]}}\operatorname{Cov}_{X,Y}[X,Y]\\
			& = 2\pm 2\operatorname{Corr}_{X,Y}[X,Y].
		\end{split}
	\end{equation}
	 From \EQref{eq:corr_deriv} the result follows
	\begin{equation}
		-1\leq \operatorname{Corr}_{X,Y}[X,Y]\leq 1.
	\end{equation}	
\end{example}

\begin{example}
	\index{Example: Correlation coefficient}
	Let $X:\Omega\to \Omega_X$ be a continuous random variable defined on the probability space $(\Omega,\mathcal{F},\mathbb{P})$ and suppose	$Y=aX+b$ given parameters $a>0$ and $b$. Since $Y$ is uniquely determined by $X$,
	\begin{equation}
		\operatorname{Corr}_{X,Y}[X,Y] = \operatorname{Corr}_{X}[X,aX+b].
	\end{equation}
	Using \dfref{def:correlation} and \dfref{def:covariance}\index{Variance}\index{Covariance}\index{Expected value}
	\begin{equation}
		\operatorname{Corr}_{X}[X,aX+b] = \frac{\operatorname{Cov}_{X}[X,aX+b]}{\sqrt{\operatorname{Var}_X[X]\operatorname{Var}_X[aX+b]}}
		\label{eq:corra}
	\end{equation}
	with
	\begin{equation}
		\begin{split}
			\operatorname{Cov}_{X}[X,aX+b] & = \mathbb{E}_{X}[X(aX+b)]-\mathbb{E}_X[X]\mathbb{E}_X[aX+b]\\
			&= a\mathbb{E}_X[X^2]+b\mathbb{E}_X[X]-a\mathbb{E}_X[X]^2-b\mathbb{E}_X[X]\\
			&=a\operatorname{Var}_X[X]
		\end{split}
		\label{eq:corrb}
	\end{equation}
	and
	\begin{equation}
		\begin{split}
			\operatorname{Var}_X[aX+b] &= a^2\operatorname{Var}_X[X]+\cancelto{0}{\operatorname{Var}_X[b]}+2\cancelto{0}{\operatorname{Cov}_{X,X}[aX,b]}\\
			& = a^2\operatorname{Var}_X[X].
		\end{split}
		\label{eq:corrc}
	\end{equation}
	Combining \EQref{eq:corra}, \EQref{eq:corrb} and \EQref{eq:corrc} yields
	\begin{equation}
		\begin{split}
			\operatorname{Corr}_{X}[X,aX+b] &= \frac{a\operatorname{Var}_X[X]}{\sqrt{a^2\operatorname{Var}_X[X]\operatorname{Var}_X[X]}}\\
			&=\frac{a}{|a|}.
		\end{split}
	\end{equation}
\end{example}

