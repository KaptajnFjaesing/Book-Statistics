\section{Bayesian Statistics}
The Bayesian paradigm (\dfref{def:bayesian_statistics}) originally come from the work of \citet{Bayes:63,laplace_thorie_1812} with much of the modern discussions and formalism created later by \citet{Finetti1937LaP,Jeffreys1940,Savage1954}.\newline
In the Bayesian paradigm, it is assumed that Nature's decisions can be captured by a statistical model\index{Statistical model} with parameters that are modeled as realizations of random variables and a subjective probability measure. This means that the probability density for Nature's actions, used to determine the optimal decision rule in \thref{theorem:opt_decision_rule}, can be written
\begin{equation}
	\begin{split}
		p(y_{n+1}\mid \tilde{D}) &= \int p(w,y_{n+1}\mid \tilde{D}) \mathrm{d}w\\
		& = \int p(y_{n+1}\mid w,\tilde{D})p(w\mid \tilde{D}) \mathrm{d}w,
	\end{split}
	\label{eq:hest1}
\end{equation}
where the relaxation of the notation described in \rmref{rem:notation} has been used. Using \thref{theorem:bayes_theorem}
\begin{equation}
	\begin{split}
		p(w|\tilde{D}) &= p(w|D)\\
		&= \frac{p(D_y|w,D_x)p(w)}{p(D_y|D_x)},
	\end{split}
	\label{eq:pa2}
\end{equation}
where $D_y= \{y_i\}_{i=1}^n$, $D_x = \{x_i\}_{i=1}^n$, \axref{ax:observation_relevance} has been used for the first and second equality and $p(D_y|D_x)$ can be expanded via marginalization (\rmref{remark:marginalization}).

\begin{axiom}[Relevance of Observations]
	\label{ax:observation_relevance}
	The Robot's observations are relevant for estimating Nature's model only when they map to known actions of Nature.
\end{axiom}

$p(w)$ is the Robot's prior belief\index{Prior measure} about $w$. $p(D_s|w,D_x)$ is the likelihood\index{Likelihood} of the past observations of Nature's actions, and $p(w|D)$, called the posterior\index{Posterior}, represents the Robot's belief after observing data. The prior depends on parameters that must be specified and cannot be learned from data, as it reflects the Robot's belief before any observations are made.

\subsection{Bayesian Regression}
\label{chp:regression}
Regression involves the Robot building a model,
\begin{equation}
	f: \Omega_\Theta\times \Omega_X\to\Omega_Y,
\end{equation} 
with associated parameters $\theta\in\Omega_\Theta \subseteq\Omega_W$, that estimates Nature's action $y\in \Omega_Y=\mathbb{R}$ based on observed data $x\in \Omega_X$. The model $f$ acts as a proxy for the Robot in that it on behalf of the Robot estimates the action of Nature given an input. Hence, in providing an estimate, the model must make a choice, similar to the Robot and thus the Robot must pick a cost function for the model. In this study, the quadratic cost function from \dfref{def:quadratic_cost} will be considered to review the subject. According to \thref{theorem:expectation_decision_rule} the best action for the Robot can be written
\begin{equation}
	U^*(x_{n+1},D) = \int y_{n+1} p(y_{n+1}|x_{n+1},D) \mathrm{d}y_{n+1}.
	\label{eq:q1}
\end{equation}
Assuming the actions of Nature follow a normal distribution\index{Normal distribution} with the function $f$ as mean and an unknown precision, $\xi\in \Omega_W$
\begin{equation}
	p(y_{n+1}|x_{n+1},w)=\sqrt{\frac{\xi}{2\pi}} e^{-\frac{\xi}{2}(f(\theta,x_{n+1})-y_{n+1})^2},
	\label{f_dist}
\end{equation}
where $w = \{\theta, \xi,\dots\}$ denotes the collection of parameters. Using \EQref{f_dist} and marginalizing\index{Marginalization} (\rmref{remark:marginalization}) over $\xi,\theta$
\begin{equation}
	\begin{split}
		p(y_{n+1}|x_{n+1},D) &= \int  p(y_{n+1},\theta,\xi|x_{n+1},D) \mathrm{d}\theta \mathrm{d}\xi\\
		& = \int  p(y_{n+1}|x_{n+1},\theta,\xi,D)  p(\theta,\xi|x_{n+1},D)\mathrm{d}\theta \mathrm{d}\xi\\
		& = \int  p(y_{n+1}|x_{n+1},\theta,\xi)  p(\theta,\xi|D) \mathrm{d}\theta \mathrm{d}\xi,\\
	\end{split}
	\label{eq:q2}
\end{equation}
where it has been used that 
\begin{equation}
	p(y_{n+1}|\theta,\xi,x_{n+1},D) = p(y_{n+1}|\theta,\xi,x_{n+1})
\end{equation}
since, by definition, $f$ deterministically maps each input $x_{n+1}$ (given $\theta,\xi$) to a conditional distribution over $y_{n+1}$ (\EQref{f_dist}), and
\begin{equation}
	p(\theta,\xi|x_{n+1},D) = p(\theta,\xi|D)
\end{equation} 
from \axref{ax:observation_relevance}. Using \EQref{eq:q2} in \EQref{eq:q1}\footnote{Note that a function of a random variable is itself a random variable, so $f$ is a random variable.}
\begin{equation}
	\begin{split}
		U^*(x_{n+1},D) & = \int f(\theta,x_{n+1})  p(\theta,\xi|D) \mathrm{d}\theta \mathrm{d}\xi,\\
		& = \mathbb{E}[f|x_{n+1},D]
	\end{split}
	\label{eq:q3}
\end{equation}	
where it has been used that
\begin{equation}
	\begin{split}
		\mathbb{E}[Y_{n+1}|x_{n+1},\theta,\xi] &= \int y_{n+1} p(y_{n+1}|x_{n+1},\theta,\xi) \mathrm{d}y_{n+1} \\
		&= f(\theta,x_{n+1})
	\end{split}
\end{equation}
according to \EQref{f_dist}. Using Bayes theorem\index{Bayes theorem} (\thref{theorem:bayes_theorem})
\begin{equation}
	p(\theta,\xi|D) = \frac{p(D_y|D_x,\theta,\xi)p(\theta,\xi|D_x)}{p(D_y|D_x)}
	\label{eq:bayes2}
\end{equation}
where from marginalization\index{Marginalization} (\rmref{remark:marginalization})
\begin{equation}
	p(D_y|D_x) = \int p(D_y|D_x,\theta,\xi)p(\theta,\xi|D_x) \mathrm{d}\theta \mathrm{d}\xi.
\end{equation}
Assuming the past actions of Nature are independent and identically distributed (IID)\index{IID}, the likelihood\index{Likelihood} can be written (using equation \EQref{f_dist})
\begin{equation}
	p(D_y|D_x,\theta,\xi) = \bigg(\frac{\xi}{2\pi}\bigg)^\frac{n}{2}\prod_{i=1}^n e^{-\frac{\xi}{2}(f(\theta,x_i)-y_i)^2}
	\label{reg:likelihood}
\end{equation}
From the chain rule\index{Chain rule} (\thref{theorem:chain_rule}) and \axref{ax:observation_relevance}
\begin{equation}
	p(\theta,\xi|D_x) = p(\theta|\xi)p(\xi).
\end{equation}
Assuming the distributions of the $\theta$'s are i) independent of $\xi$ and ii) normally distributed\footnote{The normally distributed prior is closely related to weight decay~\citep{Plaut1986}, a principle conventionally used in Frequentist statistics to avoid the issue of overfitting.} with zero mean and a precision described by a hyperparameter, $\lambda$. 	 
\begin{equation}
	\begin{split}
		p(\theta|\xi) & = p(\theta)\\
		& = \int p(\theta|\lambda)p(\lambda) \mathrm{d}\lambda
	\end{split}
	\label{eq:prior1}
\end{equation}
The precision is constructed as a wide gamma distribution\index{Gamma distribution} so as to approximate an objective prior
\begin{equation}
	p(\theta|\lambda)p(\lambda)
	= \prod_{q=1}^{\tilde{n}} \frac{\lambda_q^\frac{n_q}{2}}{(2\pi)^\frac{n_q}{2}}e^{-\frac{\lambda_q}{2}\sum_{l=1}^{n_q}\theta_l^2}\frac{\beta_q^{\alpha_q}}{\Gamma(\alpha_q)}\lambda_q^{\alpha_q-1}e^{-\beta_q \lambda_q}
	\label{eq:prior}
\end{equation}
where $\alpha_q,\beta_q$ are prior parameters and $\tilde{n}$ is the number of hyper parameters. In the completely general case $\tilde{n}$ would equal the number of parameters $\theta$, such that each parameter has an independent precision. In practice, the Robot may consider assigning some parameters the same precision, e.g. for parameters in the same layer in a neural network. Since $p(\xi)$ is analogous to $p(\lambda)$ -- in that both are prior distributions for precision parameters -- $p(\xi)$ is assumed to be a wide gamma distribution, then
\begin{equation}
	\begin{split}
		p(\xi) & = \text{Ga}(\xi|\tilde{\alpha},\tilde{\beta})\\
		& =\frac{\tilde{\beta}^{\tilde{\alpha}}}{\Gamma(\tilde{\alpha})}\xi^{\tilde{\alpha}-1}e^{-\tilde{\beta} \xi}.
	\end{split}
	\label{p7}
\end{equation}
At this point equation \EQref{eq:q1} is fully specified and can be approximated by obtaining samples from $p(\theta,\xi,\lambda|D)$ via Hamiltonian Monte Carlo (HMC)~\citep{Hammersley1964,Duane:1987de,Neal:1996,Neal2012} (see \appref{app:HMC} for a review of HMC). The centerpiece in the HMC algorithm is the Hamiltonian defined as follows~\citep{Neal:1996,Neal2012}
\begin{equation}
	H \equiv  \sum_{q=1}^{\tilde{n}}\sum_{l=1}^{n_q}\frac{p_{l}^2}{2m_{l}}-\ln p(\theta,\xi,\lambda|D)+\operatorname{const},
	\label{eqh}
\end{equation}
where 
\begin{equation}
	p(\theta,\xi|D) = \int p(\theta,\xi,\lambda|D) \mathrm{d}\lambda.
	\label{eq:ss}
\end{equation}
Besides its function in the HMC algorithm, the Hamiltonian presents the details of the Bayesian model well. Using \EQref{eq:bayes2}-\EQref{eq:ss} yields
\begin{equation}
	\begin{split}
		H&=\sum_{q=1}^{\tilde{n}}\sum_{l=1}^{n_q}\frac{p_{l}^2}{2m_{l}}+\frac{n}{2}[\ln(2\pi)-\ln\xi] +\frac{\xi}{2}\sum_{i=1}^{n}(f(\theta,x_i)-y_i)^2\\
		&\quad+\sum_{q=1}^{\tilde{n}}\bigg(\ln\Gamma(\alpha_q)-\alpha_q\ln\beta_q+(1-\alpha_q)\ln\lambda_q+\beta_q\lambda_q\\
		&\qquad\qquad+\frac{n_q}{2}(\ln(2\pi)-\ln\lambda_q)+\frac{\lambda_q}{2}\sum_{l=1}^{n_q}\theta_l^2\bigg)\\
		&\quad+\ln\Gamma(\tilde{\alpha})-\tilde{\alpha}\ln\tilde{\beta}+(1-\tilde{\alpha})\ln\xi+\tilde{\beta}\xi+\operatorname{const}.
	\end{split}
	\label{eqh2}
\end{equation}

\begin{example}
	\index{Example: HMC Hamiltonian variable change}
	Let $\xi \equiv e^\zeta$, such that $\zeta\in [-\infty,\infty]$ maps to $\xi\in[0,\infty]$ and $\xi$ is ensured to be positive definite regardless of the value of $\zeta$. Using the differential $d\xi =  \xi d\zeta$ in \EQref{eq:q3} means $p(\theta,\xi,\lambda|D)$ is multiplied with $\xi$. Hence, when taking $-\ln p(\theta,\xi,\lambda|D)$ according to \EQref{eqh}, a $-\ln\xi$ is added to the Hamiltonian. In practice this means
	\begin{equation}
		(1-\tilde{\alpha})\ln\xi\in H\Rightarrow -\tilde{\alpha}\ln\xi.
	\end{equation} 	
\end{example}

\subsection{Bayesian Classification}
\label{chp:baycl}
Classification involves the Robot building a model,
\begin{equation}
	f: \Omega_\Theta \times \Omega_X \to \Delta^K,
\end{equation}
with associated parameters $\theta \in \Omega_\Theta\subseteq\Omega_W$, that estimates Nature's actions $y\in \Omega_Y= \{1,\dots,K\}$ based on observed data $x\in \Omega_X$. Here
\begin{equation}
	\Delta^K = \bigg\{p \in \mathbb{R}^K \bigg|\, p_{y_{n+1}} \geq 0,\; \sum_{y_{n+1}=1}^K p_{y_{n+1}} = 1\bigg\}
\end{equation} 
denotes the $K$-dimensional probability simplex, so that for $x_i \in \Omega_X$ the model output $f(\theta,x_i)$ is a probability vector representing the conditional distribution of the class label $y_i \in \Omega_Y$. In particular, the probability of observing class $y_{n+1}$ given $x_{n+1}$ and parameters $\theta$ is 
\begin{equation}
	p(y_{n+1} \mid x_{n+1}, \theta) = f_{y_{n+1}}(\theta,x_{n+1}),
	\label{f_dist2}
\end{equation}
where $f_{y_{n+1}}(\theta,x_{n+1})$ denotes the $y_{n+1}$-th component of $f(\theta,x_{n+1})$. 
By construction, these probabilities satisfy
\begin{equation}
	\sum_{y_{n+1} \in \Omega_Y} p(y_{n+1} \mid x_{n+1}, \theta) = 1.
\end{equation}
In this case, the Robot's action space is equal to Natures action space, with the possible addition of a reject option, $\Omega_U=\Omega_Y\cup \{\operatorname{reject}\}$. To review this subject the Robot will be considered to be penalized equally in case of a classification error, which corresponds to the $0-1$ cost function (\dfref{def:0_1_cost_function}), with the addition of a reject option at cost $\psi$. This means
\begin{equation}
	C(U(\tilde{D}),y_{n+1}) = 1- \delta_{U(\tilde{D}),y_{n+1}}+(\psi-1)\delta_{U(\tilde{D}),\operatorname{reject}}.
\end{equation}
The optimal decision rule for the robot can the be written (\EQref{eq:conditional_cost_discrete})
\begin{equation}
	\begin{split}
		U^*(\tilde{D}) & = \argmin_{U(\tilde{D})}\mathbb{E}[C(U(\tilde{D}), Y_{n+1})|\tilde{D}]\\
		&= \argmin_{U(\tilde{D})}\bigg(\sum_{y_{n+1}\in \Omega_Y}C(U(\tilde{D}),y_{n+1})p(y_{n+1}\mid\tilde{D})+(\psi-1)\delta_{U(\tilde{D}),\operatorname{reject}}\bigg)\\
		& = \argmin_{U(\tilde{D})}\bigg(1- p(U(\tilde{D})|\tilde{D})+(\psi-1)\delta_{U(\tilde{D}),\operatorname{reject}}\bigg).
	\end{split}
	\label{eq:expected_cost1}
\end{equation}
In absence of the reject option, the optimal decision rule is to pick the MAP, as shown in \thref{theorem:MAP}. Using \EQref{f_dist2} and marginalizing over $\theta$
\begin{equation}
	\begin{split}
		p(U(\tilde{D})|\tilde{D}) &= \int p(U(\tilde{D}),\theta \mid\tilde{D}) \mathrm{d}\theta \\
		& = \int p(U(\tilde{D})\mid \theta,\tilde{D})  p(\theta \mid\tilde{D})\mathrm{d}\theta \\
		& = \int p(U(\tilde{D})\mid x_{n+1},\theta)  p(\theta\mid D)\mathrm{d}\theta \\
		& = \int f_{U(\tilde{D})}(\theta,x_{n+1})  p(\theta \mid D)\mathrm{d}\theta \\
		& = \mathbb{E}[f_{U(\tilde{D})}(\theta,x_{n+1})\mid D],\\
	\end{split}
	\label{eq:q5}
\end{equation}
where for the second to last equality it has been assumed that
\begin{equation}
	p(U(\tilde{D})\mid \theta,\tilde{D}) = p(U(\tilde{D})\mid \theta,x_{n+1})
\end{equation}
since, by definition, $f$ deterministically maps each input $x_{x+1}$ to a probability vector(\EQref{f_dist2}), and $p(\theta \mid\tilde{D}) = p(\theta \mid D)$ from \axref{ax:observation_relevance}. From Bayes theorem\index{Bayes theorem}
\begin{equation}
	p(w|D) =\frac{p(D_y|D_x,\theta)p(\theta\mid D_x)}{p(D_y\mid D_x)},
\end{equation}
where from \axref{ax:observation_relevance} $p(\theta\mid D_x) = p(\theta)$. Assuming the distribution over $\theta$ is normally distributed with zero mean and a precision described by a hyperparameter, $\lambda$, 
\begin{equation}
	p(\theta) = \int p(\theta\mid\lambda)p(\lambda) \mathrm{d}\lambda.
\end{equation}
where $p(\theta|\lambda)p(\lambda)$ is given by \EQref{eq:prior}. Assuming the past actions of Nature are independent and identically distributed (IID) \index{IID}, the likelihood can be written~\citep{Fischer1999} 
\begin{equation}
	\begin{split}
		p(D_y|D_x,\theta) &=\prod_{i=1}^{n}p(y_i|x_i,\theta)\\
		&=\prod_{i=1}^{n}f_{y_i}(\theta,x_i).\\
	\end{split}
	\label{lik}
\end{equation}
At this point \EQref{eq:expected_cost1} is fully specified and can be approximated by HMC similarly to the regression case (see \appref{app:HMC} for a review of HMC). In this case, the model can be represented by the Hamiltonian 
\begin{equation}
	H \equiv  \sum_{q}\sum_{l}\frac{p_{l}^2}{2m_{l}}-\ln p(\theta,\lambda|D)+\operatorname{const}
	\label{ham3}
\end{equation}
where
\begin{equation}
	p(\theta|D) = \int p(\theta,\lambda|D) \mathrm{d} \lambda.
\end{equation}
Using \EQref{eq:q5}-\EQref{lik} in \EQref{ham3} yields the Hamiltonian
\begin{equation}
	\begin{split}
		H&=\sum_{q=1}^{\tilde{n}}\sum_{l=1}^{n_q}\frac{p_{l}^2}{2m_{l}}-\sum_{i=1}^{n}\ln f_{y_i}(\theta,x_i)\\
		&\quad+\sum_{q=1}^{\tilde{n}}\bigg(\ln\Gamma(\alpha_q)-\alpha_q\ln\beta_q+(1-\alpha_q)\ln\lambda_q+\beta_q\lambda_q\\
		&\qquad \qquad+\frac{n_q}{2}(\ln(2\pi)-\ln\lambda_q)+\frac{\lambda_q}{2}\sum_{l=1}^{n_q}\theta_l^2\bigg)+\operatorname{const}\\
	\end{split}.
	\label{ham2}
\end{equation}
Sampling \EQref{ham2} yields a set of coefficients which can be used to compute $\mathbb{E}[f_{y_{n+1}}(\theta,x_{n+1})\mid D]$ which in turn (see \EQref{eq:q5} and \EQref{eq:expected_cost1}) can be used to compute $U^*(\tilde{D})$.


\subsection{Bayesian Parameter Estimation}
In the special case of parameter estimation, Nature’s action is identified with the unknown parameter $W \in \Omega_W$ that governs the statistical model $f$. The Robot’s goal is to infer the value of $W$ from the observed dataset $D = \{(x_i, y_i)\}_{i=1}^n$. Hence, the Robot’s action corresponds to producing an estimate of $W$, denoted by $U(D) \in \Omega_U = \Omega_W$. By \thref{theorem:opt_decision_rule}, the optimal decision rule can be written
\begin{equation}
	U^*(D)=\argmin_{U(D)}\mathbb{E}_{W\mid D}[C(U(D), W)\mid D],
	\label{eq:param_decision}
\end{equation}
with
\begin{equation}
	\mathbb{E}_{W\mid D}[C(U(D), W)\mid D] = \int C(U(D),w)p(w\mid D) \mathrm{d}w.
\end{equation}
At this point, the Robot can select a cost function like in \secref{sec:assing_cost} and proceed by expanding $p(w\mid D)$ similarly to \EQref{eq:pa2}.


\begin{example}
	\label{ex:heteroscedastic_bayes}
	\index{Example: Heteroscedastic Normal model}
	Consider two sensors that produce noisy measurements
	\begin{equation}
		D = \{ y_i^{(1)} \}_{i=1}^{N^{(1)}} \cup \{ y_j^{(2)} \}_{j=1}^{N^{(2)}}.
	\end{equation}
	of a common but unknown physical quantity. Let the parameter of interest be represented by the random variable
	\begin{equation}
		W\colon \Omega \to \Omega_W,
	\end{equation}
	interpreted as Nature’s true mean value, from the probability space $(\Omega, \mathcal{F}, \mathbb{P})$ to a measurable space $(\Omega_W,\mathcal{F}_W)$. The two sensors produce conditionally independent observations with known but distinct noise variances $\nu_1, \nu_2 > 0$, where $\nu_1 \neq \nu_2$. By \EQref{eq:param_decision} with a quadratic cost function yields the optimal decision rule 
	\begin{equation}
		\begin{split}
			U^*(D) &=\argmin_{U(D)}\mathbb{E}_{W|D}[C(U(D), W)|D]\\
			&= \argmin_{U(D)}\int (U(D) - w)^2p(w\mid D) \mathrm{d}w \\
			&= \int w p(w\mid D) \mathrm{d}w
		\end{split}
		\label{eq:deci}
	\end{equation}
	where by \thref{theorem:bayes_theorem}
	\begin{equation}
		p(w \mid D)
		= \frac{p(D \mid w)p(w)}
		{p(D)}.
		\label{eq:hetero_posterior}
	\end{equation}
	Assuming a non-informative (uniform) prior 
	\begin{equation}
		p(w) = \operatorname{Unif}(a,b),
	\end{equation}
	the posterior is proportional to the likelihood
	\begin{equation}
		\begin{split}
			p(D \mid w)
			&= \prod_{i=1}^{N^{(1)}} p(y_i^{(1)}\mid w)
			\prod_{j=1}^{N^{(2)}} p(y_j^{(2)}\mid w).
		\end{split}
	\end{equation}
	Taking 
	\begin{equation}
		p(y_i^{(1)}\mid w) = \frac{1}{\sqrt{2\pi\nu_1}}
		e^{-\frac{(y_i^{(1)} - w)^2}{2\nu_1}},
		\qquad
		p(y_j^{(2)}\mid w) = \frac{1}{\sqrt{2\pi\nu_2}}
		e^{-\frac{(y_j^{(2)} - w)^2}{2\nu_2}},
	\end{equation}
	yields
	\begin{equation}
		p(w \mid D) =\frac{1}{\sqrt{2\pi\tilde{\nu}}} e^{-\frac{1}{2\tilde{\nu}}(w - \tilde{w})^2}
		\label{eq:posterior1}
	\end{equation}
	where the posterior variance \(\tilde{\nu}\) and mean \(\tilde{\mu}\) are given by
	\begin{equation}
		\tilde{\nu}
		= \left(\frac{N^{(1)}}{\nu_1} + \frac{N^{(2)}}{\nu_2}\right)^{-1},
		\qquad
		\tilde{w}
		= \tilde{\nu}\left(\frac{N^{(1)}\bar{y}^{(1)}}{\nu_1} + \frac{N^{(2)}\bar{y}^{(2)}}{\nu_2}\right),
	\end{equation}
	with sample means
	\begin{equation}
		\bar{y}^{(1)} = \frac{1}{N^{(1)}}\sum_{i=1}^{N^{(1)}} y_i^{(1)},
		\qquad
		\bar{y}^{(2)} = \frac{1}{N^{(2)}}\sum_{j=1}^{N^{(2)}} y_j^{(2)}.
	\end{equation}
	Using \EQref{eq:posterior1} in \EQref{eq:deci} means
	\begin{equation}
		\begin{split}
			U^*(D) = \tilde{w}.
		\end{split}
	\end{equation}
	Hence, the Robot’s optimal action is to report the weighted average of the two sample means, where each weight is inversely proportional to the corresponding sensor variance.
\end{example}

